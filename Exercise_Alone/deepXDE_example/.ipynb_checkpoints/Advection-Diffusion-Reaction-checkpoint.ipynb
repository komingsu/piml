{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f97e4723-3db5-4f7c-8a0a-fa9074fe504f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: tensorflow.compat.v1\n",
      "Other supported backends: tensorflow, pytorch, jax, paddle.\n",
      "paddle supports more examples now and is recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 02:59:32.524040: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-16 02:59:32.558154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-16 02:59:32.558435: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enable just-in-time compilation with XLA.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/deepxde/nn/initializers.py:118: The name tf.keras.initializers.he_normal is deprecated. Please use tf.compat.v1.keras.initializers.he_normal instead.\n",
      "\n",
      "Warning: 500 points required, but 506 points sampled.\n",
      "Compiling model...\n",
      "Building DeepONet...\n",
      "'build' took 0.079083 s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/deepxde/nn/tensorflow_compat_v1/deeponet.py:187: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  return tf.layers.dense(\n",
      "2023-11-16 02:59:36.335031: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-16 02:59:36.336813: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-16 02:59:36.337217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-16 02:59:36.337672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-16 02:59:37.355064: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-16 02:59:37.355741: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-16 02:59:37.355783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-11-16 02:59:37.356158: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-16 02:59:37.356212: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-11-16 02:59:37.356273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3433 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'compile' took 1.467830 s\n",
      "\n",
      "Initializing variables...\n",
      "Training model...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 02:59:37.731293: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2023-11-16 02:59:37.865821: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f5fbc015a60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-16 02:59:37.865868: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2023-11-16 02:59:37.900440: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-16 02:59:51.561628: I tensorflow/compiler/jit/xla_compilation_cache.cc:478] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step      Train loss                        Test loss                         Test metric\n",
      "0         [1.66e+00, 4.26e-01, 1.10e-02]    [1.46e+00, 4.26e-01, 1.10e-02]    []  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 03:00:13.758238: W tensorflow/core/common_runtime/bfc_allocator.cc:360] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2023-11-16 03:00:25.888342: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.27GiB (rounded to 4590147328)requested by op cluster_2_1/xla_run\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-11-16 03:00:25.888405: I tensorflow/core/common_runtime/bfc_allocator.cc:1027] BFCAllocator dump for GPU_0_bfc\n",
      "2023-11-16 03:00:25.888420: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (256): \tTotal Chunks: 20, Chunks in use: 20. 5.0KiB allocated for chunks. 5.0KiB in use in bin. 80B client-requested in use in bin.\n",
      "2023-11-16 03:00:25.888428: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (512): \tTotal Chunks: 30, Chunks in use: 30. 15.0KiB allocated for chunks. 15.0KiB in use in bin. 15.0KiB client-requested in use in bin.\n",
      "2023-11-16 03:00:25.888433: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1024): \tTotal Chunks: 6, Chunks in use: 6. 6.2KiB allocated for chunks. 6.2KiB in use in bin. 6.0KiB client-requested in use in bin.\n",
      "2023-11-16 03:00:25.888438: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-16 03:00:25.888442: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-16 03:00:25.888447: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-16 03:00:25.888453: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16384): \tTotal Chunks: 5, Chunks in use: 4. 119.8KiB allocated for chunks. 100.0KiB in use in bin. 100.0KiB client-requested in use in bin.\n",
      "2023-11-16 03:00:25.888458: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (32768): \tTotal Chunks: 1, Chunks in use: 1. 39.0KiB allocated for chunks. 39.0KiB in use in bin. 25.0KiB client-requested in use in bin.\n",
      "2023-11-16 03:00:25.888463: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (65536): \tTotal Chunks: 20, Chunks in use: 20. 1.25MiB allocated for chunks. 1.25MiB in use in bin. 1.25MiB client-requested in use in bin.\n",
      "2023-11-16 03:00:25.888468: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-16 03:00:25.888472: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-16 03:00:25.888477: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (524288): \tTotal Chunks: 1, Chunks in use: 0. 583.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-16 03:00:25.888482: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1048576): \tTotal Chunks: 1, Chunks in use: 1. 1.22MiB allocated for chunks. 1.22MiB in use in bin. 1.22MiB client-requested in use in bin.\n",
      "2023-11-16 03:00:25.888486: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-16 03:00:25.888491: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4194304): \tTotal Chunks: 1, Chunks in use: 1. 4.00MiB allocated for chunks. 4.00MiB in use in bin. 2.44MiB client-requested in use in bin.\n",
      "2023-11-16 03:00:25.888495: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-16 03:00:25.888500: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-16 03:00:25.888504: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-16 03:00:25.888510: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (67108864): \tTotal Chunks: 2, Chunks in use: 1. 190.78MiB allocated for chunks. 64.00MiB in use in bin. 61.04MiB client-requested in use in bin.\n",
      "2023-11-16 03:00:25.888517: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-16 03:00:25.888522: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (268435456): \tTotal Chunks: 1, Chunks in use: 0. 3.16GiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-16 03:00:25.888541: I tensorflow/core/common_runtime/bfc_allocator.cc:1050] Bin for 4.27GiB was 256.00MiB, Chunk State: \n",
      "2023-11-16 03:00:25.888548: I tensorflow/core/common_runtime/bfc_allocator.cc:1056]   Size: 3.16GiB | Requested Size: 172.25MiB | in_use: 0 | bin_num: 20\n",
      "2023-11-16 03:00:25.888552: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 2097152\n",
      "2023-11-16 03:00:25.888559: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c00000 of size 256 next 1\n",
      "2023-11-16 03:00:25.888563: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c00100 of size 256 next 2\n",
      "2023-11-16 03:00:25.888567: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c00200 of size 256 next 3\n",
      "2023-11-16 03:00:25.888570: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c00300 of size 256 next 4\n",
      "2023-11-16 03:00:25.888574: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c00400 of size 512 next 5\n",
      "2023-11-16 03:00:25.888578: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c00600 of size 25600 next 6\n",
      "2023-11-16 03:00:25.888581: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c06a00 of size 256 next 7\n",
      "2023-11-16 03:00:25.888585: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c06b00 of size 512 next 8\n",
      "2023-11-16 03:00:25.888589: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c06d00 of size 65536 next 9\n",
      "2023-11-16 03:00:25.888595: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c16d00 of size 256 next 10\n",
      "2023-11-16 03:00:25.888599: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c16e00 of size 512 next 11\n",
      "2023-11-16 03:00:25.888602: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c17000 of size 65536 next 12\n",
      "2023-11-16 03:00:25.888606: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c27000 of size 256 next 13\n",
      "2023-11-16 03:00:25.888610: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c27100 of size 512 next 14\n",
      "2023-11-16 03:00:25.888614: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c27300 of size 1024 next 15\n",
      "2023-11-16 03:00:25.888618: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c27700 of size 256 next 16\n",
      "2023-11-16 03:00:25.888622: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c27800 of size 512 next 17\n",
      "2023-11-16 03:00:25.888628: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c27a00 of size 65536 next 18\n",
      "2023-11-16 03:00:25.888632: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c37a00 of size 256 next 19\n",
      "2023-11-16 03:00:25.888636: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c37b00 of size 512 next 20\n",
      "2023-11-16 03:00:25.888639: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c37d00 of size 65536 next 21\n",
      "2023-11-16 03:00:25.888643: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c47d00 of size 256 next 22\n",
      "2023-11-16 03:00:25.888650: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c47e00 of size 1280 next 23\n",
      "2023-11-16 03:00:25.888654: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c48300 of size 1024 next 66\n",
      "2023-11-16 03:00:25.888657: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c48700 of size 65536 next 25\n",
      "2023-11-16 03:00:25.888661: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c58700 of size 1024 next 26\n",
      "2023-11-16 03:00:25.888665: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c58b00 of size 65536 next 27\n",
      "2023-11-16 03:00:25.888669: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c68b00 of size 1024 next 28\n",
      "2023-11-16 03:00:25.888672: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c68f00 of size 65536 next 29\n",
      "2023-11-16 03:00:25.888676: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c78f00 of size 65536 next 30\n",
      "2023-11-16 03:00:25.888680: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c88f00 of size 512 next 31\n",
      "2023-11-16 03:00:25.888683: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c89100 of size 512 next 32\n",
      "2023-11-16 03:00:25.888689: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c89300 of size 512 next 33\n",
      "2023-11-16 03:00:25.888693: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c89500 of size 512 next 34\n",
      "2023-11-16 03:00:25.888697: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c89700 of size 512 next 35\n",
      "2023-11-16 03:00:25.888700: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c89900 of size 512 next 36\n",
      "2023-11-16 03:00:25.888704: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c89b00 of size 65536 next 37\n",
      "2023-11-16 03:00:25.888709: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c99b00 of size 25600 next 24\n",
      "2023-11-16 03:00:25.888712: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10c9ff00 of size 39936 next 38\n",
      "2023-11-16 03:00:25.888716: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10ca9b00 of size 65536 next 39\n",
      "2023-11-16 03:00:25.888720: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10cb9b00 of size 512 next 40\n",
      "2023-11-16 03:00:25.888724: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10cb9d00 of size 512 next 41\n",
      "2023-11-16 03:00:25.888728: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10cb9f00 of size 512 next 42\n",
      "2023-11-16 03:00:25.888731: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10cba100 of size 256 next 69\n",
      "2023-11-16 03:00:25.888735: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10cba200 of size 256 next 77\n",
      "2023-11-16 03:00:25.888739: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10cba300 of size 256 next 79\n",
      "2023-11-16 03:00:25.888742: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10cba400 of size 256 next 75\n",
      "2023-11-16 03:00:25.888746: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10cba500 of size 1024 next 80\n",
      "2023-11-16 03:00:25.888752: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10cba900 of size 512 next 81\n",
      "2023-11-16 03:00:25.888756: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10cbab00 of size 512 next 82\n",
      "2023-11-16 03:00:25.888759: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10cbad00 of size 512 next 83\n",
      "2023-11-16 03:00:25.888763: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10cbaf00 of size 512 next 84\n",
      "2023-11-16 03:00:25.888766: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10cbb100 of size 512 next 85\n",
      "2023-11-16 03:00:25.888770: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10cbb300 of size 512 next 86\n",
      "2023-11-16 03:00:25.888774: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10cbb500 of size 256 next 87\n",
      "2023-11-16 03:00:25.888777: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at b10cbb600 of size 20224 next 43\n",
      "2023-11-16 03:00:25.888781: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10cc0500 of size 65536 next 44\n",
      "2023-11-16 03:00:25.888785: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10cd0500 of size 65536 next 45\n",
      "2023-11-16 03:00:25.888789: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10ce0500 of size 512 next 46\n",
      "2023-11-16 03:00:25.888792: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10ce0700 of size 256 next 47\n",
      "2023-11-16 03:00:25.888797: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10ce0800 of size 25600 next 48\n",
      "2023-11-16 03:00:25.888801: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10ce6c00 of size 25600 next 49\n",
      "2023-11-16 03:00:25.888804: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10ced000 of size 512 next 50\n",
      "2023-11-16 03:00:25.888808: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10ced200 of size 256 next 51\n",
      "2023-11-16 03:00:25.888811: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10ced300 of size 256 next 52\n",
      "2023-11-16 03:00:25.888815: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10ced400 of size 256 next 53\n",
      "2023-11-16 03:00:25.888819: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10ced500 of size 512 next 54\n",
      "2023-11-16 03:00:25.888822: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10ced700 of size 65536 next 55\n",
      "2023-11-16 03:00:25.888826: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10cfd700 of size 256 next 56\n",
      "2023-11-16 03:00:25.888830: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10cfd800 of size 65536 next 57\n",
      "2023-11-16 03:00:25.888833: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10d0d800 of size 65536 next 58\n",
      "2023-11-16 03:00:25.888837: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10d1d800 of size 512 next 59\n",
      "2023-11-16 03:00:25.888841: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10d1da00 of size 512 next 60\n",
      "2023-11-16 03:00:25.888844: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10d1dc00 of size 512 next 61\n",
      "2023-11-16 03:00:25.888848: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10d1de00 of size 512 next 62\n",
      "2023-11-16 03:00:25.888852: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10d1e000 of size 512 next 63\n",
      "2023-11-16 03:00:25.888855: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10d1e200 of size 512 next 64\n",
      "2023-11-16 03:00:25.888859: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10d1e400 of size 65536 next 65\n",
      "2023-11-16 03:00:25.888863: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10d2e400 of size 65536 next 67\n",
      "2023-11-16 03:00:25.888866: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10d3e400 of size 65536 next 78\n",
      "2023-11-16 03:00:25.888870: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10d4e400 of size 65536 next 73\n",
      "2023-11-16 03:00:25.888873: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10d5e400 of size 65536 next 72\n",
      "2023-11-16 03:00:25.888877: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at b10d6e400 of size 596992 next 18446744073709551615\n",
      "2023-11-16 03:00:25.888881: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 4194304\n",
      "2023-11-16 03:00:25.888885: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b10e00000 of size 4194304 next 18446744073709551615\n",
      "2023-11-16 03:00:25.888889: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 67108864\n",
      "2023-11-16 03:00:25.888893: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b11200000 of size 67108864 next 18446744073709551615\n",
      "2023-11-16 03:00:25.888896: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 134217728\n",
      "2023-11-16 03:00:25.888900: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at b15200000 of size 1280000 next 74\n",
      "2023-11-16 03:00:25.888905: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at b15338800 of size 132937728 next 18446744073709551615\n",
      "2023-11-16 03:00:25.888909: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 3392143360\n",
      "2023-11-16 03:00:25.888913: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at be9c00000 of size 3392143360 next 18446744073709551615\n",
      "2023-11-16 03:00:25.888916: I tensorflow/core/common_runtime/bfc_allocator.cc:1088]      Summary of in-use Chunks by size: \n",
      "2023-11-16 03:00:25.888921: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 20 Chunks of size 256 totalling 5.0KiB\n",
      "2023-11-16 03:00:25.888926: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 30 Chunks of size 512 totalling 15.0KiB\n",
      "2023-11-16 03:00:25.888930: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 5 Chunks of size 1024 totalling 5.0KiB\n",
      "2023-11-16 03:00:25.888934: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-11-16 03:00:25.888939: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 4 Chunks of size 25600 totalling 100.0KiB\n",
      "2023-11-16 03:00:25.888943: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 39936 totalling 39.0KiB\n",
      "2023-11-16 03:00:25.888947: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 20 Chunks of size 65536 totalling 1.25MiB\n",
      "2023-11-16 03:00:25.888951: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 1280000 totalling 1.22MiB\n",
      "2023-11-16 03:00:25.888955: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 4194304 totalling 4.00MiB\n",
      "2023-11-16 03:00:25.888959: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 67108864 totalling 64.00MiB\n",
      "2023-11-16 03:00:25.888963: I tensorflow/core/common_runtime/bfc_allocator.cc:1095] Sum Total of in-use chunks: 70.63MiB\n",
      "2023-11-16 03:00:25.888967: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] total_region_allocated_bytes_: 3599761408 memory_limit_: 3599761408 available bytes: 0 curr_region_allocation_bytes_: 4294967296\n",
      "2023-11-16 03:00:25.888976: I tensorflow/core/common_runtime/bfc_allocator.cc:1103] Stats: \n",
      "Limit:                      3599761408\n",
      "InUse:                        74063104\n",
      "MaxInUse:                   2759033856\n",
      "NumAllocs:                         194\n",
      "MaxAllocSize:               2612656896\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-11-16 03:00:25.888983: W tensorflow/core/common_runtime/bfc_allocator.cc:491] ***_________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nOut of memory while trying to allocate 4590147232 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:   64.98MiB\n              constant allocation:    2.44MiB\n        maybe_live_out allocation:   285.1KiB\n     preallocated temp allocation:    4.27GiB\n  preallocated temp fragmentation:         0B (0.00%)\n                 total allocation:    4.34GiB\n              total fragmentation:    2.53MiB (0.06%)\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"MatMul\" op_name=\"gradients_2/gradients_1/dense_5/MatMul_grad/MatMul_grad/MatMul\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"MatMul\" op_name=\"gradients_2/gradients/dense_5/MatMul_grad/MatMul_grad/MatMul\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 3:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"MatMul\" op_name=\"gradients_2/gradients_1/dense_4/MatMul_grad/MatMul_grad/MatMul\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 4:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"MatMul\" op_name=\"gradients_2/gradients_1/dense_3/MatMul_grad/MatMul_grad/MatMul\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 5:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"AddN\" op_name=\"gradients_1/AddN_1\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 6:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"AddN\" op_name=\"gradients_1/AddN\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 7:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"MatMul\" op_name=\"gradients_1/gradients/dense_5/MatMul_grad/MatMul_grad/MatMul\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 8:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"MatMul\" op_name=\"gradients_1/gradients/dense_4/MatMul_grad/MatMul_grad/MatMul\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 9:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"MatMul\" op_name=\"gradients_1/gradients/dense_3/MatMul_grad/MatMul_grad/MatMul\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 10:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"MatMul\" op_name=\"gradients/dense_4/MatMul_grad/MatMul\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 11:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"MatMul\" op_name=\"gradients/dense_5/MatMul_grad/MatMul\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 12:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"BiasAdd\" op_name=\"dense_2/BiasAdd\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 13:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"Tanh\" op_name=\"dense_1/Tanh\"\n\t\tXLA Label: tanh\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 14:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"Tanh\" op_name=\"dense/Tanh\"\n\t\tXLA Label: tanh\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 15:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"Tanh\" op_name=\"dense_4/Tanh\"\n\t\tXLA Label: tanh\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\n\t [[{{node cluster_2_1/xla_run}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1377\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1360\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[0;32m-> 1360\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_tf_sessionrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1453\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_tf_sessionrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1452\u001b[0m                         run_metadata):\n\u001b[0;32m-> 1453\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1454\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1455\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Out of memory while trying to allocate 4590147232 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:   64.98MiB\n              constant allocation:    2.44MiB\n        maybe_live_out allocation:   285.1KiB\n     preallocated temp allocation:    4.27GiB\n  preallocated temp fragmentation:         0B (0.00%)\n                 total allocation:    4.34GiB\n              total fragmentation:    2.53MiB (0.06%)\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"MatMul\" op_name=\"gradients_2/gradients_1/dense_5/MatMul_grad/MatMul_grad/MatMul\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"MatMul\" op_name=\"gradients_2/gradients/dense_5/MatMul_grad/MatMul_grad/MatMul\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 3:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"MatMul\" op_name=\"gradients_2/gradients_1/dense_4/MatMul_grad/MatMul_grad/MatMul\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 4:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"MatMul\" op_name=\"gradients_2/gradients_1/dense_3/MatMul_grad/MatMul_grad/MatMul\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 5:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"AddN\" op_name=\"gradients_1/AddN_1\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 6:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"AddN\" op_name=\"gradients_1/AddN\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 7:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"MatMul\" op_name=\"gradients_1/gradients/dense_5/MatMul_grad/MatMul_grad/MatMul\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 8:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"MatMul\" op_name=\"gradients_1/gradients/dense_4/MatMul_grad/MatMul_grad/MatMul\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 9:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"MatMul\" op_name=\"gradients_1/gradients/dense_3/MatMul_grad/MatMul_grad/MatMul\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 10:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"MatMul\" op_name=\"gradients/dense_4/MatMul_grad/MatMul\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 11:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"MatMul\" op_name=\"gradients/dense_5/MatMul_grad/MatMul\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 12:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"BiasAdd\" op_name=\"dense_2/BiasAdd\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 13:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"Tanh\" op_name=\"dense_1/Tanh\"\n\t\tXLA Label: tanh\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 14:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"Tanh\" op_name=\"dense/Tanh\"\n\t\tXLA Label: tanh\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 15:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"Tanh\" op_name=\"dense_4/Tanh\"\n\t\tXLA Label: tanh\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\n\t [[{{node cluster_2_1/xla_run}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 62\u001b[0m\n\u001b[1;32m     60\u001b[0m model \u001b[38;5;241m=\u001b[39m dde\u001b[38;5;241m.\u001b[39mModel(data, net)\n\u001b[1;32m     61\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0005\u001b[39m)\n\u001b[0;32m---> 62\u001b[0m losshistory, train_state \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m dde\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mplot_loss_history(losshistory)\n\u001b[1;32m     65\u001b[0m func_feats \u001b[38;5;241m=\u001b[39m func_space\u001b[38;5;241m.\u001b[39mrandom(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/deepxde/utils/internal.py:22\u001b[0m, in \u001b[0;36mtiming.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     21\u001b[0m     ts \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mdefault_timer()\n\u001b[0;32m---> 22\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     te \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mdefault_timer()\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m took \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m s\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, te \u001b[38;5;241m-\u001b[39m ts))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/deepxde/model.py:624\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, iterations, batch_size, display_every, disregard_previous_best, callbacks, model_restore_path, model_save_path, epochs)\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m iterations \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo iterations for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt_name))\n\u001b[0;32m--> 624\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_sgd\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_every\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mon_train_end()\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/deepxde/model.py:641\u001b[0m, in \u001b[0;36mModel._train_sgd\u001b[0;34m(self, iterations, display_every)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mon_batch_begin()\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_state\u001b[38;5;241m.\u001b[39mset_data_train(\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mtrain_next_batch(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[1;32m    640\u001b[0m )\n\u001b[0;32m--> 641\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_aux_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_state\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_state\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/deepxde/model.py:534\u001b[0m, in \u001b[0;36mModel._train_step\u001b[0;34m(self, inputs, targets, auxiliary_vars)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow.compat.v1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    533\u001b[0m     feed_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet\u001b[38;5;241m.\u001b[39mfeed_dict(\u001b[38;5;28;01mTrue\u001b[39;00m, inputs, targets, auxiliary_vars)\n\u001b[0;32m--> 534\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeed_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaddle\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_step(inputs, targets, auxiliary_vars)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:967\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    964\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 967\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    969\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m    970\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1190\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[0;32m-> 1190\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1193\u001b[0m   results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1370\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1367\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1370\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1396\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124monly supports NHWC tensor format\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m message:\n\u001b[1;32m   1392\u001b[0m   message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mA possible workaround: Try disabling Grappler optimizer\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1393\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mby modifying the config for creating the session eg.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1394\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124msession_config.graph_options.rewrite_options.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1395\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisable_meta_optimizer = True\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1396\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(node_def, op, message)\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nOut of memory while trying to allocate 4590147232 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:   64.98MiB\n              constant allocation:    2.44MiB\n        maybe_live_out allocation:   285.1KiB\n     preallocated temp allocation:    4.27GiB\n  preallocated temp fragmentation:         0B (0.00%)\n                 total allocation:    4.34GiB\n              total fragmentation:    2.53MiB (0.06%)\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"MatMul\" op_name=\"gradients_2/gradients_1/dense_5/MatMul_grad/MatMul_grad/MatMul\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"MatMul\" op_name=\"gradients_2/gradients/dense_5/MatMul_grad/MatMul_grad/MatMul\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 3:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"MatMul\" op_name=\"gradients_2/gradients_1/dense_4/MatMul_grad/MatMul_grad/MatMul\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 4:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"MatMul\" op_name=\"gradients_2/gradients_1/dense_3/MatMul_grad/MatMul_grad/MatMul\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 5:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"AddN\" op_name=\"gradients_1/AddN_1\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 6:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"AddN\" op_name=\"gradients_1/AddN\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 7:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"MatMul\" op_name=\"gradients_1/gradients/dense_5/MatMul_grad/MatMul_grad/MatMul\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 8:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"MatMul\" op_name=\"gradients_1/gradients/dense_4/MatMul_grad/MatMul_grad/MatMul\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 9:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"MatMul\" op_name=\"gradients_1/gradients/dense_3/MatMul_grad/MatMul_grad/MatMul\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 10:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"MatMul\" op_name=\"gradients/dense_4/MatMul_grad/MatMul\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 11:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"MatMul\" op_name=\"gradients/dense_5/MatMul_grad/MatMul\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 12:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"BiasAdd\" op_name=\"dense_2/BiasAdd\"\n\t\tXLA Label: custom-call\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 13:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"Tanh\" op_name=\"dense_1/Tanh\"\n\t\tXLA Label: tanh\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 14:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"Tanh\" op_name=\"dense/Tanh\"\n\t\tXLA Label: tanh\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\tBuffer 15:\n\t\tSize: 156.25MiB\n\t\tOperator: op_type=\"Tanh\" op_name=\"dense_4/Tanh\"\n\t\tXLA Label: tanh\n\t\tShape: f32[320000,128]\n\t\t==========================\n\n\n\t [[{{node cluster_2_1/xla_run}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"False\"\n",
    "\n",
    "import deepxde as dde\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from ADR_solver import solve_ADR\n",
    "\n",
    "\"\"\"Solve 1D Advection-Diffusion-Reaction\n",
    "u_t = (k(x) u_x)_x - v(x) u_x + g(u) + f(x, t)\n",
    "with zero boundary condition.\n",
    "\"\"\"\n",
    "\n",
    "# PDE\n",
    "def pde(x, y, v):\n",
    "    D = 0.01\n",
    "    k = 0.01\n",
    "    dy_t = dde.grad.jacobian(y, x, j=1)\n",
    "    dy_xx = dde.grad.hessian(y, x, j=0)\n",
    "    return dy_t - D * dy_xx + k * y**2 - v\n",
    "\n",
    "\n",
    "geom = dde.geometry.Interval(0, 1)\n",
    "timedomain = dde.geometry.TimeDomain(0, 1)\n",
    "geomtime = dde.geometry.GeometryXTime(geom, timedomain)\n",
    "\n",
    "bc = dde.icbc.DirichletBC(geomtime, lambda _: 0, lambda _, on_boundary: on_boundary)\n",
    "ic = dde.icbc.IC(geomtime, lambda _: 0, lambda _, on_initial: on_initial)\n",
    "\n",
    "pde = dde.data.TimePDE(\n",
    "    geomtime,\n",
    "    pde,\n",
    "    [bc, ic],\n",
    "    num_domain=200,\n",
    "    num_boundary=40,\n",
    "    num_initial=20,\n",
    "    num_test=500,\n",
    ")\n",
    "\n",
    "# Function space\n",
    "func_space = dde.data.GRF(length_scale=0.2)\n",
    "\n",
    "# Data\n",
    "eval_pts = np.linspace(0, 1, num=50)[:, None]\n",
    "data = dde.data.PDEOperator(\n",
    "    pde, func_space, eval_pts, 1000, function_variables=[0], num_test=1000\n",
    ")\n",
    "\n",
    "# Net\n",
    "net = dde.nn.DeepONet(\n",
    "    [50, 64, 64, 64],\n",
    "    [2, 64, 64, 64],\n",
    "    \"tanh\",\n",
    "    \"Glorot normal\",\n",
    ")\n",
    "\n",
    "model = dde.Model(data, net)\n",
    "model.compile(\"adam\", lr=0.0005)\n",
    "losshistory, train_state = model.train(iterations=50000)\n",
    "dde.utils.plot_loss_history(losshistory)\n",
    "\n",
    "func_feats = func_space.random(1)\n",
    "xs = np.linspace(0, 1, num=50)[:, None]\n",
    "v = func_space.eval_batch(func_feats, xs)[0]\n",
    "x, t, u_true = solve_ADR(\n",
    "    0,\n",
    "    1,\n",
    "    0,\n",
    "    1,\n",
    "    lambda x: 0.01 * np.ones_like(x),\n",
    "    lambda x: np.zeros_like(x),\n",
    "    lambda u: 0.01 * u**2,\n",
    "    lambda u: 0.02 * u,\n",
    "    lambda x, t: np.tile(v[:, None], (1, len(t))),\n",
    "    lambda x: np.zeros_like(x),\n",
    "    100,\n",
    "    100,\n",
    ")\n",
    "u_true = u_true.T\n",
    "plt.figure()\n",
    "plt.imshow(u_true)\n",
    "plt.colorbar()\n",
    "\n",
    "v_branch = func_space.eval_batch(func_feats, np.linspace(0, 1, num=50)[:, None])[0]\n",
    "xv, tv = np.meshgrid(x, t)\n",
    "x_trunk = np.vstack((np.ravel(xv), np.ravel(tv))).T\n",
    "u_pred = model.predict((np.tile(v_branch, (100 * 100, 1)), x_trunk))\n",
    "u_pred = u_pred.reshape((100, 100))\n",
    "print(dde.metrics.l2_relative_error(u_true, u_pred))\n",
    "plt.figure()\n",
    "plt.imshow(u_pred)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fb595c-b777-4c3c-bcf6-e9d734f14ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
