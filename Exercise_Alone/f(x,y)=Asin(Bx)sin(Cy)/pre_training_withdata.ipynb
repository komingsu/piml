{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "658b908e-7e7e-4027-ab9b-2a4bc73a6c19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "import scipy\n",
    "import pyDOE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "829e1f48-13b5-40ba-9698-bab36b840f68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h=0.01\n",
    "k=0.01\n",
    "x = torch.arange(-np.pi, np.pi + h, h)\n",
    "y = torch.arange(-np.pi, np.pi + k, k)\n",
    "X = torch.stack(torch.meshgrid(x, y)).reshape(2, -1).T\n",
    "\n",
    "# u = f(x,y)=A*sin(B*x)*sin(C*y)\n",
    "A = torch.tensor([1.,])\n",
    "B = torch.tensor([1.,])\n",
    "C = torch.tensor([1.,])\n",
    "\n",
    "# training data\n",
    "bc1 = torch.stack(torch.meshgrid(x[0], y)).reshape(2, -1).T\n",
    "bc2 = torch.stack(torch.meshgrid(x[-1], y)).reshape(2, -1).T\n",
    "X_train = torch.cat([bc1, bc2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eac06acf-73aa-4d48-806d-bb3f10f063fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([630]) torch.Size([630]) torch.Size([396900, 2]) torch.Size([630, 2]) torch.Size([630, 2]) torch.Size([1260, 2])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, y.shape, X.shape, bc1.shape, bc2.shape, X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7624a70a-8f18-483a-b68e-704acbf1a3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-layer Perceptron\n",
    "class NN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,  \n",
    "        hidden_size, \n",
    "        output_size, \n",
    "        depth,\n",
    "        act=torch.nn.Tanh,\n",
    "    ):\n",
    "        super(NN, self).__init__()\n",
    "        \n",
    "        layers = [('input', torch.nn.Linear(input_size, hidden_size))]\n",
    "        layers.append(('input_activation', act()))\n",
    "        for i in range(depth): \n",
    "            layers.append(\n",
    "                (f'hidden_{i}', torch.nn.Linear(hidden_size, hidden_size))\n",
    "            )\n",
    "            layers.append((f'activation_{i}', act()))\n",
    "        layers.append(('output', torch.nn.Linear(hidden_size, output_size)))\n",
    "\n",
    "        layerDict = OrderedDict(layers)\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4d22cf-3629-4554-a0ea-9c00d11239b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net:\n",
    "    def __init__(self, A=1.0, B=1.0, C=1.0):\n",
    "        device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "        self.model = NN(\n",
    "            input_size=2,\n",
    "            hidden_size=100,\n",
    "            output_size=1,\n",
    "            depth=8,\n",
    "            act=torch.nn.Tanh\n",
    "        ).to(device)\n",
    "        \n",
    "        # 간격\n",
    "        self.h = 0.01\n",
    "        self.k = 0.01\n",
    "        # (x,y) 좌표점\n",
    "        x = torch.arange(-np.pi, np.pi + self.h, self.h)\n",
    "        y = torch.arange(-np.pi, np.pi + self.k, self.k)\n",
    "        self.X = torch.stack(torch.meshgrid(x, y)).reshape(2, -1).T\n",
    "        \n",
    "        # u = f(x,y)=A*sin(B*x)*sin(C*y)\n",
    "        self.A = torch.tensor([A,]).to(device)\n",
    "        self.B = torch.tensor([B,]).to(device)\n",
    "        self.C = torch.tensor([C,]).to(device)\n",
    "        \n",
    "        # training data\n",
    "        bc1 = torch.stack(torch.meshgrid(x[0], y)).reshape(2, -1).T\n",
    "        bc2 = torch.stack(torch.meshgrid(x[-1], y)).reshape(2, -1).T\n",
    "        self.X_train = torch.cat([bc1, bc2])\n",
    "        \n",
    "        f_bc1 = torch.zeros(len(bc1))\n",
    "        f_bc2 = torch.zeros(len(bc2))\n",
    "        self.f_train = torch.cat([f_bc1, f_bc2])\n",
    "        self.f_train = self.f_train.unsqueeze(1)\n",
    "        \n",
    "        self.X = self.X.to(device)\n",
    "        self.X_train = self.X_train.to(device)\n",
    "        self.f_train = self.f_train.to(device)\n",
    "        self.X.requires_grad = True\n",
    "        \n",
    "        self.criterion = torch.nn.MSELoss()\n",
    "        self.iter = 1\n",
    "        \n",
    "        self.optimizer = torch.optim.LBFGS(\n",
    "            self.model.parameters(), \n",
    "            lr=1.0, \n",
    "            max_iter=50000, \n",
    "            max_eval=50000, \n",
    "            history_size=5,\n",
    "            tolerance_grad=1e-13, \n",
    "            tolerance_change=1.0 * np.finfo(float).eps,\n",
    "            line_search_fn=\"strong_wolfe\",\n",
    "        )\n",
    "        self.adam = torch.optim.Adam(self.model.parameters(), lr=0.00001)\n",
    "        self.data_loss_hist = []\n",
    "        self.pde_loss_hist = []\n",
    "        self.total_loss_hist = []\n",
    "        self.print_model_state()\n",
    "        \n",
    "    # this won't use\n",
    "    def func(x,y,a=1,b=1,c=1):\n",
    "        return a*np.sin(b*x)*np.sin(c*y)\n",
    "    \n",
    "    def print_model_state(self):\n",
    "        print(\"Model's state_dict:\")\n",
    "        for param_tensor in self.model.state_dict():\n",
    "            print(param_tensor, \"\\t\", self.model.state_dict()[param_tensor].size())\n",
    "            \n",
    "    def loss_func(self):\n",
    "        \n",
    "        # 초기화\n",
    "        self.adam.zero_grad()\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        f_pred = self.model(self.X_train)\n",
    "        loss_data = self.criterion(f_pred, self.f_train)\n",
    "        u = self.model(self.X)\n",
    "\n",
    "        du_dX = torch.autograd.grad(\n",
    "            inputs=self.X, \n",
    "            outputs=u, \n",
    "            grad_outputs=torch.ones_like(u), \n",
    "            retain_graph=True, \n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        du_dx = du_dX[:, 0]\n",
    "        du_dy = du_dX[:, 1]\n",
    "        du_dXX = torch.autograd.grad(\n",
    "            inputs=self.X, \n",
    "            outputs=du_dX, \n",
    "            grad_outputs=torch.ones_like(du_dX), \n",
    "            retain_graph=True, \n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        du_dxx = du_dXX[:,0]\n",
    "        du_dyy = du_dXX[:,1]\n",
    "        \n",
    "        # u = f(x,y)=A*sin(B*x)*sin(C*y)\n",
    "        # fxx + fyy + A*(B^2+C^2)*f = 0\n",
    "        loss_pde = self.criterion( du_dxx + du_dyy , -self.A*(self.B*self.B+self.C*self.C)*u.squeeze() )\n",
    "\n",
    "        loss = loss_pde + loss_data\n",
    "        loss.backward()\n",
    "        if self.iter % 100 == 0: \n",
    "            print(f\"it :{self.iter:06}, Data Loss :{loss_data.item()},\\t PDE Loss :{loss_pde.item()}, \\t Total Loss :{loss.item()}\")\n",
    "            self.total_loss_hist.append(loss.item())\n",
    "            self.pde_loss_hist.append(loss_pde.item())\n",
    "            self.data_loss_hist.append(loss_data.item())\n",
    "        self.iter = self.iter + 1\n",
    "        return loss\n",
    "    \n",
    "    def train(self):\n",
    "        self.model.train()\n",
    "        print(\"train with Adam optimizer\")\n",
    "        for i in range(1000):\n",
    "            self.adam.step(self.loss_func)\n",
    "        print(\"train with L-BFGs\")\n",
    "        self.optimizer.step(self.loss_func)\n",
    "        \n",
    "    def eval_(self):\n",
    "        self.model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
