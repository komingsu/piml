{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_points(num_samples=100):  # 기본 샘플 수를 인자로 받음\n",
    "    # Collocation points\n",
    "    x_collocation = np.random.uniform(-1, 3, size=(num_samples * 5, 1))  # 500 -> num_samples * 5\n",
    "    y_collocation = np.random.uniform(-1, 1, size=(num_samples * 5, 1))\n",
    "    t_collocation = np.random.uniform(0, 10, size=(num_samples * 5, 1))\n",
    "    collocation_points = np.concatenate([x_collocation, y_collocation, t_collocation], axis=1)\n",
    "\n",
    "    # Boundary and initial points, 각각 num_samples로 조정\n",
    "    y_inlet = np.random.uniform(-1, 1, size=(num_samples, 1))\n",
    "    t_inlet = np.random.uniform(0, 10, size=(num_samples, 1))\n",
    "    inlet_points = np.concatenate([-np.ones((num_samples, 1)), y_inlet, t_inlet], axis=1)\n",
    "\n",
    "    y_outlet = np.random.uniform(-1, 1, size=(num_samples, 1))\n",
    "    t_outlet = np.random.uniform(0, 10, size=(num_samples, 1))\n",
    "    outlet_points = np.concatenate([3*np.ones((num_samples, 1)), y_outlet, t_outlet], axis=1)\n",
    "\n",
    "    x_wall_top = np.random.uniform(-1, 3, size=(num_samples, 1))\n",
    "    t_wall_top = np.random.uniform(0, 10, size=(num_samples, 1))\n",
    "    wall_top_points = np.concatenate([x_wall_top, np.ones((num_samples, 1)), t_wall_top], axis=1)\n",
    "\n",
    "    x_wall_bottom = np.random.uniform(-1, 3, size=(num_samples, 1))\n",
    "    t_wall_bottom = np.random.uniform(0, 10, size=(num_samples, 1))\n",
    "    wall_bottom_points = np.concatenate([x_wall_bottom, -np.ones((num_samples, 1)), t_wall_bottom], axis=1)\n",
    "\n",
    "    x_initial = np.random.uniform(-1, 3, size=(num_samples, 1))\n",
    "    y_initial = np.random.uniform(-1, 1, size=(num_samples, 1))\n",
    "    initial_points = np.concatenate([x_initial, y_initial, np.zeros((num_samples, 1))], axis=1)\n",
    "\n",
    "    return collocation_points, inlet_points, outlet_points, wall_top_points, wall_bottom_points, initial_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDE Loss: 0.0061466386541724205\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Define the neural network for u, v, and p\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(PINN, self).__init__()\n",
    "        # 중간 레이어\n",
    "        self.middle_layers = nn.ModuleList()\n",
    "        for i in range(len(layers)-2):\n",
    "            self.middle_layers.append(nn.Linear(layers[i], layers[i+1]))\n",
    "            self.middle_layers.append(nn.Tanh())\n",
    "        \n",
    "        # 마지막 레이어를 분리하여 u, v와 p를 각각 예측\n",
    "        self.last_layer_uv = nn.Linear(layers[-2], 2) # u와 v를 위한 레이어\n",
    "        self.last_layer_p = nn.Linear(layers[-2], 1) # p를 위한 레이어\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.middle_layers:\n",
    "            x = layer(x)\n",
    "        u_v = self.last_layer_uv(x)\n",
    "        p = self.last_layer_p(x)\n",
    "        return u_v, p\n",
    "\n",
    "\n",
    "def compute_pde_loss(model, inputs, nu):\n",
    "    inputs.requires_grad_(True)\n",
    "    u_v, p = model(inputs)\n",
    "    u = u_v[:, 0].unsqueeze(1)\n",
    "    v = u_v[:, 1].unsqueeze(1)\n",
    "    \n",
    "    # Compute gradients\n",
    "    ones = torch.ones_like(u)\n",
    "    u_x = torch.autograd.grad(u, inputs, grad_outputs=ones, create_graph=True)[0][:, 0].unsqueeze(1)\n",
    "    u_y = torch.autograd.grad(u, inputs, grad_outputs=ones, create_graph=True)[0][:, 1].unsqueeze(1)\n",
    "    u_t = torch.autograd.grad(u, inputs, grad_outputs=ones, create_graph=True)[0][:, 2].unsqueeze(1)\n",
    "    \n",
    "    v_x = torch.autograd.grad(v, inputs, grad_outputs=ones, create_graph=True)[0][:, 0].unsqueeze(1)\n",
    "    v_y = torch.autograd.grad(v, inputs, grad_outputs=ones, create_graph=True)[0][:, 1].unsqueeze(1)\n",
    "    v_t = torch.autograd.grad(v, inputs, grad_outputs=ones, create_graph=True)[0][:, 2].unsqueeze(1)\n",
    "    \n",
    "    p_x = torch.autograd.grad(p, inputs, grad_outputs=ones, create_graph=True)[0][:, 0].unsqueeze(1)\n",
    "    p_y = torch.autograd.grad(p, inputs, grad_outputs=ones, create_graph=True)[0][:, 1].unsqueeze(1)\n",
    "    \n",
    "    # Navier-Stokes equations\n",
    "    continuity_eq = u_x + v_y\n",
    "    u_momentum_eq = u_t + u*u_x + v*u_y + p_x - nu*(torch.autograd.grad(u_x, inputs, grad_outputs=ones, create_graph=True)[0][:, 0].unsqueeze(1) + torch.autograd.grad(u_y, inputs, grad_outputs=ones, create_graph=True)[0][:, 1].unsqueeze(1))\n",
    "    v_momentum_eq = v_t + u*v_x + v*v_y + p_y - nu*(torch.autograd.grad(v_x, inputs, grad_outputs=ones, create_graph=True)[0][:, 0].unsqueeze(1) + torch.autograd.grad(v_y, inputs, grad_outputs=ones, create_graph=True)[0][:, 1].unsqueeze(1))\n",
    "    \n",
    "    # PDE loss\n",
    "    pde_loss = torch.mean(continuity_eq**2) + torch.mean(u_momentum_eq**2) + torch.mean(v_momentum_eq**2)\n",
    "    return pde_loss\n",
    "\n",
    "def compute_bc_loss(model, inlet_points, outlet_points, wall_top_points, wall_bottom_points):\n",
    "    # Inlet condition: u = 1, v = 0\n",
    "    inlet_u_v, _ = model(torch.tensor(inlet_points, dtype=torch.float32))\n",
    "    inlet_loss = torch.mean((inlet_u_v[:, 0] - 1) ** 2) + torch.mean(inlet_u_v[:, 1] ** 2)\n",
    "\n",
    "    # Outlet condition: p = 0 (Assuming model returns u, v, and p separately)\n",
    "    _, outlet_p = model(torch.tensor(outlet_points, dtype=torch.float32))\n",
    "    outlet_loss = torch.mean(outlet_p ** 2)\n",
    "\n",
    "    # No-slip wall condition: u = v = 0\n",
    "    wall_top_u_v, _ = model(torch.tensor(wall_top_points, dtype=torch.float32))\n",
    "    wall_bottom_u_v, _ = model(torch.tensor(wall_bottom_points, dtype=torch.float32))\n",
    "    wall_loss = torch.mean(wall_top_u_v ** 2) + torch.mean(wall_bottom_u_v ** 2)\n",
    "\n",
    "    # Total BC loss\n",
    "    bc_loss = inlet_loss + outlet_loss + wall_loss\n",
    "    return bc_loss\n",
    "\n",
    "def compute_ic_loss(model, initial_points):\n",
    "    \"\"\"\n",
    "    Compute the initial condition loss.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The PINN model.\n",
    "    - initial_points: Tensor of input values at the initial time (x, y, t=0).\n",
    "    \n",
    "    Returns:\n",
    "    - ic_loss: The computed initial condition loss.\n",
    "    \"\"\"\n",
    "    # 모델을 통해 초기 포인트에 대한 예측을 수행합니다.\n",
    "    predicted_initial_u_v, _ = model(torch.tensor(initial_points, dtype=torch.float32))\n",
    "    \n",
    "    # 초기 조건에 대한 loss를 계산합니다. 여기서는 inlet 조건에 따라 u = 1, v = 0을 사용합니다.\n",
    "    # 실제 초기 조건이 다르다면 이 부분을 조정해야 합니다.\n",
    "    ic_loss = torch.mean((predicted_initial_u_v[:, 0] - 1) ** 2) + torch.mean(predicted_initial_u_v[:, 1] ** 2)\n",
    "    \n",
    "    return ic_loss\n",
    "\n",
    "\n",
    "# Example usage\n",
    "layers = [3, 50, 50, 50, 2] # The input layer includes x, y, t, and the output layer includes u, v, and p\n",
    "model = PINN(layers=layers)\n",
    "nu = 0.01 # Viscosity, example value\n",
    "\n",
    "# Define inputs (x, y, t)\n",
    "inputs = torch.rand(100, 3, requires_grad=True) # Example inputs\n",
    "\n",
    "# Compute PDE loss\n",
    "pde_loss = compute_pde_loss(model, inputs, nu)\n",
    "print(f\"PDE Loss: {pde_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3) (10000, 3) (10000, 3) (10000, 3) (10000, 3) (10000, 3)\n"
     ]
    }
   ],
   "source": [
    "collocation_points, inlet_points, outlet_points, wall_top_points, wall_bottom_points, initial_points = generate_points(10000)\n",
    "print(collocation_points.shape, inlet_points.shape, outlet_points.shape, wall_top_points.shape, wall_bottom_points.shape, initial_points.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10000\n",
    "collocation_points_tensor = torch.tensor(collocation_points, dtype=torch.float32)\n",
    "inlet_points_tensor = torch.tensor(inlet_points, dtype=torch.float32)\n",
    "outlet_points_tensor = torch.tensor(outlet_points, dtype=torch.float32)\n",
    "wall_top_points_tensor = torch.tensor(wall_top_points, dtype=torch.float32)\n",
    "wall_bottom_points_tensor = torch.tensor(wall_bottom_points, dtype=torch.float32)\n",
    "initial_points_tensor = torch.tensor(initial_points, dtype=torch.float32)\n",
    "\n",
    "collocation_loader = DataLoader(collocation_points_tensor, batch_size=BATCH_SIZE, shuffle=True)\n",
    "inlet_loader = DataLoader(inlet_points_tensor, batch_size=BATCH_SIZE, shuffle=True)\n",
    "outlet_loader = DataLoader(outlet_points_tensor, batch_size=BATCH_SIZE, shuffle=True)\n",
    "wall_top_loader = DataLoader(wall_top_points_tensor, batch_size=BATCH_SIZE, shuffle=True)\n",
    "wall_bottom_loader = DataLoader(wall_bottom_points_tensor, batch_size=BATCH_SIZE, shuffle=True)\n",
    "initial_loader = DataLoader(initial_points_tensor, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가정: optimizer, model, total_epochs 등이 이미 정의되어 있음\n",
    "total_epochs = 100\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # PDE Loss 계산\n",
    "    pde_loss = compute_pde_loss(model, collocation_points, nu)\n",
    "    \n",
    "    # BC Loss 계산\n",
    "    bc_loss = compute_bc_loss(model, inlet_points, outlet_points, wall_top_points, wall_bottom_points)\n",
    "    \n",
    "    # IC Loss 계산\n",
    "    ic_loss = compute_ic_loss(model, initial_points)\n",
    "    \n",
    "    # Total Loss\n",
    "    total_loss = pde_loss + bc_loss + ic_loss\n",
    "    \n",
    "    # Backpropagation and optimization\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Total Loss: {total_loss.item()}, PDE Loss: {pde_loss.item()}, BC Loss: {bc_loss.item()}, IC Loss: {ic_loss.item()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
