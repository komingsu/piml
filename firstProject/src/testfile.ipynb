{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class Network:\n",
    "    \"\"\"\n",
    "    Build a physics informed neural network (PINN) model for the steady Navier-Stokes equations.\n",
    "    Attributes:\n",
    "        activations: custom activation functions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Setup custom activation functions.\n",
    "        \"\"\"\n",
    "        self.activations = {\n",
    "            'tanh' : 'tanh',\n",
    "            'swish': self.swish,\n",
    "            'mish' : self.mish,\n",
    "        }\n",
    "    # Examples of other activation functions:\n",
    "    def swish(self, x):\n",
    "        \"\"\"\n",
    "        Swish activation function.\n",
    "        Args:\n",
    "            x: activation input.\n",
    "        Returns:\n",
    "            Swish output.\n",
    "        \"\"\"\n",
    "        return x * tf.math.sigmoid(x)\n",
    "\n",
    "    def mish(self, x):\n",
    "        \"\"\"\n",
    "        Mish activation function.\n",
    "        Args:\n",
    "            x: activation input.\n",
    "        Returns:\n",
    "            Mish output.\n",
    "        \"\"\"\n",
    "        return x * tf.math.tanh(tf.softplus(x))\n",
    "\n",
    "    def build(self, num_inputs=2, layers=[48,48,48,48], activation='tanh', num_outputs=3):\n",
    "        \"\"\"\n",
    "        Build a PINN model for the steady Navier-Stokes equation with input shape (x,y) and output shape (u, v, p).\n",
    "        Args:\n",
    "            num_inputs: number of input variables. Default is 2 for (x, y).\n",
    "            layers: number of hidden layers.\n",
    "            activation: activation function in hidden layers.\n",
    "            num_outpus: number of output variables. Default is 3 for (u, v, p).\n",
    "        Returns:\n",
    "            keras network model\n",
    "        \"\"\"\n",
    "\n",
    "        # input layer\n",
    "        inputs = tf.keras.layers.Input(shape=(num_inputs,))\n",
    "        # hidden layers\n",
    "        x = inputs\n",
    "        for layer in layers:\n",
    "            x = tf.keras.layers.Dense(layer, activation=self.activations[activation],\n",
    "                kernel_initializer='he_normal')(x)\n",
    "        # output layer\n",
    "        outputs = tf.keras.layers.Dense(num_outputs,\n",
    "            kernel_initializer='he_normal')(x)\n",
    "\n",
    "        return tf.keras.models.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class GradientLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Custom layer to compute derivatives for the steady Navier-Stokes equation.\n",
    "    Attributes:\n",
    "        model: keras network model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model: keras network model.\n",
    "        \"\"\"\n",
    "\n",
    "        self.model = model\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, xyt):\n",
    "        \"\"\"\n",
    "        Computing derivatives for the steady Navier-Stokes equation.\n",
    "        Args:\n",
    "            xy: input variable.\n",
    "        Returns:\n",
    "            psi: stream function.\n",
    "            p_grads: pressure and its gradients.\n",
    "            u_grads: u and its gradients.\n",
    "            v_grads: v and its gradients.\n",
    "        \"\"\"\n",
    "\n",
    "        x, y = [ xyt[..., i, tf.newaxis] for i in range(xyt.shape[-1]) ]\n",
    "        with tf.GradientTape(persistent=True) as ggg:\n",
    "            ggg.watch(x)\n",
    "            ggg.watch(y)\n",
    "\n",
    "            with tf.GradientTape(persistent=True) as gg:\n",
    "                gg.watch(x)\n",
    "                gg.watch(y)\n",
    "\n",
    "                with tf.GradientTape(persistent=True) as g:\n",
    "                    g.watch(x)\n",
    "                    g.watch(y)\n",
    "\n",
    "                    u_v_p = self.model(tf.concat([x, y], axis=-1))\n",
    "                    u = u_v_p[..., 0, tf.newaxis]\n",
    "                    v = u_v_p[..., 1, tf.newaxis]\n",
    "                    p = u_v_p[..., 2, tf.newaxis]\n",
    "                u_x = g.batch_jacobian(u, x)[..., 0]\n",
    "                v_x = g.batch_jacobian(v, x)[..., 0]\n",
    "                u_y = g.batch_jacobian(u, y)[..., 0]\n",
    "                v_y = g.batch_jacobian(v, y)[..., 0]\n",
    "                p_x = g.batch_jacobian(p, x)[..., 0]\n",
    "                p_y = g.batch_jacobian(p, y)[..., 0]\n",
    "\n",
    "                del g\n",
    "            u_xx = gg.batch_jacobian(u_x, x)[..., 0]\n",
    "            u_yy = gg.batch_jacobian(u_y, y)[..., 0]\n",
    "\n",
    "            v_xx = gg.batch_jacobian(v_x, x)[..., 0]\n",
    "            v_yy = gg.batch_jacobian(v_y, y)[..., 0]\n",
    "\n",
    "            del gg\n",
    "        # if more derivatives are required...\n",
    "        del ggg\n",
    "\n",
    "        p_grads = p, p_x, p_y\n",
    "        u_grads = u, u_x, u_y, u_xx, u_yy\n",
    "        v_grads = v, v_x, v_y, v_xx, v_yy\n",
    "\n",
    "        return p_grads, u_grads, v_grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class L_BFGS_B:\n",
    "    \"\"\"\n",
    "    Optimize the keras network model using L-BFGS-B algorithm.\n",
    "    Attributes:\n",
    "        model: optimization target model.\n",
    "        samples: training samples.\n",
    "        factr: function convergence condition. typical values for factr are: 1e12 for low accuracy;\n",
    "               1e7 for moderate accuracy; 10.0 for extremely high accuracy.\n",
    "        pgtol: gradient convergence condition.\n",
    "        m: maximum number of variable metric corrections used to define the limited memory matrix.\n",
    "        maxls: maximum number of line search steps (per iteration).\n",
    "        maxiter: maximum number of iterations.\n",
    "        metris: log metrics\n",
    "        progbar: progress bar\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, x_train, y_train, factr=1e5, m=50, maxls=50, maxiter=30000):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model: optimization target model.\n",
    "            samples: training samples.\n",
    "            factr: convergence condition. typical values for factr are: 1e12 for low accuracy;\n",
    "                   1e7 for moderate accuracy; 10.0 for extremely high accuracy.\n",
    "            pgtol: gradient convergence condition.\n",
    "            m: maximum number of variable metric corrections used to define the limited memory matrix.\n",
    "            maxls: maximum number of line search steps (per iteration).\n",
    "            maxiter: maximum number of iterations.\n",
    "        \"\"\"\n",
    "\n",
    "        # set attributes\n",
    "        self.model = model\n",
    "        self.x_train = [ tf.constant(x, dtype=tf.float32) for x in x_train ]\n",
    "        self.y_train = [ tf.constant(y, dtype=tf.float32) for y in y_train ]\n",
    "        self.factr = factr\n",
    "        self.m = m\n",
    "        self.maxls = maxls\n",
    "        self.maxiter = maxiter\n",
    "        self.metrics = ['loss']\n",
    "        # initialize the progress bar\n",
    "        self.progbar = tf.keras.callbacks.ProgbarLogger(\n",
    "            count_mode='steps', stateful_metrics=self.metrics)\n",
    "        self.progbar.set_params( {\n",
    "            'verbose':1, 'epochs':1, 'steps':self.maxiter, 'metrics':self.metrics})\n",
    "\n",
    "    def set_weights(self, flat_weights):\n",
    "        \"\"\"\n",
    "        Set weights to the model.\n",
    "        Args:\n",
    "            flat_weights: flatten weights.\n",
    "        \"\"\"\n",
    "\n",
    "        # get model weights\n",
    "        shapes = [ w.shape for w in self.model.get_weights() ]\n",
    "        # compute splitting indices\n",
    "        split_ids = np.cumsum([ np.prod(shape) for shape in [0] + shapes ])\n",
    "        # reshape weights\n",
    "        weights = [ flat_weights[from_id:to_id].reshape(shape)\n",
    "            for from_id, to_id, shape in zip(split_ids[:-1], split_ids[1:], shapes) ]\n",
    "        # set weights to the model\n",
    "        self.model.set_weights(weights)\n",
    "\n",
    "    @tf.function\n",
    "    def tf_evaluate(self, x, y):\n",
    "        \"\"\"\n",
    "        Evaluate loss and gradients for weights as tf.Tensor.\n",
    "        Args:\n",
    "            x: input data.\n",
    "        Returns:\n",
    "            loss and gradients for weights as tf.Tensor.\n",
    "        \"\"\"\n",
    "\n",
    "        with tf.GradientTape() as g:\n",
    "            loss = tf.reduce_mean(tf.keras.losses.logcosh(self.model(x), y))\n",
    "        grads = g.gradient(loss, self.model.trainable_variables)\n",
    "        return loss, grads\n",
    "\n",
    "    def evaluate(self, weights):\n",
    "        \"\"\"\n",
    "        Evaluate loss and gradients for weights as ndarray.\n",
    "        Args:\n",
    "            weights: flatten weights.\n",
    "        Returns:\n",
    "            loss and gradients for weights as ndarray.\n",
    "        \"\"\"\n",
    "\n",
    "        # update weights\n",
    "        self.set_weights(weights)\n",
    "        # compute loss and gradients for weights\n",
    "        loss, grads = self.tf_evaluate(self.x_train, self.y_train)\n",
    "        # convert tf.Tensor to flatten ndarray\n",
    "        loss = loss.numpy().astype('float64')\n",
    "        grads = np.concatenate([ g.numpy().flatten() for g in grads ]).astype('float64')\n",
    "\n",
    "        return loss, grads\n",
    "\n",
    "    def callback(self, weights):\n",
    "        \"\"\"\n",
    "        Callback that prints the progress to stdout.\n",
    "        Args:\n",
    "            weights: flatten weights.\n",
    "        \"\"\"\n",
    "        self.progbar.on_batch_begin(0)\n",
    "        loss, _ = self.evaluate(weights)\n",
    "        self.progbar.on_batch_end(0, logs=dict(zip(self.metrics, [loss])))\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Train the model using L-BFGS-B algorithm.\n",
    "        \"\"\"\n",
    "\n",
    "        # get initial weights as a flat vector\n",
    "        initial_weights = np.concatenate(\n",
    "            [ w.flatten() for w in self.model.get_weights() ])\n",
    "        # optimize the weight vector\n",
    "        print('Optimizer: L-BFGS-B (maxiter={})'.format(self.maxiter))\n",
    "        self.progbar.on_train_begin()\n",
    "        self.progbar.on_epoch_begin(1)\n",
    "        scipy.optimize.fmin_l_bfgs_b(func=self.evaluate, x0=initial_weights,\n",
    "            factr=self.factr, m=self.m,\n",
    "            maxls=self.maxls, maxiter=self.maxiter, callback=self.callback)\n",
    "        self.progbar.on_epoch_end(1)\n",
    "        self.progbar.on_train_end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class PINN:\n",
    "    \"\"\"\n",
    "    Build a physics informed neural network (PINN) model for the steady Navier-Stokes equation.\n",
    "    Attributes:\n",
    "        network: keras network model with input (x, y) and output (u, v, p).\n",
    "        rho: density.\n",
    "        nu: viscosity.\n",
    "        grads: gradient layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, network, rho=1, mu=0.01):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            network: keras network model with input (x, y) and output (u, v, p).\n",
    "            rho: density.\n",
    "            nu: viscosity.\n",
    "        \"\"\"\n",
    "\n",
    "        self.network = network\n",
    "        self.rho = rho\n",
    "        self.mu = mu\n",
    "        self.grads = GradientLayer(self.network)\n",
    "\n",
    "    def build(self):\n",
    "        \"\"\"\n",
    "        Build a PINN model for the steady Navier-Stokes equation.\n",
    "        Returns:\n",
    "            PINN model for the steady Navier-Stokes equation with\n",
    "                input: [ (x, y) relative to equation,\n",
    "                         (x, y) relative to boundary condition ],\n",
    "                output: [ (u, v) relative to equation (must be zero),\n",
    "                          (psi, psi) relative to boundary condition (psi is duplicated because outputs require the same dimensions),\n",
    "                          (u, v) relative to boundary condition ]\n",
    "        \"\"\"\n",
    "\n",
    "        # equation input: (x, y)\n",
    "        xy_eqn = tf.keras.layers.Input(shape=(2,))\n",
    "        # boundary condition\n",
    "        xy_in = tf.keras.layers.Input(shape=(2,))\n",
    "        xy_out = tf.keras.layers.Input(shape=(2,))\n",
    "        xy_w1 = tf.keras.layers.Input(shape=(2,))\n",
    "        xy_w2 = tf.keras.layers.Input(shape=(2,))\n",
    "        xy_circle = tf.keras.layers.Input(shape=(2,))\n",
    "\n",
    "        # compute gradients relative to equation\n",
    "        p_grads, u_grads, v_grads = self.grads(xy_eqn)\n",
    "        _, p_x, p_y = p_grads\n",
    "        u, u_x, u_y, u_xx, u_yy = u_grads\n",
    "        v, v_x, v_y, v_xx, v_yy = v_grads\n",
    "        # compute equation loss\n",
    "        u_eqn =  u*u_x + v*u_y + p_x/self.rho - self.mu*(u_xx + u_yy) / self.rho\n",
    "        v_eqn =  u*v_x + v*v_y + p_y/self.rho - self.mu*(v_xx + v_yy) / self.rho\n",
    "        uv_eqn = u_x + v_y\n",
    "        uv_eqn = tf.concat([u_eqn, v_eqn, uv_eqn], axis=-1)\n",
    "\n",
    "        # compute gradients relative to boundary condition\n",
    "        p_r, u_grads_r, v_grads_r = self.grads(xy_out)\n",
    "        uv_out = tf.concat([p_r[0], p_r[0], p_r[0]], axis=-1)\n",
    "\n",
    "        p_l, u_grads_l, v_grads_l = self.grads(xy_w1)\n",
    "        uv_w1 = tf.concat([u_grads_l[0], v_grads_l[0], p_l[2]], axis=-1)\n",
    "        \n",
    "        p_l, u_grads_l, v_grads_l = self.grads(xy_w2)\n",
    "        uv_w2 = tf.concat([u_grads_l[0], v_grads_l[0], p_l[2]], axis=-1)\n",
    "        \n",
    "        p_l, u_grads_l, v_grads_l = self.grads(xy_circle)\n",
    "        uv_circle = tf.concat([u_grads_l[0], v_grads_l[0], u_grads_l[0]], axis=-1)\n",
    "\n",
    "        p_inn, u_inn, v_inn = self.grads(xy_in)\n",
    "        uv_in = tf.concat([u_inn[0], v_inn[0], u_inn[0]], axis=-1)\n",
    "\n",
    "        # build the PINN model for the steady Navier-Stokes equation\n",
    "        return tf.keras.models.Model(\n",
    "            inputs=[xy_eqn, xy_w1, xy_w2, xy_out, xy_in, xy_circle], outputs=[uv_eqn, uv_in, uv_out, uv_w1, uv_w2, uv_circle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf_silent\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from pinn import PINN\n",
    "from network import Network\n",
    "from optimizer import L_BFGS_B\n",
    "\n",
    "\n",
    "\n",
    "def mass_cons(network, xy):\n",
    "    \"\"\"\n",
    "    Compute u_x and v_y\n",
    "    Args:\n",
    "        xy: network input variables as ndarray.\n",
    "    Returns:\n",
    "        (u_x, v_y) as ndarray.\n",
    "    \"\"\"\n",
    "\n",
    "    xy = tf.constant(xy)\n",
    "    x, y = [ xy[..., i, tf.newaxis] for i in range(xy.shape[-1]) ]\n",
    "    with tf.GradientTape(persistent=True) as g:\n",
    "      g.watch(x)\n",
    "      g.watch(y)\n",
    "\n",
    "      u_v_p = network(tf.concat([x, y], axis=-1))\n",
    "      u = u_v_p[..., 0, tf.newaxis]\n",
    "      v = u_v_p[..., 1, tf.newaxis]\n",
    "      p = u_v_p[..., 2, tf.newaxis]\n",
    "    u_x = g.batch_jacobian(u, x)[..., 0]\n",
    "    v_y = g.batch_jacobian(v, y)[..., 0]\n",
    "\n",
    "    return u_x.numpy(), v_y.numpy()\n",
    "\n",
    "def u_0(xy):\n",
    "    \"\"\"\n",
    "    Initial wave form.\n",
    "    Args:\n",
    "        tx: variables (t, x) as tf.Tensor.\n",
    "    Returns:\n",
    "        u(t, x) as tf.Tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    x = xy[..., 0, None]\n",
    "    y = xy[..., 1, None]\n",
    "\n",
    "\n",
    "    return    4*y*(1 - y) \n",
    "\n",
    "\n",
    "def contour(x, y, z, title, levels=100):\n",
    "    \"\"\"\n",
    "    Contour plot.\n",
    "    Args:\n",
    "        grid: plot position.\n",
    "        x: x-array.\n",
    "        y: y-array.\n",
    "        z: z-array.\n",
    "        title: title string.\n",
    "        levels: number of contour lines.\n",
    "    \"\"\"\n",
    "\n",
    "    # get the value range\n",
    "    vmin = np.min(z)\n",
    "    vmax = np.max(z)\n",
    "    # plot a contour\n",
    "    font1 = {'family':'serif','size':20}\n",
    "    plt.contour(x, y, z, colors='k', linewidths=0.2, levels=levels)\n",
    "    plt.contourf(x, y, z, cmap='rainbow', levels=levels, norm=Normalize(vmin=vmin, vmax=vmax))\n",
    "    plt.axes()\n",
    "    circle = plt.Circle((0.5,0.5),0.1, fc='black')\n",
    "    plt.gca().add_patch(circle)\n",
    "    plt.axis('scaled')\n",
    "    plt.title(title, fontdict = font1)\n",
    "    plt.xlabel(\"x\", fontdict = font1)\n",
    "    plt.ylabel(\"y\", fontdict = font1)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "\n",
    "    cbar = plt.colorbar(pad=0.03, aspect=25, format='%.0e')\n",
    "    cbar.mappable.set_clim(vmin, vmax)\n",
    "    cbar.ax.tick_params(labelsize=15)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \"\"\"\n",
    "    Test the physics informed neural network (PINN) model\n",
    "    for the cavity flow governed by the steady Navier-Stokes equation.\n",
    "    \"\"\"\n",
    "\n",
    "    # number of training samples\n",
    "    num_train_samples = 5000\n",
    "    # number of test samples\n",
    "    num_test_samples = 200\n",
    "\n",
    "    # inlet flow velocity\n",
    "    u0 = 1\n",
    "    # density\n",
    "    rho = 1\n",
    "    # viscosity\n",
    "    mu = 1e-1\n",
    "    # Re = rho/mu\n",
    "\n",
    "    # build a core network model\n",
    "    network = Network().build()\n",
    "    network.summary()\n",
    "    # build a PINN model\n",
    "    pinn = PINN(network, rho=rho, mu=mu).build()\n",
    "\n",
    "    # Domain and circle data\n",
    "    x_f =2\n",
    "    x_ini=0\n",
    "    y_f=1\n",
    "    y_ini=0\n",
    "    Cx = 0.5\n",
    "    Cy = 0.5\n",
    "    a = 0.1\n",
    "    b = 0.1\n",
    "\n",
    "    xyt_circle = np.random.rand(num_train_samples, 2)\n",
    "    xyt_circle[...,0] = 2*(a)*xyt_circle[...,0] +(Cx-a)\n",
    "    xyt_circle[0:num_train_samples//2,1] = b*(1 - (xyt_circle[0:num_train_samples//2,0]-Cx)**2 / a**2)**0.5 + Cy\n",
    "    xyt_circle[num_train_samples//2:,1] = -b*(1 - (xyt_circle[num_train_samples//2:,0]-Cx)**2 / a**2)**0.5 + Cy\n",
    "\n",
    "    # create training input\n",
    "    xyt_eqn = np.random.rand(num_train_samples, 2)\n",
    "    xyt_eqn[...,0] = (x_f - x_ini)*xyt_eqn[...,0] + x_ini\n",
    "    xyt_eqn[...,1] = (y_f - y_ini)*xyt_eqn[...,1] + y_ini\n",
    "\n",
    "    for i in range(num_train_samples):\n",
    "      while (xyt_eqn[i, 0] - Cx)**2/a**2 + (xyt_eqn[i, 1] - Cy)**2/b**2 < 1:\n",
    "        xyt_eqn[i, 0] = (x_f - x_ini) * np.random.rand(1, 1) + x_ini\n",
    "        xyt_eqn[i, 1] = (y_f - y_ini) * np.random.rand(1, 1) + y_ini\n",
    "\n",
    "    xyt_w1 = np.random.rand(num_train_samples, 2)  # top-bottom boundaries\n",
    "    xyt_w1[..., 0] = (x_f - x_ini)*xyt_w1[...,0] + x_ini\n",
    "    xyt_w1[..., 1] =  y_ini          # y-position is 0 or 1\n",
    "\n",
    "    xyt_w2 = np.random.rand(num_train_samples, 2)  # top-bottom boundaries\n",
    "    xyt_w2[..., 0] = (x_f - x_ini)*xyt_w2[...,0] + x_ini\n",
    "    xyt_w2[..., 1] =  y_f\n",
    "\n",
    "    xyt_out = np.random.rand(num_train_samples, 2)  # left-right boundaries\n",
    "    xyt_out[..., 0] = x_f\n",
    "\n",
    "    xyt_in = np.random.rand(num_train_samples, 2)\n",
    "    xyt_in[...,0] = x_ini\n",
    "\n",
    "    x_train = [xyt_eqn, xyt_w1, xyt_w2, xyt_out, xyt_in, xyt_circle]\n",
    "\n",
    "    # create training output\n",
    "    zeros = np.zeros((num_train_samples, 3))\n",
    "    #uv_bnd[..., 0] = -u0 * np.floor(xy_bnd[..., 0]) +1\n",
    "    #ones = np.ones((num_train_samples, 3))\n",
    "    #onze = np.random.rand(num_train_samples, 3)\n",
    "    #onze[...,0] = u0\n",
    "    #onze[...,1] = 0\n",
    "    #onze[...,2] = u0\n",
    "    a = u_0(tf.constant(xyt_in)).numpy()\n",
    "    b = np.zeros((num_train_samples, 1))\n",
    "    onze = np.random.permutation(np.concatenate([a,b,a],axis = -1))\n",
    "\n",
    "    y_train = [zeros, onze, zeros, zeros, zeros, zeros]\n",
    "\n",
    "    # train the model using L-BFGS-B algorithm\n",
    "    lbfgs = L_BFGS_B(model=pinn, x_train=x_train, y_train=y_train)\n",
    "    lbfgs.fit()\n",
    "\n",
    "    # create meshgrid coordinates (x, y) for test plots    \n",
    "\n",
    "    x = np.linspace(x_ini, x_f, num_test_samples)\n",
    "    y = np.linspace(y_ini, y_f, num_test_samples)\n",
    "    x, y = np.meshgrid(x, y)\n",
    "    xy = np.stack([x.flatten(), y.flatten()], axis=-1)\n",
    "    # predict (psi, p)\n",
    "    u_v_p = network.predict(xy, batch_size=len(xy))\n",
    "    u, v, p = [ u_v_p[..., i].reshape(x.shape) for i in range(u_v_p.shape[-1]) ]\n",
    "    # compute (u, v)\n",
    "    u = u.reshape(x.shape)\n",
    "    v = v.reshape(x.shape)\n",
    "    p = p.reshape(x.shape)\n",
    "    # plot test results\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    contour(x, y, p, 'p')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    contour(x, y, u, 'u')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    contour(x, y, v, 'v')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    ###########################\n",
    "    from matplotlib.patches import Circle\n",
    "    font1 = {'family':'serif','size':20}\n",
    "\n",
    "    fig0, ax0 = plt.subplots(1, 1,figsize=(20,8))\n",
    "    cf0 = ax0.contourf(x, y, p, np.arange(-0.2, 1, .02),\n",
    "                   extend='both',cmap='rainbow')\n",
    "    cbar0 = plt.colorbar(cf0, pad=0.03, aspect=25, format='%.0e')\n",
    "    plt.title(\"p\", fontdict = font1)\n",
    "    plt.xlabel(\"x\", fontdict = font1)\n",
    "    plt.ylabel(\"y\", fontdict = font1)\n",
    "    ax0.add_patch(Circle((0.5, 0.5), 0.1,color=\"black\"))\n",
    "    plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "    cbar0.ax.tick_params(labelsize=15)\n",
    "    plt.show()\n",
    "\n",
    "    ###########################\n",
    "\n",
    "    fig0, ax0 = plt.subplots(1, 1, figsize=(20,8))\n",
    "    cf0 = ax0.contourf(x, y, u, np.arange(-0.5, 1.1, .02),\n",
    "                   extend='both',cmap='rainbow')\n",
    "    cbar0 = plt.colorbar(cf0, )\n",
    "    plt.title(\"u\", fontdict = font1)\n",
    "    plt.xlabel(\"x\", fontdict = font1)\n",
    "    plt.ylabel(\"y\", fontdict = font1)\n",
    "    ax0.add_patch(Circle((0.5, 0.5), 0.1,color=\"black\"))\n",
    "    plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "    cbar0.ax.tick_params(labelsize=15)\n",
    "    plt.show()\n",
    "\n",
    "    ###########################\n",
    "\n",
    "    fig0, ax0 = plt.subplots(1, 1,figsize=(20,8))\n",
    "    cf0 = ax0.contourf(x, y, v, np.arange(-0.4, 0.4, .02),\n",
    "                   extend='both',cmap='rainbow')\n",
    "    cbar0 = plt.colorbar(cf0, pad=0.03, aspect=25, format='%.0e')\n",
    "    plt.title(\"v\", fontdict = font1)\n",
    "    plt.xlabel(\"x\", fontdict = font1)\n",
    "    plt.ylabel(\"y\", fontdict = font1)\n",
    "    ax0.add_patch(Circle((0.5, 0.5), 0.1,color=\"black\"))\n",
    "    plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "    cbar0.ax.tick_params(labelsize=15)\n",
    "    plt.show()\n",
    "\n",
    "    ############################ \n",
    "\n",
    "    x = np.linspace(0.3, 1, num_test_samples)\n",
    "    y = np.linspace(0.3, 0.7, num_test_samples)\n",
    "    x, y = np.meshgrid(x, y)\n",
    "    xy = np.stack([x.flatten(), y.flatten()], axis=-1)\n",
    "    # predict (psi, p)\n",
    "    u_v_p = network.predict(xy, batch_size=len(xy))\n",
    "    u, v, p = [ u_v_p[..., i].reshape(x.shape) for i in range(u_v_p.shape[-1]) ]\n",
    "    # compute (u, v)\n",
    "    u = u.reshape(x.shape)\n",
    "    v = v.reshape(x.shape)\n",
    "    p = p.reshape(x.shape)\n",
    "    # plot test results\n",
    "    \n",
    "    fig = plt.figure(figsize=(15, 8))\n",
    "    #contour(gs[0, 0], x, y, psi, 'psi')\n",
    "    contour(x, y, p, 'p')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 8))\n",
    "    contour(x, y, u, 'u')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 8))\n",
    "    contour(x, y, v, 'v')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    ###########################\n",
    "    from matplotlib.patches import Circle\n",
    "    font1 = {'family':'serif','size':20}\n",
    "\n",
    "    fig0, ax0 = plt.subplots(1, 1,figsize=(18,8))\n",
    "    cf0 = ax0.contourf(x, y, p, np.arange(-0.2, 0.6, .02),\n",
    "                   extend='both',cmap='rainbow')\n",
    "    cbar0 = plt.colorbar(cf0, pad=0.03, aspect=25, format='%.0e')\n",
    "    plt.title(\"p\", fontdict = font1)\n",
    "    plt.xlabel(\"x\", fontdict = font1)\n",
    "    plt.ylabel(\"y\", fontdict = font1)\n",
    "    ax0.add_patch(Circle((0.5, 0.5), 0.1,color=\"black\"))\n",
    "    plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "    cbar0.ax.tick_params(labelsize=15)\n",
    "    plt.show()\n",
    "\n",
    "    ###########################\n",
    "\n",
    "    fig0, ax0 = plt.subplots(1, 1, figsize=(18,8))\n",
    "    cf0 = ax0.contourf(x, y, u, np.arange(-0.5, 1.1, .02),\n",
    "                   extend='both',cmap='rainbow')\n",
    "    cbar0 = plt.colorbar(cf0, )\n",
    "    plt.title(\"u\", fontdict = font1)\n",
    "    plt.xlabel(\"x\", fontdict = font1)\n",
    "    plt.ylabel(\"y\", fontdict = font1)\n",
    "    ax0.add_patch(Circle((0.5, 0.5), 0.1,color=\"black\"))\n",
    "    plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "    cbar0.ax.tick_params(labelsize=15)\n",
    "    plt.show()\n",
    "\n",
    "    ###########################\n",
    "\n",
    "    fig0, ax0 = plt.subplots(1, 1,figsize=(18,8))\n",
    "    cf0 = ax0.contourf(x, y, v, np.arange(-0.4, 0.4, .02),\n",
    "                   extend='both',cmap='rainbow')\n",
    "    cbar0 = plt.colorbar(cf0, pad=0.03, aspect=25, format='%.0e')\n",
    "    plt.title(\"v\", fontdict = font1)\n",
    "    plt.xlabel(\"x\", fontdict = font1)\n",
    "    plt.ylabel(\"y\", fontdict = font1)\n",
    "    ax0.add_patch(Circle((0.5, 0.5), 0.1,color=\"black\"))\n",
    "    plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "    cbar0.ax.tick_params(labelsize=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
