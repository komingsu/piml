{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "\n",
    "from NN import *\n",
    "from th_operator import calc_grad\n",
    "from utils import print_model_layers\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "import os, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "batch_size = 10000\n",
    "\n",
    "# Task parameters\n",
    "u0 = 1 # inlet flow velocity\n",
    "rho = 1000 # density\n",
    "mu = 1 # viscosity\n",
    "\n",
    "# Samples\n",
    "num_points_per_step = 10000  # number of spatial points per time step\n",
    "num_BC_points_per_step = 1000  # number of boundary condition points per time step\n",
    "num_IC_points = 2000  # number of initial condition points\n",
    "\n",
    "# Data boundary\n",
    "## Domain\n",
    "x_ini, x_f, y_ini, y_f = 0, 20, 0, 8\n",
    "\n",
    "## Time\n",
    "T = 20  # total time in seconds\n",
    "Delta_t = 0.1  # time step in seconds\n",
    "num_time_steps = int(T / Delta_t)  # number of time steps\n",
    "time_steps = np.random.uniform(0, T, num_time_steps)\n",
    "\n",
    "## Circle\n",
    "Cx, Cy, r = 4, 4, 0.5\n",
    "\n",
    "\n",
    "def generate_domain_points(num_points, x_range, y_range, time_steps, circle_center, circle_radius):\n",
    "    \"\"\"\n",
    "    Generate spatial-temporal points within specified domain excluding a circular obstacle, for given time steps.\n",
    "\n",
    "    Parameters:\n",
    "    - num_points: Number of points to generate for each time step.\n",
    "    - x_range: Tuple of (min_x, max_x) for x-coordinate range.\n",
    "    - y_range: Tuple of (min_y, max_y) for y-coordinate range.\n",
    "    - time_steps: Array of time steps.\n",
    "    - circle_center: Tuple of (Cx, Cy), the center of the circular obstacle.\n",
    "    - circle_radius: Radius of the circular obstacle.\n",
    "\n",
    "    Returns:\n",
    "    - Numpy array of spatial-temporal points with shape (num_points * len(time_steps), 3), where each row represents (x, y, t),\n",
    "      excluding points inside the circular obstacle.\n",
    "    \"\"\"\n",
    "    Cx, Cy = circle_center\n",
    "    xyt_points = []\n",
    "\n",
    "    for t in time_steps:\n",
    "        for _ in range(num_points):\n",
    "            while True:\n",
    "                x = np.random.uniform(x_range[0], x_range[1])\n",
    "                y = np.random.uniform(y_range[0], y_range[1])\n",
    "                # Check if the point is outside the circular obstacle\n",
    "                if (x - Cx)**2 + (y - Cy)**2 >= circle_radius**2:\n",
    "                    xyt_points.append([x, y, t])\n",
    "                    break\n",
    "    \n",
    "    domain = np.array(xyt_points, dtype=np.float32)\n",
    "    idx = np.lexsort((domain[:, 1], domain[:, 0], domain[:, 2]))\n",
    "    return domain[idx]\n",
    "\n",
    "def generate_boundary_points(num_points, boundary_func, time_steps):\n",
    "    xyt_points = []\n",
    "    for t in time_steps:\n",
    "        points = boundary_func(num_points)\n",
    "        t_col = np.full((points.shape[0], 1), t)\n",
    "        xyt = np.hstack((points, t_col))\n",
    "        xyt_points.append(xyt)\n",
    "        \n",
    "    bc = np.vstack(xyt_points)\n",
    "    idx = np.lexsort((bc[:, 1], bc[:, 0], bc[:, 2]))\n",
    "    return bc[idx]\n",
    "\n",
    "def circle_boundary(num_points):\n",
    "    # Generate points for the circle boundary\n",
    "    theta = np.random.uniform(0, 2*np.pi, num_points)\n",
    "    x = Cx + r * np.cos(theta)\n",
    "    y = Cy + r * np.sin(theta)\n",
    "    return np.vstack((x, y)).T\n",
    "\n",
    "def wall_boundary(num_points, x_range, y_value):\n",
    "    # Generate points for wall boundaries (top or bottom)\n",
    "    x = np.random.uniform(x_range[0], x_range[1], num_points)\n",
    "    y = np.full(num_points, y_value)\n",
    "    return np.vstack((x, y)).T\n",
    "\n",
    "def inlet_outlet_boundary(num_points, y_range, x_value):\n",
    "    # Generate points for inlet or outlet boundaries\n",
    "    y = np.random.uniform(y_range[0], y_range[1], num_points)\n",
    "    x = np.full(num_points, x_value)\n",
    "    return np.vstack((x, y)).T\n",
    "\n",
    "def generate_initial_conditions(num_points, x_range, y_range):\n",
    "    x_initial = np.random.uniform(x_range[0], x_range[1], num_points)\n",
    "    y_initial = np.random.uniform(y_range[0], y_range[1], num_points)\n",
    "    t_initial = np.zeros(num_points)\n",
    "    xyt_initial = np.stack((x_initial, y_initial, t_initial), axis=-1)\n",
    "    return xyt_initial\n",
    "\n",
    "def train_dataset():\n",
    "    # Generating boundary points for each boundary condition and time step\n",
    "    xyt_eqn = generate_domain_points(num_points_per_step, (x_ini, x_f), (y_ini, y_f), time_steps, (0, 0), 0.5)\n",
    "    xyt_circle = generate_boundary_points(num_BC_points_per_step, circle_boundary, time_steps)\n",
    "    xyt_w1 = generate_boundary_points(num_BC_points_per_step, lambda num_points: wall_boundary(num_points, (x_ini, x_f), y_ini), time_steps)\n",
    "    xyt_w2 = generate_boundary_points(num_BC_points_per_step, lambda num_points: wall_boundary(num_points, (x_ini, x_f), y_f), time_steps)\n",
    "    xyt_in = generate_boundary_points(num_BC_points_per_step, lambda num_points: inlet_outlet_boundary(num_points, (y_ini, y_f), x_ini), time_steps)\n",
    "    xyt_out = generate_boundary_points(num_BC_points_per_step, lambda num_points: inlet_outlet_boundary(num_points, (y_ini, y_f), x_f), time_steps)\n",
    "    xyt_initial = generate_initial_conditions(num_IC_points, (x_ini, x_f), (y_ini, y_f))\n",
    "\n",
    "    # Combine all training points\n",
    "    return {\n",
    "        \"eqn\": xyt_eqn,\n",
    "        \"circle\": xyt_circle,\n",
    "        \"w1\": xyt_w1,\n",
    "        \"w2\": xyt_w2,\n",
    "        \"in\": xyt_in,\n",
    "        \"out\": xyt_out,\n",
    "        \"initial\": xyt_initial,\n",
    "    }\n",
    "\n",
    "x_train = train_dataset()\n",
    "# # Save the training data\n",
    "# mu_str = '{:04.1f}'.format(mu)\n",
    "# file_path = f\"./trainX__rho_{rho:04d}__mu_{mu_str}__.mat\"\n",
    "# sio.savemat(file_path, {\n",
    "#     \"eqn\": xyt_eqn,\n",
    "#     \"circle\": xyt_circle,\n",
    "#     \"w1\": xyt_w1,\n",
    "#     \"w2\": xyt_w2,\n",
    "#     \"in\": xyt_in,\n",
    "#     \"out\": xyt_out,\n",
    "#     \"initial\": xyt_initial,\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eqn shape:  (2000000, 3)\n",
      "circle shape:  (200000, 3)\n",
      "w1 shape:  (200000, 3)\n",
      "w2 shape:  (200000, 3)\n",
      "in shape:  (200000, 3)\n",
      "out shape:  (200000, 3)\n",
      "initial shape:  (50000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"eqn shape: \", x_train[\"eqn\"].shape)\n",
    "print(\"circle shape: \", x_train[\"circle\"].shape)\n",
    "print(\"w1 shape: \", x_train[\"w1\"].shape)\n",
    "print(\"w2 shape: \", x_train[\"w2\"].shape)\n",
    "print(\"in shape: \", x_train[\"in\"].shape)\n",
    "print(\"out shape: \", x_train[\"out\"].shape)\n",
    "print(\"initial shape: \", x_train[\"initial\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치학습을 위한 데이터 로더 함수를 정의합니다.\n",
    "def create_dataloader(x_data, batch_size, shuffle):\n",
    "    dataset = TensorDataset(th.tensor(x_data, dtype=th.float32))\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return loader\n",
    "\n",
    "def generate_combined_batch(dataloaders_iterators, batch_size_per_loader):\n",
    "    batch_parts = {}\n",
    "    for key, iterator in dataloaders_iterators.items():\n",
    "        try:\n",
    "            # 각 DataLoader의 iterator로부터 데이터 배치를 가져옴\n",
    "            data, = next(iterator)\n",
    "            batch_parts[key] = data[:batch_size_per_loader]\n",
    "        except StopIteration:\n",
    "            # 현재 DataLoader의 데이터가 끝에 도달했을 경우, iterator를 다시 시작\n",
    "            dataloaders_iterators[key] = iter(dataloaders[key])\n",
    "            data, = next(dataloaders_iterators[key])\n",
    "            batch_parts[key] = data[:batch_size_per_loader]\n",
    "    return batch_parts\n",
    "\n",
    "dataloaders = {key: create_dataloader(x_train[key], batch_size, False) for key in x_train}\n",
    "dataloaders_iterators = {key: iter(loader) for key, loader in dataloaders.items()}\n",
    "\n",
    "# for _ in range(200):  # 200번의 iteration으로 1 epoch을 수행\n",
    "#     print(\"---\")\n",
    "#     combined_batch = generate_combined_batch(dataloaders_iterators, batch_size_per_loader=10000)\n",
    "#     for k, v in combined_batch.items():\n",
    "#         print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP = MultiLayerPerceptronClass(\n",
    "    x_dim=3, y_dim=2,\n",
    "    h_dim_list=[100,100,100,100],\n",
    "    actv= th.nn.Tanh(),\n",
    "    p_drop=0.0,\n",
    "    batch_norm=False\n",
    ")\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "MLP = MLP.to(device)\n",
    "# MLP = th.nn.DataParallel(MLP,device_ids=[0,1],output_device=0)\n",
    "pinn = PINN(network=MLP, rho=rho, mu=mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L_BFGS_B:\n",
    "    \"\"\"\n",
    "    Optimize the PyTorch model using L-BFGS-B algorithm.\n",
    "    Attributes:\n",
    "        model: optimization target model.\n",
    "        samples: training samples.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, dataloaders_iterators, generate_func, batch_size=10000, epochs=20):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model: optimization target model.\n",
    "            x_train: training input samples as tensors.\n",
    "            y_train: training target samples as tensors.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.dataloaders_iterators = dataloaders_iterators\n",
    "        self.generate_combined_batch = generate_func\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "\n",
    "        self.optimizer = optim.LBFGS(\n",
    "            params = self.model.parameters(),\n",
    "            lr = 1,\n",
    "            max_iter = 10000,\n",
    "            max_eval = 10000,\n",
    "            tolerance_grad = 1e-5,\n",
    "            tolerance_change = 0.5 * th.finfo(float).eps,\n",
    "            history_size = 50,\n",
    "            line_search_fn=\"strong_wolfe\",\n",
    "            )\n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\"\n",
    "        Evaluate loss and gradients for the model.\n",
    "        Returns:\n",
    "            loss: the loss as a scalar tensor.\n",
    "        \"\"\"\n",
    "        def closure():\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            combined_batch = self.generate_combined_batch(self.dataloaders_iterators, self.batch_size)\n",
    "            for key in combined_batch:\n",
    "                combined_batch[key] = combined_batch[key].to(device)\n",
    "            \n",
    "            outputs = self.model(combined_batch)\n",
    "            PDE, BC, IC, inlet = outputs[\"grads\"]\n",
    "            \n",
    "            # PDE: u_eqn, v_eqn\n",
    "            # BC: uv_in, uv_w1, uv_w2, uv_circle # uv_out is not used\n",
    "            # IC: u_initial, v_initial\n",
    "            # inlet: uv_inlet\n",
    "            \n",
    "            # LOSS\n",
    "            criterion = nn.MSELoss(reduction=\"sum\")\n",
    "            loss_eqn = criterion(PDE, th.zeros_like(PDE))\n",
    "            loss_in = criterion(BC[0], inlet)\n",
    "            loss_w1 = criterion(BC[1], th.zeros_like(BC[1]))\n",
    "            loss_w2 = criterion(BC[2], th.zeros_like(BC[2]))\n",
    "            loss_circle = criterion(BC[3], th.zeros_like(BC[3]))\n",
    "            loss_ic = criterion(IC, th.zeros_like(IC))\n",
    "            loss_out = criterion(BC[4], th.zeros_like(BC[4]))\n",
    "            total_loss = (loss_eqn + loss_in + loss_w1 + loss_w2 + loss_circle + loss_ic + loss_out) / 7\n",
    "\n",
    "            total_loss.backward()\n",
    "\n",
    "            return total_loss\n",
    "        \n",
    "        return closure\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Train the model using L-BFGS-B algorithm.\n",
    "        Args:\n",
    "            max_iter: Maximum number of iterations.\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        # Optimize\n",
    "        for epoch in range(self.epochs):\n",
    "            for iter in range(2000000//self.batch_size):\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.optimizer.step(self.evaluate())\n",
    "                print(f\"{epoch:02d}:{iter:03d}:{loss}\")   \n",
    "        print('Optimization finished.')\n",
    "        \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Predict using the trained model.\n",
    "        Args:\n",
    "            x: Input data for prediction.\n",
    "        Returns:\n",
    "            predictions: Predicted values by the model.\n",
    "        \"\"\"\n",
    "        self.model.eval()  # 모델을 평가 모드로 설정\n",
    "        with th.no_grad():  # 그라디언트 계산 비활성화\n",
    "            outputs = self.model(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:000:3201.523681640625\n",
      "00:001:5612.5654296875\n",
      "00:002:2786.58154296875\n",
      "00:003:2745.634521484375\n",
      "00:004:723.1945190429688\n",
      "00:005:2321.205810546875\n",
      "00:006:3184.42431640625\n",
      "00:007:690.8748779296875\n",
      "00:008:1176.2679443359375\n",
      "00:009:2110.11865234375\n",
      "00:010:2089.26708984375\n",
      "00:011:631.3583374023438\n",
      "00:012:2262.68115234375\n",
      "00:013:669.0353393554688\n",
      "00:014:2129.08447265625\n",
      "00:015:1847.1236572265625\n",
      "00:016:2877.872314453125\n",
      "00:017:871.948486328125\n",
      "00:018:2008.4503173828125\n",
      "00:019:717.4125366210938\n",
      "00:020:2265.83251953125\n",
      "00:021:710.773193359375\n",
      "00:022:2253.456298828125\n",
      "00:023:909.116943359375\n",
      "00:024:1296.6204833984375\n",
      "00:025:4790.78466796875\n",
      "00:026:906.7282104492188\n",
      "00:027:1914.2744140625\n",
      "00:028:776.9412841796875\n",
      "00:029:1736.0035400390625\n",
      "00:030:2398.86572265625\n",
      "00:031:1415.177978515625\n",
      "00:032:1927.431396484375\n",
      "00:033:1299.335693359375\n",
      "00:034:2853.790771484375\n",
      "00:035:734.1129150390625\n",
      "00:036:1312.0858154296875\n",
      "00:037:971.6281127929688\n",
      "00:038:895.1232299804688\n",
      "00:039:986.233642578125\n",
      "00:040:722.7105712890625\n",
      "00:041:629.0626831054688\n",
      "00:042:839.6632690429688\n",
      "00:043:812.7509155273438\n",
      "00:044:764.9758911132812\n",
      "00:045:921.2637329101562\n",
      "00:046:617.7322387695312\n",
      "00:047:693.0687255859375\n",
      "00:048:1133.1319580078125\n",
      "00:049:631.62451171875\n",
      "00:050:541.5904541015625\n",
      "00:051:868.805908203125\n",
      "00:052:866.6557006835938\n",
      "00:053:734.4102783203125\n",
      "00:054:1466.423583984375\n",
      "00:055:1153.2508544921875\n",
      "00:056:637.849365234375\n",
      "00:057:713.8722534179688\n",
      "00:058:651.9881591796875\n",
      "00:059:957.5519409179688\n",
      "00:060:446.03125\n",
      "00:061:353.2916259765625\n",
      "00:062:620.5663452148438\n",
      "00:063:2084.15625\n",
      "00:064:857.9715576171875\n",
      "00:065:455.49261474609375\n",
      "00:066:1323.78466796875\n",
      "00:067:450.5206298828125\n",
      "00:068:772.5170288085938\n",
      "00:069:519.6317749023438\n",
      "00:070:697.830322265625\n",
      "00:071:551.7854614257812\n",
      "00:072:831.962646484375\n",
      "00:073:487.54278564453125\n",
      "00:074:455.922119140625\n",
      "00:075:500.3515930175781\n",
      "00:076:1781.394775390625\n",
      "00:077:386.02044677734375\n",
      "00:078:606.549072265625\n",
      "00:079:432.3177795410156\n",
      "00:080:654.1817626953125\n",
      "00:081:448.59942626953125\n",
      "00:082:550.0736083984375\n",
      "00:083:427.7212219238281\n",
      "00:084:406.30120849609375\n",
      "00:085:247.61801147460938\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m lbfgs \u001b[38;5;241m=\u001b[39m L_BFGS_B(model\u001b[38;5;241m=\u001b[39mpinn, dataloaders_iterators\u001b[38;5;241m=\u001b[39mdataloaders_iterators, generate_func\u001b[38;5;241m=\u001b[39mgenerate_combined_batch, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mlbfgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 83\u001b[0m, in \u001b[0;36mL_BFGS_B.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2000000\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size):\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 83\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28miter\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)   \n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOptimization finished.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\enomazosii\\OneDrive\\document\\GitHub\\piml\\.venv\\lib\\site-packages\\torch\\optim\\optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    371\u001b[0m             )\n\u001b[1;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\enomazosii\\OneDrive\\document\\GitHub\\piml\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\enomazosii\\OneDrive\\document\\GitHub\\piml\\.venv\\lib\\site-packages\\torch\\optim\\lbfgs.py:426\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(x, t, d):\n\u001b[0;32m    424\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_directional_evaluate(closure, x, t, d)\n\u001b[1;32m--> 426\u001b[0m     loss, flat_grad, t, ls_func_evals \u001b[38;5;241m=\u001b[39m \u001b[43m_strong_wolfe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgtd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_grad(t, d)\n\u001b[0;32m    429\u001b[0m opt_cond \u001b[38;5;241m=\u001b[39m flat_grad\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m tolerance_grad\n",
      "File \u001b[1;32mc:\\Users\\enomazosii\\OneDrive\\document\\GitHub\\piml\\.venv\\lib\\site-packages\\torch\\optim\\lbfgs.py:99\u001b[0m, in \u001b[0;36m_strong_wolfe\u001b[1;34m(obj_func, x, t, d, f, g, gtd, c1, c2, tolerance_change, max_ls)\u001b[0m\n\u001b[0;32m     97\u001b[0m g_prev \u001b[38;5;241m=\u001b[39m g_new\u001b[38;5;241m.\u001b[39mclone(memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcontiguous_format)\n\u001b[0;32m     98\u001b[0m gtd_prev \u001b[38;5;241m=\u001b[39m gtd_new\n\u001b[1;32m---> 99\u001b[0m f_new, g_new \u001b[38;5;241m=\u001b[39m \u001b[43mobj_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m ls_func_evals \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    101\u001b[0m gtd_new \u001b[38;5;241m=\u001b[39m g_new\u001b[38;5;241m.\u001b[39mdot(d)\n",
      "File \u001b[1;32mc:\\Users\\enomazosii\\OneDrive\\document\\GitHub\\piml\\.venv\\lib\\site-packages\\torch\\optim\\lbfgs.py:424\u001b[0m, in \u001b[0;36mLBFGS.step.<locals>.obj_func\u001b[1;34m(x, t, d)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(x, t, d):\n\u001b[1;32m--> 424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_directional_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\enomazosii\\OneDrive\\document\\GitHub\\piml\\.venv\\lib\\site-packages\\torch\\optim\\lbfgs.py:278\u001b[0m, in \u001b[0;36mLBFGS._directional_evaluate\u001b[1;34m(self, closure, x, t, d)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_directional_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, closure, x, t, d):\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_grad(t, d)\n\u001b[1;32m--> 278\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m     flat_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gather_flat_grad()\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_param(x)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lbfgs = L_BFGS_B(model=pinn, dataloaders_iterators=dataloaders_iterators, generate_func=generate_combined_batch, batch_size=batch_size, epochs=2)\n",
    "lbfgs.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.save(MLP.state_dict(), \"./model_state_dict.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch as th\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# import numpy as np\n",
    "# import scipy.io as sio\n",
    "\n",
    "# from NN import *\n",
    "# from th_operator import calc_grad\n",
    "# from utils import print_model_layers\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.colors import Normalize\n",
    "\n",
    "def contour(x, y, z, title, levels=100):\n",
    "    \"\"\"\n",
    "    Contour plot.\n",
    "    Args:\n",
    "        x: x-array.\n",
    "        y: y-array.\n",
    "        z: z-array.\n",
    "        title: title string.\n",
    "        levels: number of contour lines.\n",
    "    \"\"\"\n",
    "\n",
    "    # get the value range\n",
    "    vmin = np.min(z)\n",
    "    vmax = np.max(z)\n",
    "\n",
    "    # plot a contour\n",
    "    font1 = {'family':'serif','size':20}\n",
    "    plt.contour(x, y, z, colors='k', linewidths=0.2, levels=levels)\n",
    "    contour_filled = plt.contourf(x, y, z, cmap='rainbow', levels=levels, norm=Normalize(vmin=vmin, vmax=vmax))\n",
    "\n",
    "    # Add the circle patch to the current axes without altering the axes limits\n",
    "    circle = plt.Circle((4, 4), 0.5, color='black')\n",
    "    plt.gca().add_patch(circle)\n",
    "\n",
    "    plt.title(title, fontdict=font1)\n",
    "    plt.xlabel(\"X\", fontdict=font1)\n",
    "    plt.ylabel(\"Y\", fontdict=font1)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "\n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(contour_filled, pad=0.03, aspect=25, format='%.0e')\n",
    "    cbar.mappable.set_clim(vmin, vmax)\n",
    "    cbar.ax.tick_params(labelsize=15)\n",
    "    \n",
    "\n",
    "\n",
    "def make_gif(folder_path, title):\n",
    "    frames = [Image.open(image) for image in sorted(glob.glob(folder_path))]\n",
    "    frame_one = frames[0]\n",
    "    frame_one.save(f\"./{title}.gif\", format=\"GIF\", append_images=frames, save_all=True, duration=100, loop=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2010000, 3])\n"
     ]
    }
   ],
   "source": [
    "# 도메인 및 시간 설정\n",
    "x_min, x_max = 0, 20\n",
    "y_min, y_max = 0, 8\n",
    "t_min, t_max = 0, 20  # 테스트할 시간 범위\n",
    "delta_t = 0.1  # 시간 단위\n",
    "\n",
    "# 공간 그리드 포인트 수\n",
    "num_x, num_y = 100, 100 # 공간 및 시간 축에 대한 포인트 수\n",
    "\n",
    "# 공간 및 시간 축을 위한 그리드 생성\n",
    "x = np.linspace(x_min, x_max, num_x)\n",
    "y = np.linspace(y_min, y_max, num_y)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "test_shape = X.shape\n",
    "time_steps = np.arange(t_min, t_max + delta_t, delta_t)\n",
    "\n",
    "# 초기화\n",
    "test_xyt = np.empty((0, 3), dtype=np.float32)\n",
    "\n",
    "# 각 시간 스텝에 대해 x, y 그리드와 t 값을 결합\n",
    "for t in time_steps:\n",
    "    T = np.full(X.shape, t)\n",
    "    xyt = np.stack([X.ravel(), Y.ravel(), T.ravel()], axis=-1)\n",
    "    test_xyt = np.vstack([test_xyt, xyt])\n",
    "    \n",
    "# PyTorch 텐서로 변환 및 디바이스 할당\n",
    "test_xyt = th.tensor(test_xyt, dtype=th.float32)\n",
    "\n",
    "print(test_xyt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model = predictlayer(MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>), tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>), tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0',\n",
      "       grad_fn=<NegBackward0>)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enomazosii\\AppData\\Local\\Temp\\ipykernel_17192\\635911006.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  xyt = th.tensor(xyt, dtype=th.float32).to(device)\n"
     ]
    }
   ],
   "source": [
    "for time_steps, xyt in enumerate(test_xyt.split(10000)):\n",
    "    xx = xyt[..., 0].unsqueeze(-1).reshape(test_shape).numpy()\n",
    "    yy = xyt[..., 1].unsqueeze(-1).reshape(test_shape).numpy()\n",
    "    xyt = th.tensor(xyt, dtype=th.float32).to(device)\n",
    "    p_u_v = pred_model(xyt)\n",
    "    print(p_u_v)\n",
    "    break\n",
    "\n",
    "#     p, u, v = [ p_u_v[..., i].reshape(test_shape) for i in range(p_u_v.shape[-1]) ]\n",
    "#     u = u.detach().cpu().numpy()\n",
    "#     v = v.detach().cpu().numpy()\n",
    "#     p = p.detach().cpu().numpy()\n",
    "#     # compute (u, v)\n",
    "#     u = u.reshape(test_shape)\n",
    "#     v = v.reshape(test_shape)\n",
    "#     p = p.reshape(test_shape)\n",
    "\n",
    "#     # plot test results\n",
    "#     fig = plt.figure(figsize=(15, 6))\n",
    "#     contour(xx, yy, p, f'p_{time_steps:03d}')\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(f'./p/Pressure_timestep_{time_steps:03d}.png')\n",
    "#     plt.close(fig)\n",
    "\n",
    "#     fig = plt.figure(figsize=(15, 6))\n",
    "#     contour(xx, yy, u, f'u_{time_steps:03d}')\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(f'./u/Vx_timestep_{time_steps:03d}.png')\n",
    "#     plt.close(fig)\n",
    "\n",
    "#     fig = plt.figure(figsize=(15, 6))\n",
    "#     contour(xx, yy, v, f'v_{time_steps:03d}')\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(f'./v/Vy_timestep_{time_steps:03d}.png')\n",
    "#     plt.close(fig)\n",
    "    \n",
    "# make_gif(\"./p/*.png\", \"p\")\n",
    "# make_gif(\"./u/*.png\", \"u\")\n",
    "# make_gif(\"./v/*.png\", \"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class predictlayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom layer to compute derivatives for the steady Navier-Stokes equation using PyTorch.\n",
    "    # model = Create_Model()\n",
    "    # gradient_layer = GradientLayer(model)\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        super(predictlayer, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, xyt):\n",
    "        x, y, t = xyt[..., 0], xyt[..., 1], xyt[..., 2]\n",
    "        x.requires_grad_(True)\n",
    "        y.requires_grad_(True)\n",
    "        t.requires_grad_(True)\n",
    "        # Combine x and y and predict u, v, p\n",
    "        output = self.model(th.stack([x, y, t], dim=-1))\n",
    "        psi = output[..., 0]\n",
    "        p_pred = output[..., 1]\n",
    "        u_pred = calc_grad(psi, y)\n",
    "        v_pred = -calc_grad(psi, x)\n",
    "\n",
    "        return [p_pred, u_pred, v_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
