{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import torch\n",
    "from torch import nn, autograd, Tensor\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(y, x) -> Tensor:\n",
    "    grad = autograd.grad(\n",
    "        outputs=y,\n",
    "        inputs=x,\n",
    "        grad_outputs=torch.ones_like(y),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pinn(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dims: List[int]):\n",
    "        super().__init__()\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.ffn_layers = []\n",
    "        input_dim = 3\n",
    "        for hidden_dim in hidden_dims:\n",
    "            self.ffn_layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            self.ffn_layers.append(nn.Tanh())\n",
    "            input_dim = hidden_dim\n",
    "        self.ffn_layers.append(nn.Linear(input_dim, 2))\n",
    "        self.ffn = nn.Sequential(*self.ffn_layers)\n",
    "\n",
    "        self.lambda1 = nn.Parameter(torch.tensor(0.0))\n",
    "        self.lambda2 = nn.Parameter(torch.tensor(0.0))\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: Tensor,\n",
    "        y: Tensor,\n",
    "        t: Tensor,\n",
    "        p: Tensor = None,\n",
    "        u: Tensor = None,\n",
    "        v: Tensor = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        inputs: x, y, t\n",
    "        labels: p, u, v\n",
    "        \"\"\"\n",
    "        inputs = torch.stack([x, y, t], dim=1)\n",
    "        hidden_output = self.ffn(inputs)\n",
    "        psi = hidden_output[:, 0]\n",
    "        p_pred = hidden_output[:, 1]\n",
    "        u_pred = calc_grad(psi, y)\n",
    "        v_pred = -calc_grad(psi, x)\n",
    "\n",
    "        preds = torch.stack([p_pred, u_pred, v_pred], dim=1)\n",
    "        u_t = calc_grad(u_pred, t)\n",
    "        u_x = calc_grad(u_pred, x)\n",
    "        u_y = calc_grad(u_pred, y)\n",
    "        u_xx = calc_grad(u_x, x)\n",
    "        u_yy = calc_grad(u_y, y)\n",
    "\n",
    "        v_t = calc_grad(v_pred, t)\n",
    "        v_x = calc_grad(v_pred, x)\n",
    "        v_y = calc_grad(v_pred, y)\n",
    "        v_xx = calc_grad(v_x, x)\n",
    "        v_yy = calc_grad(v_y, y)\n",
    "\n",
    "        p_x = calc_grad(p_pred, x)\n",
    "        p_y = calc_grad(p_pred, y)\n",
    "\n",
    "        f_u = (\n",
    "            u_t\n",
    "            + self.lambda1 * (u_pred * u_x + v_pred * u_y)\n",
    "            + p_x\n",
    "            - self.lambda2 * (u_xx + u_yy)\n",
    "        )\n",
    "        f_v = (\n",
    "            v_t\n",
    "            + self.lambda1 * (u_pred * v_x + v_pred * v_y)\n",
    "            + p_y\n",
    "            - self.lambda2 * (v_xx + v_yy)\n",
    "        )\n",
    "        loss = self.loss_fn(u, v, u_pred, v_pred, f_u, f_v)\n",
    "        return {\n",
    "            \"preds\": preds,\n",
    "            \"loss\": loss,\n",
    "        }\n",
    "\n",
    "    def loss_fn(self, u, v, u_pred, v_pred, f_u_pred, f_v_pred):\n",
    "        \"\"\"\n",
    "        u: (b, 1)\n",
    "        v: (b, 1)\n",
    "        p: (b, 1)\n",
    "        \"\"\"\n",
    "        loss = (\n",
    "            F.mse_loss(u, u_pred, reduction=\"sum\")\n",
    "            + F.mse_loss(v, v_pred, reduction=\"sum\")\n",
    "            + F.mse_loss(f_u_pred, torch.zeros_like(f_u_pred), reduction=\"sum\")\n",
    "            + F.mse_loss(f_v_pred, torch.zeros_like(f_v_pred), reduction=\"sum\")\n",
    "        )\n",
    "        return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
