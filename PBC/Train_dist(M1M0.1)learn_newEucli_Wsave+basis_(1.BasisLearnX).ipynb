{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T02:02:35.310814Z",
     "iopub.status.busy": "2024-04-23T02:02:35.310506Z",
     "iopub.status.idle": "2024-04-23T02:02:36.354990Z",
     "shell.execute_reply": "2024-04-23T02:02:36.354486Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchsummary import summary\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T02:02:36.358143Z",
     "iopub.status.busy": "2024-04-23T02:02:36.357563Z",
     "iopub.status.idle": "2024-04-23T02:02:36.369516Z",
     "shell.execute_reply": "2024-04-23T02:02:36.369051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Current cuda device: 0\n",
      "Count of using GPUs: 2\n"
     ]
    }
   ],
   "source": [
    "# CUDA 사용 가능한지 확인합니다.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T02:02:36.420560Z",
     "iopub.status.busy": "2024-04-23T02:02:36.420248Z",
     "iopub.status.idle": "2024-04-23T02:02:36.422627Z",
     "shell.execute_reply": "2024-04-23T02:02:36.422274Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")  # 0번 GPU를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T02:02:36.426286Z",
     "iopub.status.busy": "2024-04-23T02:02:36.426068Z",
     "iopub.status.idle": "2024-04-23T02:02:37.615655Z",
     "shell.execute_reply": "2024-04-23T02:02:37.615071Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# 시드 설정\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T02:02:37.618582Z",
     "iopub.status.busy": "2024-04-23T02:02:37.618227Z",
     "iopub.status.idle": "2024-04-23T02:02:37.635522Z",
     "shell.execute_reply": "2024-04-23T02:02:37.635072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>A_scaled</th>\n",
       "      <th>B_scaled</th>\n",
       "      <th>C_scaled</th>\n",
       "      <th>Initial Total Loss</th>\n",
       "      <th>Total Loss at 50</th>\n",
       "      <th>Avg Loss 0-50</th>\n",
       "      <th>dist_from0</th>\n",
       "      <th>dist_from1</th>\n",
       "      <th>dist_from2</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>-0.552750</td>\n",
       "      <td>-0.606017</td>\n",
       "      <td>-0.647231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-0.528888</td>\n",
       "      <td>-0.610003</td>\n",
       "      <td>-0.651601</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-0.447648</td>\n",
       "      <td>-0.599378</td>\n",
       "      <td>-0.623454</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>-0.447229</td>\n",
       "      <td>-0.662263</td>\n",
       "      <td>-0.665812</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-0.922506</td>\n",
       "      <td>-0.766860</td>\n",
       "      <td>-0.812981</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-0.822324</td>\n",
       "      <td>-0.767863</td>\n",
       "      <td>-0.813792</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>-0.506590</td>\n",
       "      <td>-0.722144</td>\n",
       "      <td>-0.685461</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-0.755358</td>\n",
       "      <td>-0.768687</td>\n",
       "      <td>-0.807436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-0.652738</td>\n",
       "      <td>-0.769890</td>\n",
       "      <td>-0.805635</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>0.628385</td>\n",
       "      <td>1.085074</td>\n",
       "      <td>0.973400</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>0.707020</td>\n",
       "      <td>0.992458</td>\n",
       "      <td>0.929765</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>0.801478</td>\n",
       "      <td>0.983218</td>\n",
       "      <td>0.991927</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>0.606207</td>\n",
       "      <td>0.815648</td>\n",
       "      <td>0.797870</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-1.977386</td>\n",
       "      <td>-0.763410</td>\n",
       "      <td>-0.850788</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-1.208969</td>\n",
       "      <td>-0.768068</td>\n",
       "      <td>-0.833252</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>0.736237</td>\n",
       "      <td>0.029045</td>\n",
       "      <td>0.460709</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-1.192925</td>\n",
       "      <td>-0.767233</td>\n",
       "      <td>-0.830689</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-0.574138</td>\n",
       "      <td>-0.768989</td>\n",
       "      <td>-0.799679</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>1.559954</td>\n",
       "      <td>1.930742</td>\n",
       "      <td>1.804001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>1.598503</td>\n",
       "      <td>1.891407</td>\n",
       "      <td>1.772269</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>1.728613</td>\n",
       "      <td>1.829878</td>\n",
       "      <td>1.808205</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>1.496816</td>\n",
       "      <td>1.751257</td>\n",
       "      <td>1.687899</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-0.814077</td>\n",
       "      <td>-0.704586</td>\n",
       "      <td>-0.683205</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-0.247788</td>\n",
       "      <td>-0.719647</td>\n",
       "      <td>-0.683076</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>1.634840</td>\n",
       "      <td>0.850517</td>\n",
       "      <td>1.250954</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-0.059455</td>\n",
       "      <td>-0.666047</td>\n",
       "      <td>-0.679502</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>0.212718</td>\n",
       "      <td>-0.728159</td>\n",
       "      <td>-0.603406</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A   B   C  A_scaled  B_scaled  C_scaled  Initial Total Loss  \\\n",
       "0    1   2   3 -1.357931 -1.337451 -1.316686           -0.552750   \n",
       "1    1   2   7 -1.357931 -1.337451  0.211405           -0.528888   \n",
       "2    1   2  11 -1.357931 -1.337451  1.105281           -0.447648   \n",
       "3    1   7   3 -1.357931  0.270708 -1.316686           -0.447229   \n",
       "4    1   7   7 -1.357931  0.270708  0.211405           -0.922506   \n",
       "5    1   7  11 -1.357931  0.270708  1.105281           -0.822324   \n",
       "6    1  12   3 -1.357931  1.066743 -1.316686           -0.506590   \n",
       "7    1  12   7 -1.357931  1.066743  0.211405           -0.755358   \n",
       "8    1  12  11 -1.357931  1.066743  1.105281           -0.652738   \n",
       "9    7   2   3  0.336886 -1.337451 -1.316686            0.628385   \n",
       "10   7   2   7  0.336886 -1.337451  0.211405            0.707020   \n",
       "11   7   2  11  0.336886 -1.337451  1.105281            0.801478   \n",
       "12   7   7   3  0.336886  0.270708 -1.316686            0.606207   \n",
       "13   7   7   7  0.336886  0.270708  0.211405           -1.977386   \n",
       "14   7   7  11  0.336886  0.270708  1.105281           -1.208969   \n",
       "15   7  12   3  0.336886  1.066743 -1.316686            0.736237   \n",
       "16   7  12   7  0.336886  1.066743  0.211405           -1.192925   \n",
       "17   7  12  11  0.336886  1.066743  1.105281           -0.574138   \n",
       "18  13   2   3  1.021045 -1.337451 -1.316686            1.559954   \n",
       "19  13   2   7  1.021045 -1.337451  0.211405            1.598503   \n",
       "20  13   2  11  1.021045 -1.337451  1.105281            1.728613   \n",
       "21  13   7   3  1.021045  0.270708 -1.316686            1.496816   \n",
       "22  13   7   7  1.021045  0.270708  0.211405           -0.814077   \n",
       "23  13   7  11  1.021045  0.270708  1.105281           -0.247788   \n",
       "24  13  12   3  1.021045  1.066743 -1.316686            1.634840   \n",
       "25  13  12   7  1.021045  1.066743  0.211405           -0.059455   \n",
       "26  13  12  11  1.021045  1.066743  1.105281            0.212718   \n",
       "\n",
       "    Total Loss at 50  Avg Loss 0-50  dist_from0  dist_from1  dist_from2  \\\n",
       "0          -0.606017      -0.647231         1.0         0.1         0.1   \n",
       "1          -0.610003      -0.651601         1.0         0.1         0.1   \n",
       "2          -0.599378      -0.623454         1.0         0.1         0.1   \n",
       "3          -0.662263      -0.665812         1.0         0.1         0.1   \n",
       "4          -0.766860      -0.812981         1.0         0.1         0.1   \n",
       "5          -0.767863      -0.813792         1.0         0.1         0.1   \n",
       "6          -0.722144      -0.685461         1.0         0.1         0.1   \n",
       "7          -0.768687      -0.807436         1.0         0.1         0.1   \n",
       "8          -0.769890      -0.805635         1.0         0.1         0.1   \n",
       "9           1.085074       0.973400         0.1         1.0         0.1   \n",
       "10          0.992458       0.929765         0.1         1.0         0.1   \n",
       "11          0.983218       0.991927         0.1         1.0         0.1   \n",
       "12          0.815648       0.797870         0.1         1.0         0.1   \n",
       "13         -0.763410      -0.850788         0.1         0.1         1.0   \n",
       "14         -0.768068      -0.833252         0.1         0.1         1.0   \n",
       "15          0.029045       0.460709         0.1         1.0         0.1   \n",
       "16         -0.767233      -0.830689         0.1         0.1         1.0   \n",
       "17         -0.768989      -0.799679         0.1         0.1         1.0   \n",
       "18          1.930742       1.804001         0.1         1.0         0.1   \n",
       "19          1.891407       1.772269         0.1         1.0         0.1   \n",
       "20          1.829878       1.808205         0.1         1.0         0.1   \n",
       "21          1.751257       1.687899         0.1         1.0         0.1   \n",
       "22         -0.704586      -0.683205         0.1         0.1         1.0   \n",
       "23         -0.719647      -0.683076         0.1         0.1         1.0   \n",
       "24          0.850517       1.250954         0.1         1.0         0.1   \n",
       "25         -0.666047      -0.679502         0.1         0.1         1.0   \n",
       "26         -0.728159      -0.603406         0.1         0.1         1.0   \n",
       "\n",
       "    Cluster  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "5         0  \n",
       "6         0  \n",
       "7         0  \n",
       "8         0  \n",
       "9         1  \n",
       "10        1  \n",
       "11        1  \n",
       "12        1  \n",
       "13        2  \n",
       "14        2  \n",
       "15        1  \n",
       "16        2  \n",
       "17        2  \n",
       "18        1  \n",
       "19        1  \n",
       "20        1  \n",
       "21        1  \n",
       "22        2  \n",
       "23        2  \n",
       "24        1  \n",
       "25        2  \n",
       "26        2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실험 데이터 로드\n",
    "data1 = pd.read_csv('./NewABC_cluster_results_newsdist(0.1).csv')\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T02:02:37.638068Z",
     "iopub.status.busy": "2024-04-23T02:02:37.637940Z",
     "iopub.status.idle": "2024-04-23T02:02:37.651348Z",
     "shell.execute_reply": "2024-04-23T02:02:37.650934Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>A_scaled</th>\n",
       "      <th>B_scaled</th>\n",
       "      <th>C_scaled</th>\n",
       "      <th>Initial Total Loss</th>\n",
       "      <th>Total Loss at 50</th>\n",
       "      <th>Avg Loss 0-50</th>\n",
       "      <th>dist_from0</th>\n",
       "      <th>dist_from1</th>\n",
       "      <th>dist_from2</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>-0.552750</td>\n",
       "      <td>-0.606017</td>\n",
       "      <td>-0.647231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-0.528888</td>\n",
       "      <td>-0.610003</td>\n",
       "      <td>-0.651601</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-0.447648</td>\n",
       "      <td>-0.599378</td>\n",
       "      <td>-0.623454</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>-0.447229</td>\n",
       "      <td>-0.662263</td>\n",
       "      <td>-0.665812</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-0.922506</td>\n",
       "      <td>-0.766860</td>\n",
       "      <td>-0.812981</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-0.822324</td>\n",
       "      <td>-0.767863</td>\n",
       "      <td>-0.813792</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>-0.506590</td>\n",
       "      <td>-0.722144</td>\n",
       "      <td>-0.685461</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-0.755358</td>\n",
       "      <td>-0.768687</td>\n",
       "      <td>-0.807436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-0.652738</td>\n",
       "      <td>-0.769890</td>\n",
       "      <td>-0.805635</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>0.628385</td>\n",
       "      <td>1.085074</td>\n",
       "      <td>0.973400</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>0.707020</td>\n",
       "      <td>0.992458</td>\n",
       "      <td>0.929765</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>0.801478</td>\n",
       "      <td>0.983218</td>\n",
       "      <td>0.991927</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>0.606207</td>\n",
       "      <td>0.815648</td>\n",
       "      <td>0.797870</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-1.977386</td>\n",
       "      <td>-0.763410</td>\n",
       "      <td>-0.850788</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-1.208969</td>\n",
       "      <td>-0.768068</td>\n",
       "      <td>-0.833252</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>0.736237</td>\n",
       "      <td>0.029045</td>\n",
       "      <td>0.460709</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-1.192925</td>\n",
       "      <td>-0.767233</td>\n",
       "      <td>-0.830689</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-0.574138</td>\n",
       "      <td>-0.768989</td>\n",
       "      <td>-0.799679</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>1.559954</td>\n",
       "      <td>1.930742</td>\n",
       "      <td>1.804001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>1.598503</td>\n",
       "      <td>1.891407</td>\n",
       "      <td>1.772269</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>1.728613</td>\n",
       "      <td>1.829878</td>\n",
       "      <td>1.808205</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>1.496816</td>\n",
       "      <td>1.751257</td>\n",
       "      <td>1.687899</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-0.814077</td>\n",
       "      <td>-0.704586</td>\n",
       "      <td>-0.683205</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-0.247788</td>\n",
       "      <td>-0.719647</td>\n",
       "      <td>-0.683076</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>1.634840</td>\n",
       "      <td>0.850517</td>\n",
       "      <td>1.250954</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-0.059455</td>\n",
       "      <td>-0.666047</td>\n",
       "      <td>-0.679502</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>0.212718</td>\n",
       "      <td>-0.728159</td>\n",
       "      <td>-0.603406</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A   B   C  A_scaled  B_scaled  C_scaled  Initial Total Loss  \\\n",
       "0    1   2   3 -1.357931 -1.337451 -1.316686           -0.552750   \n",
       "1    1   2   7 -1.357931 -1.337451  0.211405           -0.528888   \n",
       "2    1   2  11 -1.357931 -1.337451  1.105281           -0.447648   \n",
       "3    1   7   3 -1.357931  0.270708 -1.316686           -0.447229   \n",
       "4    1   7   7 -1.357931  0.270708  0.211405           -0.922506   \n",
       "5    1   7  11 -1.357931  0.270708  1.105281           -0.822324   \n",
       "6    1  12   3 -1.357931  1.066743 -1.316686           -0.506590   \n",
       "7    1  12   7 -1.357931  1.066743  0.211405           -0.755358   \n",
       "8    1  12  11 -1.357931  1.066743  1.105281           -0.652738   \n",
       "9    7   2   3  0.336886 -1.337451 -1.316686            0.628385   \n",
       "10   7   2   7  0.336886 -1.337451  0.211405            0.707020   \n",
       "11   7   2  11  0.336886 -1.337451  1.105281            0.801478   \n",
       "12   7   7   3  0.336886  0.270708 -1.316686            0.606207   \n",
       "13   7   7   7  0.336886  0.270708  0.211405           -1.977386   \n",
       "14   7   7  11  0.336886  0.270708  1.105281           -1.208969   \n",
       "15   7  12   3  0.336886  1.066743 -1.316686            0.736237   \n",
       "16   7  12   7  0.336886  1.066743  0.211405           -1.192925   \n",
       "17   7  12  11  0.336886  1.066743  1.105281           -0.574138   \n",
       "18  13   2   3  1.021045 -1.337451 -1.316686            1.559954   \n",
       "19  13   2   7  1.021045 -1.337451  0.211405            1.598503   \n",
       "20  13   2  11  1.021045 -1.337451  1.105281            1.728613   \n",
       "21  13   7   3  1.021045  0.270708 -1.316686            1.496816   \n",
       "22  13   7   7  1.021045  0.270708  0.211405           -0.814077   \n",
       "23  13   7  11  1.021045  0.270708  1.105281           -0.247788   \n",
       "24  13  12   3  1.021045  1.066743 -1.316686            1.634840   \n",
       "25  13  12   7  1.021045  1.066743  0.211405           -0.059455   \n",
       "26  13  12  11  1.021045  1.066743  1.105281            0.212718   \n",
       "\n",
       "    Total Loss at 50  Avg Loss 0-50  dist_from0  dist_from1  dist_from2  \\\n",
       "0          -0.606017      -0.647231         1.0         0.1         0.1   \n",
       "1          -0.610003      -0.651601         1.0         0.1         0.1   \n",
       "2          -0.599378      -0.623454         1.0         0.1         0.1   \n",
       "3          -0.662263      -0.665812         1.0         0.1         0.1   \n",
       "4          -0.766860      -0.812981         1.0         0.1         0.1   \n",
       "5          -0.767863      -0.813792         1.0         0.1         0.1   \n",
       "6          -0.722144      -0.685461         1.0         0.1         0.1   \n",
       "7          -0.768687      -0.807436         1.0         0.1         0.1   \n",
       "8          -0.769890      -0.805635         1.0         0.1         0.1   \n",
       "9           1.085074       0.973400         0.1         1.0         0.1   \n",
       "10          0.992458       0.929765         0.1         1.0         0.1   \n",
       "11          0.983218       0.991927         0.1         1.0         0.1   \n",
       "12          0.815648       0.797870         0.1         1.0         0.1   \n",
       "13         -0.763410      -0.850788         0.1         0.1         1.0   \n",
       "14         -0.768068      -0.833252         0.1         0.1         1.0   \n",
       "15          0.029045       0.460709         0.1         1.0         0.1   \n",
       "16         -0.767233      -0.830689         0.1         0.1         1.0   \n",
       "17         -0.768989      -0.799679         0.1         0.1         1.0   \n",
       "18          1.930742       1.804001         0.1         1.0         0.1   \n",
       "19          1.891407       1.772269         0.1         1.0         0.1   \n",
       "20          1.829878       1.808205         0.1         1.0         0.1   \n",
       "21          1.751257       1.687899         0.1         1.0         0.1   \n",
       "22         -0.704586      -0.683205         0.1         0.1         1.0   \n",
       "23         -0.719647      -0.683076         0.1         0.1         1.0   \n",
       "24          0.850517       1.250954         0.1         1.0         0.1   \n",
       "25         -0.666047      -0.679502         0.1         0.1         1.0   \n",
       "26         -0.728159      -0.603406         0.1         0.1         1.0   \n",
       "\n",
       "    Cluster  Number  \n",
       "0         0       1  \n",
       "1         0       2  \n",
       "2         0       3  \n",
       "3         0       4  \n",
       "4         0       5  \n",
       "5         0       6  \n",
       "6         0       7  \n",
       "7         0       8  \n",
       "8         0       9  \n",
       "9         1      10  \n",
       "10        1      11  \n",
       "11        1      12  \n",
       "12        1      13  \n",
       "13        2      14  \n",
       "14        2      15  \n",
       "15        1      16  \n",
       "16        2      17  \n",
       "17        2      18  \n",
       "18        1      19  \n",
       "19        1      20  \n",
       "20        1      21  \n",
       "21        1      22  \n",
       "22        2      23  \n",
       "23        2      24  \n",
       "24        1      25  \n",
       "25        2      26  \n",
       "26        2      27  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0. 데이터프레임에 'Number' 인덱스 추가\n",
    "data1['Number'] = range(1, 28)\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T02:02:37.653645Z",
     "iopub.status.busy": "2024-04-23T02:02:37.653442Z",
     "iopub.status.idle": "2024-04-23T02:02:37.666261Z",
     "shell.execute_reply": "2024-04-23T02:02:37.665841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>A_scaled</th>\n",
       "      <th>B_scaled</th>\n",
       "      <th>C_scaled</th>\n",
       "      <th>Initial Total Loss</th>\n",
       "      <th>Total Loss at 50</th>\n",
       "      <th>Avg Loss 0-50</th>\n",
       "      <th>dist_from0</th>\n",
       "      <th>dist_from1</th>\n",
       "      <th>dist_from2</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>-0.552750</td>\n",
       "      <td>-0.606017</td>\n",
       "      <td>-0.647231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-0.528888</td>\n",
       "      <td>-0.610003</td>\n",
       "      <td>-0.651601</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-0.447648</td>\n",
       "      <td>-0.599378</td>\n",
       "      <td>-0.623454</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>-0.447229</td>\n",
       "      <td>-0.662263</td>\n",
       "      <td>-0.665812</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-0.922506</td>\n",
       "      <td>-0.766860</td>\n",
       "      <td>-0.812981</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-0.822324</td>\n",
       "      <td>-0.767863</td>\n",
       "      <td>-0.813792</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>-0.506590</td>\n",
       "      <td>-0.722144</td>\n",
       "      <td>-0.685461</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-0.755358</td>\n",
       "      <td>-0.768687</td>\n",
       "      <td>-0.807436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-0.652738</td>\n",
       "      <td>-0.769890</td>\n",
       "      <td>-0.805635</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>0.628385</td>\n",
       "      <td>1.085074</td>\n",
       "      <td>0.973400</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>0.707020</td>\n",
       "      <td>0.992458</td>\n",
       "      <td>0.929765</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>0.801478</td>\n",
       "      <td>0.983218</td>\n",
       "      <td>0.991927</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>0.606207</td>\n",
       "      <td>0.815648</td>\n",
       "      <td>0.797870</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-1.977386</td>\n",
       "      <td>-0.763410</td>\n",
       "      <td>-0.850788</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-1.208969</td>\n",
       "      <td>-0.768068</td>\n",
       "      <td>-0.833252</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>0.736237</td>\n",
       "      <td>0.029045</td>\n",
       "      <td>0.460709</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-1.192925</td>\n",
       "      <td>-0.767233</td>\n",
       "      <td>-0.830689</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-0.574138</td>\n",
       "      <td>-0.768989</td>\n",
       "      <td>-0.799679</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>1.559954</td>\n",
       "      <td>1.930742</td>\n",
       "      <td>1.804001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>1.598503</td>\n",
       "      <td>1.891407</td>\n",
       "      <td>1.772269</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>1.728613</td>\n",
       "      <td>1.829878</td>\n",
       "      <td>1.808205</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>1.496816</td>\n",
       "      <td>1.751257</td>\n",
       "      <td>1.687899</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-0.814077</td>\n",
       "      <td>-0.704586</td>\n",
       "      <td>-0.683205</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-0.247788</td>\n",
       "      <td>-0.719647</td>\n",
       "      <td>-0.683076</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>1.634840</td>\n",
       "      <td>0.850517</td>\n",
       "      <td>1.250954</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-0.059455</td>\n",
       "      <td>-0.666047</td>\n",
       "      <td>-0.679502</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>0.212718</td>\n",
       "      <td>-0.728159</td>\n",
       "      <td>-0.603406</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A   B   C  A_scaled  B_scaled  C_scaled  Initial Total Loss  \\\n",
       "0    1   2   3 -1.357931 -1.337451 -1.316686           -0.552750   \n",
       "1    1   2   7 -1.357931 -1.337451  0.211405           -0.528888   \n",
       "2    1   2  11 -1.357931 -1.337451  1.105281           -0.447648   \n",
       "3    1   7   3 -1.357931  0.270708 -1.316686           -0.447229   \n",
       "4    1   7   7 -1.357931  0.270708  0.211405           -0.922506   \n",
       "5    1   7  11 -1.357931  0.270708  1.105281           -0.822324   \n",
       "6    1  12   3 -1.357931  1.066743 -1.316686           -0.506590   \n",
       "7    1  12   7 -1.357931  1.066743  0.211405           -0.755358   \n",
       "8    1  12  11 -1.357931  1.066743  1.105281           -0.652738   \n",
       "9    7   2   3  0.336886 -1.337451 -1.316686            0.628385   \n",
       "10   7   2   7  0.336886 -1.337451  0.211405            0.707020   \n",
       "11   7   2  11  0.336886 -1.337451  1.105281            0.801478   \n",
       "12   7   7   3  0.336886  0.270708 -1.316686            0.606207   \n",
       "13   7   7   7  0.336886  0.270708  0.211405           -1.977386   \n",
       "14   7   7  11  0.336886  0.270708  1.105281           -1.208969   \n",
       "15   7  12   3  0.336886  1.066743 -1.316686            0.736237   \n",
       "16   7  12   7  0.336886  1.066743  0.211405           -1.192925   \n",
       "17   7  12  11  0.336886  1.066743  1.105281           -0.574138   \n",
       "18  13   2   3  1.021045 -1.337451 -1.316686            1.559954   \n",
       "19  13   2   7  1.021045 -1.337451  0.211405            1.598503   \n",
       "20  13   2  11  1.021045 -1.337451  1.105281            1.728613   \n",
       "21  13   7   3  1.021045  0.270708 -1.316686            1.496816   \n",
       "22  13   7   7  1.021045  0.270708  0.211405           -0.814077   \n",
       "23  13   7  11  1.021045  0.270708  1.105281           -0.247788   \n",
       "24  13  12   3  1.021045  1.066743 -1.316686            1.634840   \n",
       "25  13  12   7  1.021045  1.066743  0.211405           -0.059455   \n",
       "26  13  12  11  1.021045  1.066743  1.105281            0.212718   \n",
       "\n",
       "    Total Loss at 50  Avg Loss 0-50  dist_from0  dist_from1  dist_from2  \\\n",
       "0          -0.606017      -0.647231         1.0         0.1         0.1   \n",
       "1          -0.610003      -0.651601         1.0         0.1         0.1   \n",
       "2          -0.599378      -0.623454         1.0         0.1         0.1   \n",
       "3          -0.662263      -0.665812         1.0         0.1         0.1   \n",
       "4          -0.766860      -0.812981         1.0         0.1         0.1   \n",
       "5          -0.767863      -0.813792         1.0         0.1         0.1   \n",
       "6          -0.722144      -0.685461         1.0         0.1         0.1   \n",
       "7          -0.768687      -0.807436         1.0         0.1         0.1   \n",
       "8          -0.769890      -0.805635         1.0         0.1         0.1   \n",
       "9           1.085074       0.973400         0.1         1.0         0.1   \n",
       "10          0.992458       0.929765         0.1         1.0         0.1   \n",
       "11          0.983218       0.991927         0.1         1.0         0.1   \n",
       "12          0.815648       0.797870         0.1         1.0         0.1   \n",
       "13         -0.763410      -0.850788         0.1         0.1         1.0   \n",
       "14         -0.768068      -0.833252         0.1         0.1         1.0   \n",
       "15          0.029045       0.460709         0.1         1.0         0.1   \n",
       "16         -0.767233      -0.830689         0.1         0.1         1.0   \n",
       "17         -0.768989      -0.799679         0.1         0.1         1.0   \n",
       "18          1.930742       1.804001         0.1         1.0         0.1   \n",
       "19          1.891407       1.772269         0.1         1.0         0.1   \n",
       "20          1.829878       1.808205         0.1         1.0         0.1   \n",
       "21          1.751257       1.687899         0.1         1.0         0.1   \n",
       "22         -0.704586      -0.683205         0.1         0.1         1.0   \n",
       "23         -0.719647      -0.683076         0.1         0.1         1.0   \n",
       "24          0.850517       1.250954         0.1         1.0         0.1   \n",
       "25         -0.666047      -0.679502         0.1         0.1         1.0   \n",
       "26         -0.728159      -0.603406         0.1         0.1         1.0   \n",
       "\n",
       "    Cluster  Number  \n",
       "0         0       1  \n",
       "1         0       2  \n",
       "2         0       3  \n",
       "3         0       4  \n",
       "4         0       5  \n",
       "5         0       6  \n",
       "6         0       7  \n",
       "7         0       8  \n",
       "8         0       9  \n",
       "9         1      10  \n",
       "10        1      11  \n",
       "11        1      12  \n",
       "12        1      13  \n",
       "13        2      14  \n",
       "14        2      15  \n",
       "15        1      16  \n",
       "16        2      17  \n",
       "17        2      18  \n",
       "18        1      19  \n",
       "19        1      20  \n",
       "20        1      21  \n",
       "21        1      22  \n",
       "22        2      23  \n",
       "23        2      24  \n",
       "24        1      25  \n",
       "25        2      26  \n",
       "26        2      27  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2=data1.copy()\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T02:02:37.668887Z",
     "iopub.status.busy": "2024-04-23T02:02:37.668736Z",
     "iopub.status.idle": "2024-04-23T02:02:37.671802Z",
     "shell.execute_reply": "2024-04-23T02:02:37.671375Z"
    }
   },
   "outputs": [],
   "source": [
    "origin_columns = ['A_scaled', 'B_scaled', 'C_scaled', 'Initial Total Loss', 'Total Loss at 50', 'Avg Loss 0-50']\n",
    "origin = data2.loc[13, origin_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T02:02:37.673933Z",
     "iopub.status.busy": "2024-04-23T02:02:37.673810Z",
     "iopub.status.idle": "2024-04-23T02:02:37.676793Z",
     "shell.execute_reply": "2024-04-23T02:02:37.676407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.33688572,  0.27070835,  0.21140502, -1.97738581, -0.76340968,\n",
       "       -0.85078787])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T02:02:37.679302Z",
     "iopub.status.busy": "2024-04-23T02:02:37.679044Z",
     "iopub.status.idle": "2024-04-23T02:02:37.700869Z",
     "shell.execute_reply": "2024-04-23T02:02:37.700421Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>A_scaled</th>\n",
       "      <th>B_scaled</th>\n",
       "      <th>C_scaled</th>\n",
       "      <th>Initial Total Loss</th>\n",
       "      <th>Total Loss at 50</th>\n",
       "      <th>Avg Loss 0-50</th>\n",
       "      <th>dist_from0</th>\n",
       "      <th>dist_from1</th>\n",
       "      <th>dist_from2</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Number</th>\n",
       "      <th>Euclidean Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>-0.552750</td>\n",
       "      <td>-0.606017</td>\n",
       "      <td>-0.647231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.144748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-0.528888</td>\n",
       "      <td>-0.610003</td>\n",
       "      <td>-0.651601</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.760423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-0.447648</td>\n",
       "      <td>-0.599378</td>\n",
       "      <td>-0.623454</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.945552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>-0.447229</td>\n",
       "      <td>-0.662263</td>\n",
       "      <td>-0.665812</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.755592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-0.922506</td>\n",
       "      <td>-0.766860</td>\n",
       "      <td>-0.812981</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.996651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-0.822324</td>\n",
       "      <td>-0.767863</td>\n",
       "      <td>-0.813792</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.237627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>-0.506590</td>\n",
       "      <td>-0.722144</td>\n",
       "      <td>-0.685461</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.834327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-0.755358</td>\n",
       "      <td>-0.768687</td>\n",
       "      <td>-0.807436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2.236366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-0.652738</td>\n",
       "      <td>-0.769890</td>\n",
       "      <td>-0.805635</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2.462084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>0.628385</td>\n",
       "      <td>1.085074</td>\n",
       "      <td>0.973400</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4.296026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>0.707020</td>\n",
       "      <td>0.992458</td>\n",
       "      <td>0.929765</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4.005703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>0.801478</td>\n",
       "      <td>0.983218</td>\n",
       "      <td>0.991927</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>4.189699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>0.606207</td>\n",
       "      <td>0.815648</td>\n",
       "      <td>0.797870</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>3.771142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-1.977386</td>\n",
       "      <td>-0.763410</td>\n",
       "      <td>-0.850788</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-1.208969</td>\n",
       "      <td>-0.768068</td>\n",
       "      <td>-0.833252</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1.178901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>0.736237</td>\n",
       "      <td>0.029045</td>\n",
       "      <td>0.460709</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3.560968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-1.192925</td>\n",
       "      <td>-0.767233</td>\n",
       "      <td>-0.830689</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>1.117797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-0.574138</td>\n",
       "      <td>-0.768989</td>\n",
       "      <td>-0.799679</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>1.845110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>1.559954</td>\n",
       "      <td>1.930742</td>\n",
       "      <td>1.804001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>5.675248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>1.598503</td>\n",
       "      <td>1.891407</td>\n",
       "      <td>1.772269</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>5.456163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>1.728613</td>\n",
       "      <td>1.829878</td>\n",
       "      <td>1.808205</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>5.602060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>1.496816</td>\n",
       "      <td>1.751257</td>\n",
       "      <td>1.687899</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>5.257537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-0.814077</td>\n",
       "      <td>-0.704586</td>\n",
       "      <td>-0.683205</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1.361214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-0.247788</td>\n",
       "      <td>-0.719647</td>\n",
       "      <td>-0.683076</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>2.070903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>1.634840</td>\n",
       "      <td>0.850517</td>\n",
       "      <td>1.250954</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>4.848408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-0.059455</td>\n",
       "      <td>-0.666047</td>\n",
       "      <td>-0.679502</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>2.195227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>0.212718</td>\n",
       "      <td>-0.728159</td>\n",
       "      <td>-0.603406</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>2.599952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A   B   C  A_scaled  B_scaled  C_scaled  Initial Total Loss  \\\n",
       "0    1   2   3 -1.357931 -1.337451 -1.316686           -0.552750   \n",
       "1    1   2   7 -1.357931 -1.337451  0.211405           -0.528888   \n",
       "2    1   2  11 -1.357931 -1.337451  1.105281           -0.447648   \n",
       "3    1   7   3 -1.357931  0.270708 -1.316686           -0.447229   \n",
       "4    1   7   7 -1.357931  0.270708  0.211405           -0.922506   \n",
       "5    1   7  11 -1.357931  0.270708  1.105281           -0.822324   \n",
       "6    1  12   3 -1.357931  1.066743 -1.316686           -0.506590   \n",
       "7    1  12   7 -1.357931  1.066743  0.211405           -0.755358   \n",
       "8    1  12  11 -1.357931  1.066743  1.105281           -0.652738   \n",
       "9    7   2   3  0.336886 -1.337451 -1.316686            0.628385   \n",
       "10   7   2   7  0.336886 -1.337451  0.211405            0.707020   \n",
       "11   7   2  11  0.336886 -1.337451  1.105281            0.801478   \n",
       "12   7   7   3  0.336886  0.270708 -1.316686            0.606207   \n",
       "13   7   7   7  0.336886  0.270708  0.211405           -1.977386   \n",
       "14   7   7  11  0.336886  0.270708  1.105281           -1.208969   \n",
       "15   7  12   3  0.336886  1.066743 -1.316686            0.736237   \n",
       "16   7  12   7  0.336886  1.066743  0.211405           -1.192925   \n",
       "17   7  12  11  0.336886  1.066743  1.105281           -0.574138   \n",
       "18  13   2   3  1.021045 -1.337451 -1.316686            1.559954   \n",
       "19  13   2   7  1.021045 -1.337451  0.211405            1.598503   \n",
       "20  13   2  11  1.021045 -1.337451  1.105281            1.728613   \n",
       "21  13   7   3  1.021045  0.270708 -1.316686            1.496816   \n",
       "22  13   7   7  1.021045  0.270708  0.211405           -0.814077   \n",
       "23  13   7  11  1.021045  0.270708  1.105281           -0.247788   \n",
       "24  13  12   3  1.021045  1.066743 -1.316686            1.634840   \n",
       "25  13  12   7  1.021045  1.066743  0.211405           -0.059455   \n",
       "26  13  12  11  1.021045  1.066743  1.105281            0.212718   \n",
       "\n",
       "    Total Loss at 50  Avg Loss 0-50  dist_from0  dist_from1  dist_from2  \\\n",
       "0          -0.606017      -0.647231         1.0         0.1         0.1   \n",
       "1          -0.610003      -0.651601         1.0         0.1         0.1   \n",
       "2          -0.599378      -0.623454         1.0         0.1         0.1   \n",
       "3          -0.662263      -0.665812         1.0         0.1         0.1   \n",
       "4          -0.766860      -0.812981         1.0         0.1         0.1   \n",
       "5          -0.767863      -0.813792         1.0         0.1         0.1   \n",
       "6          -0.722144      -0.685461         1.0         0.1         0.1   \n",
       "7          -0.768687      -0.807436         1.0         0.1         0.1   \n",
       "8          -0.769890      -0.805635         1.0         0.1         0.1   \n",
       "9           1.085074       0.973400         0.1         1.0         0.1   \n",
       "10          0.992458       0.929765         0.1         1.0         0.1   \n",
       "11          0.983218       0.991927         0.1         1.0         0.1   \n",
       "12          0.815648       0.797870         0.1         1.0         0.1   \n",
       "13         -0.763410      -0.850788         0.1         0.1         1.0   \n",
       "14         -0.768068      -0.833252         0.1         0.1         1.0   \n",
       "15          0.029045       0.460709         0.1         1.0         0.1   \n",
       "16         -0.767233      -0.830689         0.1         0.1         1.0   \n",
       "17         -0.768989      -0.799679         0.1         0.1         1.0   \n",
       "18          1.930742       1.804001         0.1         1.0         0.1   \n",
       "19          1.891407       1.772269         0.1         1.0         0.1   \n",
       "20          1.829878       1.808205         0.1         1.0         0.1   \n",
       "21          1.751257       1.687899         0.1         1.0         0.1   \n",
       "22         -0.704586      -0.683205         0.1         0.1         1.0   \n",
       "23         -0.719647      -0.683076         0.1         0.1         1.0   \n",
       "24          0.850517       1.250954         0.1         1.0         0.1   \n",
       "25         -0.666047      -0.679502         0.1         0.1         1.0   \n",
       "26         -0.728159      -0.603406         0.1         0.1         1.0   \n",
       "\n",
       "    Cluster  Number  Euclidean Distance  \n",
       "0         0       1            3.144748  \n",
       "1         0       2            2.760423  \n",
       "2         0       3            2.945552  \n",
       "3         0       4            2.755592  \n",
       "4         0       5            1.996651  \n",
       "5         0       6            2.237627  \n",
       "6         0       7            2.834327  \n",
       "7         0       8            2.236366  \n",
       "8         0       9            2.462084  \n",
       "9         1      10            4.296026  \n",
       "10        1      11            4.005703  \n",
       "11        1      12            4.189699  \n",
       "12        1      13            3.771142  \n",
       "13        2      14            0.000000  \n",
       "14        2      15            1.178901  \n",
       "15        1      16            3.560968  \n",
       "16        2      17            1.117797  \n",
       "17        2      18            1.845110  \n",
       "18        1      19            5.675248  \n",
       "19        1      20            5.456163  \n",
       "20        1      21            5.602060  \n",
       "21        1      22            5.257537  \n",
       "22        2      23            1.361214  \n",
       "23        2      24            2.070903  \n",
       "24        1      25            4.848408  \n",
       "25        2      26            2.195227  \n",
       "26        2      27            2.599952  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유클리드 거리 계산 함수\n",
    "def euclidean_distance(row, origin):\n",
    "    return np.sqrt(np.sum((row - origin) ** 2))\n",
    "\n",
    "# 데이터프레임에 유클리드 거리 계산 및 추가\n",
    "def add_euclidean_distance(df, origin):\n",
    "    # 유클리드 거리 계산에 사용될 컬럼 선택\n",
    "    cols = ['A_scaled', 'B_scaled', 'C_scaled', 'Initial Total Loss', 'Total Loss at 50', 'Avg Loss 0-50']\n",
    "    df['Euclidean Distance'] = df.apply(lambda row: euclidean_distance(row[cols].values, origin), axis=1)\n",
    "    return df\n",
    "\n",
    "# 원본 데이터프레임에 유클리드 거리 추가\n",
    "data2 = add_euclidean_distance(data2, origin)\n",
    "\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T02:02:37.703700Z",
     "iopub.status.busy": "2024-04-23T02:02:37.703450Z",
     "iopub.status.idle": "2024-04-23T02:02:37.725587Z",
     "shell.execute_reply": "2024-04-23T02:02:37.725093Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 1. 클러스터 종류별로 데이터 나누기\n",
    "cluster_2 = data2[data2['Cluster'] == 2.0]\n",
    "cluster_1 = data2[data2['Cluster'] == 1.0]\n",
    "cluster_0 = data2[data2['Cluster'] == 0.0]\n",
    "\n",
    "# 2. 각 클러스터에서 가장 짧은 길이만큼 데이터 추출\n",
    "min_length = min(len(cluster_2), len(cluster_1), len(cluster_0))\n",
    "\n",
    "# 클러스터 데이터 복사 (비복원 추출을 위해)\n",
    "copy_cluster_2 = cluster_2.copy()\n",
    "copy_cluster_1 = cluster_1.copy()\n",
    "copy_cluster_0 = cluster_0.copy()\n",
    "\n",
    "# # 2, 1, 0 순으로 데이터 추출하여 새로운 데이터프레임 생성 (비복원 추출)\n",
    "# extracted_rows = []\n",
    "# for _ in range(min_length):\n",
    "#     for cluster in [copy_cluster_2, copy_cluster_1, copy_cluster_0]:\n",
    "#         if not cluster.empty:\n",
    "#             # 랜덤 추출 후 선택된 행을 리스트에서 제거\n",
    "#             row = cluster.sample(n=1)\n",
    "#             extracted_rows.append(row)\n",
    "#             cluster.drop(row.index, inplace=True)\n",
    "\n",
    "# # 추출된 행들을 병합하여 새 데이터프레임 생성\n",
    "# data_new = pd.concat(extracted_rows).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# 각 클러스터에서 유클리드 거리가 가장 작은 데이터 추출 및 비복원 추출을 위해 데이터프레임 생성\n",
    "extracted_rows = []\n",
    "for _ in range(min_length):\n",
    "    for cluster_copy in [copy_cluster_2, copy_cluster_1, copy_cluster_0]:\n",
    "        # 유클리드 거리가 가장 작은 행을 찾음\n",
    "        row = cluster_copy.sort_values(by='Euclidean Distance').head(1)\n",
    "        extracted_rows.append(row)\n",
    "        # 추출된 행을 복사본 데이터프레임에서 제거\n",
    "        cluster_copy.drop(row.index, inplace=True)\n",
    "\n",
    "# 추출된 행들을 병합하여 새 데이터프레임 생성\n",
    "data_new = pd.concat(extracted_rows, ignore_index=True)\n",
    "\n",
    "\n",
    "# 3. 남은 데이터 추가\n",
    "longest_length = max(len(cluster_2), len(cluster_1), len(cluster_0))\n",
    "remaining_steps = longest_length - min_length\n",
    "\n",
    "# 원본 클러스터 길이 저장\n",
    "original_lengths = {\n",
    "    2: len(cluster_2),\n",
    "    1: len(cluster_1),\n",
    "    0: len(cluster_0)\n",
    "}\n",
    "\n",
    "# 남은 데이터 추가 로직 수정\n",
    "for _ in range(longest_length - min_length):\n",
    "    for cluster_num, copy_cluster in zip([2, 1, 0], [copy_cluster_2, copy_cluster_1, copy_cluster_0]):\n",
    "        if original_lengths[cluster_num] > len(data_new[data_new['Cluster'] == cluster_num]):\n",
    "            # 원본 길이가 더 클 경우, 복사한 클러스터에서 남은 데이터 중 하나 추가 (비복원 추출)\n",
    "            if not copy_cluster.empty:\n",
    "                row = copy_cluster.sample(n=1)\n",
    "                data_new = pd.concat([data_new, row])\n",
    "                copy_cluster.drop(row.index, inplace=True)\n",
    "        else:\n",
    "            # 원본 길이보다 data_new의 해당 클러스터 길이가 같거나 클 경우, 원본 클러스터에서 데이터 한 개 추가 (복원 추출)\n",
    "            row = data2[data2['Cluster'] == cluster_num].sample(n=1, replace=True)\n",
    "            data_new = pd.concat([data_new, row])\n",
    "\n",
    "# 데이터프레임 인덱스 재설정\n",
    "data = data_new.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T02:02:37.727997Z",
     "iopub.status.busy": "2024-04-23T02:02:37.727865Z",
     "iopub.status.idle": "2024-04-23T02:02:37.741951Z",
     "shell.execute_reply": "2024-04-23T02:02:37.741532Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>A_scaled</th>\n",
       "      <th>B_scaled</th>\n",
       "      <th>C_scaled</th>\n",
       "      <th>Initial Total Loss</th>\n",
       "      <th>Total Loss at 50</th>\n",
       "      <th>Avg Loss 0-50</th>\n",
       "      <th>dist_from0</th>\n",
       "      <th>dist_from1</th>\n",
       "      <th>dist_from2</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Number</th>\n",
       "      <th>Euclidean Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-1.977386</td>\n",
       "      <td>-0.763410</td>\n",
       "      <td>-0.850788</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>0.736237</td>\n",
       "      <td>0.029045</td>\n",
       "      <td>0.460709</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3.560968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-0.922506</td>\n",
       "      <td>-0.766860</td>\n",
       "      <td>-0.812981</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.996651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-1.192925</td>\n",
       "      <td>-0.767233</td>\n",
       "      <td>-0.830689</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>1.117797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>0.606207</td>\n",
       "      <td>0.815648</td>\n",
       "      <td>0.797870</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>3.771142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-0.755358</td>\n",
       "      <td>-0.768687</td>\n",
       "      <td>-0.807436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2.236366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-1.208969</td>\n",
       "      <td>-0.768068</td>\n",
       "      <td>-0.833252</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1.178901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>0.707020</td>\n",
       "      <td>0.992458</td>\n",
       "      <td>0.929765</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4.005703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-0.822324</td>\n",
       "      <td>-0.767863</td>\n",
       "      <td>-0.813792</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.237627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-0.814077</td>\n",
       "      <td>-0.704586</td>\n",
       "      <td>-0.683205</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1.361214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>0.801478</td>\n",
       "      <td>0.983218</td>\n",
       "      <td>0.991927</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>4.189699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-0.652738</td>\n",
       "      <td>-0.769890</td>\n",
       "      <td>-0.805635</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2.462084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-0.574138</td>\n",
       "      <td>-0.768989</td>\n",
       "      <td>-0.799679</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>1.845110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>0.628385</td>\n",
       "      <td>1.085074</td>\n",
       "      <td>0.973400</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4.296026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>-0.447229</td>\n",
       "      <td>-0.662263</td>\n",
       "      <td>-0.665812</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.755592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-0.247788</td>\n",
       "      <td>-0.719647</td>\n",
       "      <td>-0.683076</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>2.070903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>1.634840</td>\n",
       "      <td>0.850517</td>\n",
       "      <td>1.250954</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>4.848408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-0.528888</td>\n",
       "      <td>-0.610003</td>\n",
       "      <td>-0.651601</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.760423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-0.059455</td>\n",
       "      <td>-0.666047</td>\n",
       "      <td>-0.679502</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>2.195227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>1.496816</td>\n",
       "      <td>1.751257</td>\n",
       "      <td>1.687899</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>5.257537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>-0.506590</td>\n",
       "      <td>-0.722144</td>\n",
       "      <td>-0.685461</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.834327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>0.212718</td>\n",
       "      <td>-0.728159</td>\n",
       "      <td>-0.603406</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>2.599952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>1.598503</td>\n",
       "      <td>1.891407</td>\n",
       "      <td>1.772269</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>5.456163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>-0.447648</td>\n",
       "      <td>-0.599378</td>\n",
       "      <td>-0.623454</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.945552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-0.059455</td>\n",
       "      <td>-0.666047</td>\n",
       "      <td>-0.679502</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>2.195227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>1.559954</td>\n",
       "      <td>1.930742</td>\n",
       "      <td>1.804001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>5.675248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>-1.316686</td>\n",
       "      <td>-0.552750</td>\n",
       "      <td>-0.606017</td>\n",
       "      <td>-0.647231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.144748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-0.814077</td>\n",
       "      <td>-0.704586</td>\n",
       "      <td>-0.683205</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1.361214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>-1.337451</td>\n",
       "      <td>1.105281</td>\n",
       "      <td>1.728613</td>\n",
       "      <td>1.829878</td>\n",
       "      <td>1.808205</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>5.602060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.357931</td>\n",
       "      <td>1.066743</td>\n",
       "      <td>0.211405</td>\n",
       "      <td>-0.755358</td>\n",
       "      <td>-0.768687</td>\n",
       "      <td>-0.807436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2.236366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A   B   C  A_scaled  B_scaled  C_scaled  Initial Total Loss  \\\n",
       "0    7   7   7  0.336886  0.270708  0.211405           -1.977386   \n",
       "1    7  12   3  0.336886  1.066743 -1.316686            0.736237   \n",
       "2    1   7   7 -1.357931  0.270708  0.211405           -0.922506   \n",
       "3    7  12   7  0.336886  1.066743  0.211405           -1.192925   \n",
       "4    7   7   3  0.336886  0.270708 -1.316686            0.606207   \n",
       "5    1  12   7 -1.357931  1.066743  0.211405           -0.755358   \n",
       "6    7   7  11  0.336886  0.270708  1.105281           -1.208969   \n",
       "7    7   2   7  0.336886 -1.337451  0.211405            0.707020   \n",
       "8    1   7  11 -1.357931  0.270708  1.105281           -0.822324   \n",
       "9   13   7   7  1.021045  0.270708  0.211405           -0.814077   \n",
       "10   7   2  11  0.336886 -1.337451  1.105281            0.801478   \n",
       "11   1  12  11 -1.357931  1.066743  1.105281           -0.652738   \n",
       "12   7  12  11  0.336886  1.066743  1.105281           -0.574138   \n",
       "13   7   2   3  0.336886 -1.337451 -1.316686            0.628385   \n",
       "14   1   7   3 -1.357931  0.270708 -1.316686           -0.447229   \n",
       "15  13   7  11  1.021045  0.270708  1.105281           -0.247788   \n",
       "16  13  12   3  1.021045  1.066743 -1.316686            1.634840   \n",
       "17   1   2   7 -1.357931 -1.337451  0.211405           -0.528888   \n",
       "18  13  12   7  1.021045  1.066743  0.211405           -0.059455   \n",
       "19  13   7   3  1.021045  0.270708 -1.316686            1.496816   \n",
       "20   1  12   3 -1.357931  1.066743 -1.316686           -0.506590   \n",
       "21  13  12  11  1.021045  1.066743  1.105281            0.212718   \n",
       "22  13   2   7  1.021045 -1.337451  0.211405            1.598503   \n",
       "23   1   2  11 -1.357931 -1.337451  1.105281           -0.447648   \n",
       "24  13  12   7  1.021045  1.066743  0.211405           -0.059455   \n",
       "25  13   2   3  1.021045 -1.337451 -1.316686            1.559954   \n",
       "26   1   2   3 -1.357931 -1.337451 -1.316686           -0.552750   \n",
       "27  13   7   7  1.021045  0.270708  0.211405           -0.814077   \n",
       "28  13   2  11  1.021045 -1.337451  1.105281            1.728613   \n",
       "29   1  12   7 -1.357931  1.066743  0.211405           -0.755358   \n",
       "\n",
       "    Total Loss at 50  Avg Loss 0-50  dist_from0  dist_from1  dist_from2  \\\n",
       "0          -0.763410      -0.850788         0.1         0.1         1.0   \n",
       "1           0.029045       0.460709         0.1         1.0         0.1   \n",
       "2          -0.766860      -0.812981         1.0         0.1         0.1   \n",
       "3          -0.767233      -0.830689         0.1         0.1         1.0   \n",
       "4           0.815648       0.797870         0.1         1.0         0.1   \n",
       "5          -0.768687      -0.807436         1.0         0.1         0.1   \n",
       "6          -0.768068      -0.833252         0.1         0.1         1.0   \n",
       "7           0.992458       0.929765         0.1         1.0         0.1   \n",
       "8          -0.767863      -0.813792         1.0         0.1         0.1   \n",
       "9          -0.704586      -0.683205         0.1         0.1         1.0   \n",
       "10          0.983218       0.991927         0.1         1.0         0.1   \n",
       "11         -0.769890      -0.805635         1.0         0.1         0.1   \n",
       "12         -0.768989      -0.799679         0.1         0.1         1.0   \n",
       "13          1.085074       0.973400         0.1         1.0         0.1   \n",
       "14         -0.662263      -0.665812         1.0         0.1         0.1   \n",
       "15         -0.719647      -0.683076         0.1         0.1         1.0   \n",
       "16          0.850517       1.250954         0.1         1.0         0.1   \n",
       "17         -0.610003      -0.651601         1.0         0.1         0.1   \n",
       "18         -0.666047      -0.679502         0.1         0.1         1.0   \n",
       "19          1.751257       1.687899         0.1         1.0         0.1   \n",
       "20         -0.722144      -0.685461         1.0         0.1         0.1   \n",
       "21         -0.728159      -0.603406         0.1         0.1         1.0   \n",
       "22          1.891407       1.772269         0.1         1.0         0.1   \n",
       "23         -0.599378      -0.623454         1.0         0.1         0.1   \n",
       "24         -0.666047      -0.679502         0.1         0.1         1.0   \n",
       "25          1.930742       1.804001         0.1         1.0         0.1   \n",
       "26         -0.606017      -0.647231         1.0         0.1         0.1   \n",
       "27         -0.704586      -0.683205         0.1         0.1         1.0   \n",
       "28          1.829878       1.808205         0.1         1.0         0.1   \n",
       "29         -0.768687      -0.807436         1.0         0.1         0.1   \n",
       "\n",
       "    Cluster  Number  Euclidean Distance  \n",
       "0         2      14            0.000000  \n",
       "1         1      16            3.560968  \n",
       "2         0       5            1.996651  \n",
       "3         2      17            1.117797  \n",
       "4         1      13            3.771142  \n",
       "5         0       8            2.236366  \n",
       "6         2      15            1.178901  \n",
       "7         1      11            4.005703  \n",
       "8         0       6            2.237627  \n",
       "9         2      23            1.361214  \n",
       "10        1      12            4.189699  \n",
       "11        0       9            2.462084  \n",
       "12        2      18            1.845110  \n",
       "13        1      10            4.296026  \n",
       "14        0       4            2.755592  \n",
       "15        2      24            2.070903  \n",
       "16        1      25            4.848408  \n",
       "17        0       2            2.760423  \n",
       "18        2      26            2.195227  \n",
       "19        1      22            5.257537  \n",
       "20        0       7            2.834327  \n",
       "21        2      27            2.599952  \n",
       "22        1      20            5.456163  \n",
       "23        0       3            2.945552  \n",
       "24        2      26            2.195227  \n",
       "25        1      19            5.675248  \n",
       "26        0       1            3.144748  \n",
       "27        2      23            1.361214  \n",
       "28        1      21            5.602060  \n",
       "29        0       8            2.236366  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T02:02:37.744577Z",
     "iopub.status.busy": "2024-04-23T02:02:37.744423Z",
     "iopub.status.idle": "2024-04-23T02:02:37.748694Z",
     "shell.execute_reply": "2024-04-23T02:02:37.748276Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "inputs = torch.tensor(data[['A', 'B', 'C']].values, dtype=torch.float32)\n",
    "targets = torch.tensor(data[['Initial Total Loss', 'Total Loss at 50', 'Avg Loss 0-50']].values, dtype=torch.float32)\n",
    "distances = torch.tensor(data[['dist_from0', 'dist_from1', 'dist_from2']].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T02:02:37.750907Z",
     "iopub.status.busy": "2024-04-23T02:02:37.750790Z",
     "iopub.status.idle": "2024-04-23T02:02:37.759853Z",
     "shell.execute_reply": "2024-04-23T02:02:37.759424Z"
    }
   },
   "outputs": [],
   "source": [
    "class BasisNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasisNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 10)  # 입력 차원과 출력 차원 설정\n",
    "        self.fc2 = nn.Linear(10, 10) # 중간 레이어의 차원 설정\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = F.tanh(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class ForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ForwardNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 10)  # 5개의 입력을 받음\n",
    "        self.fc2 = nn.Linear(10, 10) # 10개의 성분으로 구성된 벡터를 출력\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = F.tanh(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class BackwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BackwardNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 10) # 첫 번째 네트워크의 출력을 입력으로 받음\n",
    "        self.fc2 = nn.Linear(10, 10)  # 1개의 성분으로 구성된 Output을 출력 # 첫 번째 네트워크의 출력을 입력으로 받음\n",
    "        self.fc3 = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = F.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# # 직렬 네트워크 구성\n",
    "# class SerialNetwork(nn.Module):\n",
    "#     def __init__(self, forward_nets, backward_net):\n",
    "#         super(SerialNetwork, self).__init__()\n",
    "#         self.forward_nets = forward_nets\n",
    "#         self.backward_net = backward_net\n",
    "\n",
    "#     def forward(self, x, n0, n1, n2):\n",
    "#         out1 = self.forward_nets[0](x)\n",
    "#         out2 = self.forward_nets[1](x)\n",
    "#         out3 = self.forward_nets[2](x)\n",
    "#         n0 = n0.unsqueeze(-1)  # 마지막 차원을 추가하여 브로드캐스팅이 가능하게 함\n",
    "#         n1 = n1.unsqueeze(-1)  # 마지막 차원을 추가\n",
    "#         n2 = n2.unsqueeze(-1)  # 마지막 차원을 추가\n",
    "#         combined_output = n0 * out1 + n1 * out2 + n2 * out3\n",
    "#         final_output = self.backward_net(combined_output)\n",
    "#         return final_output\n",
    "\n",
    "class SerialNetwork(nn.Module):\n",
    "    def __init__(self, basis_net, forward_nets, backward_net, n0_init, n1_init, n2_init):\n",
    "        super(SerialNetwork, self).__init__()\n",
    "        self.basis_net = basis_net  # basis network 추가\n",
    "        self.forward_nets = nn.ModuleList(forward_nets) # 리스트를 ModuleList로 변경\n",
    "        self.backward_net = backward_net\n",
    "        # n0, n1, n2를 학습 가능한 파라미터로 정의\n",
    "        self.n0 = nn.Parameter(torch.tensor([n0_init], dtype=torch.float32))\n",
    "        self.n1 = nn.Parameter(torch.tensor([n1_init], dtype=torch.float32))\n",
    "        self.n2 = nn.Parameter(torch.tensor([n2_init], dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.forward_nets[0](x)\n",
    "        out2 = self.forward_nets[1](x)\n",
    "        out3 = self.forward_nets[2](x)\n",
    "        basis_output = self.basis_net(x)  # basis network의 출력 계산\n",
    "        combined_output = self.n0 * out1 + self.n1 * out2 + self.n2 * out3 + basis_output\n",
    "        final_output = self.backward_net(combined_output)\n",
    "        return final_output\n",
    "\n",
    "\n",
    "def forward_pass(model, batch_xy, device):\n",
    "    # 모든 입력을 모델과 동일한 디바이스로 이동\n",
    "    batch_xy = batch_xy.to(device)\n",
    "    if isinstance(model, torch.nn.DataParallel):\n",
    "        # DataParallel 인스턴스에서 원래 모듈을 얻음\n",
    "        return model.module.forward(batch_xy)\n",
    "    else:\n",
    "        return model.forward(batch_xy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def forward_pass(model, batch_xy, n0, n1, n2, device):\n",
    "#     # DataParallel을 사용할 때와 그렇지 않을 때 모두 작동하도록 함\n",
    "#     # 모든 입력을 모델과 동일한 디바이스로 이동\n",
    "#     batch_xy = batch_xy.to(device)\n",
    "#     # n0, n1, n2를 텐서로 변환하고 해당 디바이스로 옮김\n",
    "#     n0 = torch.tensor(n0, dtype=torch.float32, device=device)\n",
    "#     n1 = torch.tensor(n1, dtype=torch.float32, device=device)\n",
    "#     n2 = torch.tensor(n2, dtype=torch.float32, device=device)\n",
    "#     if isinstance(model, torch.nn.DataParallel):\n",
    "#         # DataParallel 인스턴스에서 원래 모듈을 얻음\n",
    "#         return model.module.forward(batch_xy, n0, n1, n2)\n",
    "#     else:\n",
    "#         return model.forward(batch_xy, n0, n1, n2)\n",
    "\n",
    "\n",
    "    \n",
    "# # 메인 모델 정의, 두 네트워크를 직렬로 연결\n",
    "# class SerialNetwork(nn.Module):\n",
    "#     def __init__(self, forward_net, backward_net):\n",
    "#         super(SerialNetwork, self).__init__()\n",
    "#         self.forward_net = forward_net\n",
    "#         self.backward_net = backward_net\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.forward_net(x)\n",
    "#         x = self.backward_net(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "# class SerialNetwork2(nn.Module):\n",
    "#     def __init__(self, forward_nets, backward_net):\n",
    "#         super(SerialNetwork2, self).__init__()\n",
    "#         self.forward_nets = nn.ModuleList(forward_nets)  # 세 개의 전방 네트워크\n",
    "#         self.backward_net = backward_net  # 하나의 후방 네트워크\n",
    "\n",
    "#     def forward(self, x, n0, n1, n2):\n",
    "#         # 세 개의 전방 네트워크의 출력에 가중치를 적용\n",
    "#         out1 = self.forward_nets[0](x) * n0.unsqueeze(-1)  # n0, n1, n2는 배치 크기의 텐서여야 함\n",
    "#         out2 = self.forward_nets[1](x) * n1.unsqueeze(-1)\n",
    "#         out3 = self.forward_nets[2](x) * n2.unsqueeze(-1)\n",
    "        \n",
    "#         # 가중치가 적용된 출력을 합친 후, 후방 네트워크에 전달\n",
    "#         combined_out = out1 + out2 + out3\n",
    "#         final_out = self.backward_net(combined_out)\n",
    "#         return final_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T02:02:37.761986Z",
     "iopub.status.busy": "2024-04-23T02:02:37.761868Z",
     "iopub.status.idle": "2024-04-23T02:02:37.767453Z",
     "shell.execute_reply": "2024-04-23T02:02:37.767055Z"
    }
   },
   "outputs": [],
   "source": [
    "# def compute_derivatives(model, xy_data):\n",
    "#     xy_data = xy_data.to(device)\n",
    "#     # Ensure that xy_data has gradient information.\n",
    "#     xy_data.requires_grad_(True)\n",
    "    \n",
    "#     # Get the model prediction.\n",
    "#     f_pred = model(xy_data)\n",
    "    \n",
    "#     # Create a tensor of ones with the same shape as f_pred to be used for gradient computation.\n",
    "#     # Reshape the ones tensor to match the shape of f_pred.\n",
    "#     ones = torch.ones(f_pred.shape, device=device, requires_grad=False)\n",
    "    \n",
    "#     # Compute the first derivatives.\n",
    "#     f_x = torch.autograd.grad(f_pred, xy_data, grad_outputs=ones, create_graph=True)[0][:, 0]\n",
    "#     f_y = torch.autograd.grad(f_pred, xy_data, grad_outputs=ones, create_graph=True)[0][:, 1]\n",
    "    \n",
    "#     # Compute the second derivatives.\n",
    "#     f_xx = torch.autograd.grad(f_x, xy_data, grad_outputs=ones[:, 0], create_graph=True)[0][:, 0]\n",
    "#     f_yy = torch.autograd.grad(f_y, xy_data, grad_outputs=ones[:, 0], create_graph=True)[0][:, 1]\n",
    "    \n",
    "#     return f_xx, f_yy\n",
    "\n",
    "\n",
    "# compute_derivatives 함수에 n0, n1, n2 인자를 추가합니다.\n",
    "def compute_derivatives(model, xy_data, n0, n1, n2, device):\n",
    "    xy_data = xy_data.to(device)\n",
    "    xy_data.requires_grad_(True)\n",
    "    \n",
    "    n0 = torch.tensor(n0, dtype=torch.float32, device=device)\n",
    "    n1 = torch.tensor(n1, dtype=torch.float32, device=device)\n",
    "    n2 = torch.tensor(n2, dtype=torch.float32, device=device)\n",
    "    # compute_derivatives 함수 내부:\n",
    "    if isinstance(model, torch.nn.DataParallel):\n",
    "        # 모델이 DataParallel을 사용하는 경우\n",
    "        batch_size = xy_data.size(0)  # 현재 배치의 크기를 얻음\n",
    "        # n0, n1, n2를 현재 배치 크기에 맞게 확장\n",
    "        n0 = torch.full((batch_size, ), n0, dtype=torch.float32, device=device)\n",
    "        n1 = torch.full((batch_size, ), n1, dtype=torch.float32, device=device)\n",
    "        n2 = torch.full((batch_size, ), n2, dtype=torch.float32, device=device)\n",
    "        # 수정된 모델 호출\n",
    "        f_pred = model.module.forward(xy_data)\n",
    "    else:\n",
    "        # 모델이 단일 GPU 또는 CPU에서만 실행되는 경우\n",
    "        f_pred = model.forward(xy_data)\n",
    "    # # 모델 예측을 n0, n1, n2 값과 함께 계산합니다.\n",
    "    # f_pred = model(xy_data, n0, n1, n2)  # 수정된 부분\n",
    "\n",
    "    ones = torch.ones(f_pred.shape, device=device, requires_grad=False)\n",
    "    f_x = torch.autograd.grad(f_pred, xy_data, grad_outputs=ones, create_graph=True)[0][:, 0]\n",
    "    f_y = torch.autograd.grad(f_pred, xy_data, grad_outputs=ones, create_graph=True)[0][:, 1]\n",
    "    f_xx = torch.autograd.grad(f_x, xy_data, grad_outputs=ones[:, 0], create_graph=True)[0][:, 0]\n",
    "    f_yy = torch.autograd.grad(f_y, xy_data, grad_outputs=ones[:, 0], create_graph=True)[0][:, 1]\n",
    "    return f_xx, f_yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T02:02:37.769576Z",
     "iopub.status.busy": "2024-04-23T02:02:37.769461Z",
     "iopub.status.idle": "2024-04-23T02:02:37.771743Z",
     "shell.execute_reply": "2024-04-23T02:02:37.771337Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def freeze_parameters(net, freeze=True):\n",
    "    for param in net.parameters():\n",
    "        param.requires_grad = not freeze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T02:02:37.773893Z",
     "iopub.status.busy": "2024-04-23T02:02:37.773689Z",
     "iopub.status.idle": "2024-04-23T02:02:37.776887Z",
     "shell.execute_reply": "2024-04-23T02:02:37.776501Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 데이터 생성 함수\n",
    "def generate_data(A, B, C):\n",
    "    x_data, y_data = np.meshgrid(\n",
    "    np.linspace(-30, 30, 100),\n",
    "    np.linspace(-30, 30, 100))    \n",
    "    # numpy 배열에서 tensor로 변환할 때 requires_grad=True 설정\n",
    "    f_test = A * np.sin(x_data/B) * np.sin(y_data/C)\n",
    "    # 정규화된 A, B, C를 포함하여 입력 데이터 준비\n",
    "    xy_data_ = np.stack([x_data.ravel(), y_data.ravel()], axis=-1)\n",
    "    xy_data = torch.tensor(xy_data_, dtype=torch.float32)\n",
    "    f_data = torch.tensor(f_test.ravel(), dtype=torch.float32).view(-1, 1)\n",
    "    return x_data, y_data, f_data, f_test, xy_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T02:02:37.779162Z",
     "iopub.status.busy": "2024-04-23T02:02:37.778941Z",
     "iopub.status.idle": "2024-04-23T02:02:39.814302Z",
     "shell.execute_reply": "2024-04-23T02:02:39.813811Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 전방 네트워크와 후방 네트워크 초기화\n",
    "basis_net = BasisNet().to(device)\n",
    "forward_nets = [ForwardNet().to(device) for _ in range(3)]\n",
    "backward_net = BackwardNet().to(device)\n",
    "\n",
    "# 전방 네트워크에 대한 모델 가중치 불러오기\n",
    "# for net in forward_nets:\n",
    "#     net.load_state_dict(torch.load('first_network_final.pth'))\n",
    "#     pass\n",
    "\n",
    "basis_net.load_state_dict(torch.load('./basis_sum_pth/basis_network_basis_sum_777.pth'))\n",
    "forward_nets[0].load_state_dict(torch.load('./basis_sum_pth/forward_network_0_basis_sum_777.pth'))\n",
    "forward_nets[1].load_state_dict(torch.load('./basis_sum_pth/forward_network_1_basis_sum_777.pth'))\n",
    "forward_nets[2].load_state_dict(torch.load('./basis_sum_pth/forward_network_2_basis_sum_777.pth'))\n",
    "# 후방 네트워크에 대한 모델 가중치 불러오기\n",
    "backward_net.load_state_dict(torch.load('./basis_sum_pth/backward_network_basis_sum_777.pth'))\n",
    "\n",
    "\n",
    "\n",
    "# ##\n",
    "\n",
    "# # 모델 인스턴스화\n",
    "# forward_net_0 = ForwardNet().to(device)\n",
    "# forward_net_1 = ForwardNet().to(device)\n",
    "# forward_net_2 = ForwardNet().to(device)\n",
    "\n",
    "# # 가중치 로드\n",
    "# forward_net_0.load_state_dict(torch.load('first_network_final_777_2input.pth', map_location=device))\n",
    "# forward_net_1.load_state_dict(torch.load('first_network_final_777_2input.pth', map_location=device))\n",
    "# forward_net_2.load_state_dict(torch.load('first_network_final_777_2input.pth', map_location=device))\n",
    "\n",
    "# # DataParallel 적용\n",
    "# forward_net_0 = torch.nn.DataParallel(forward_net_0)\n",
    "# forward_net_1 = torch.nn.DataParallel(forward_net_1)\n",
    "# forward_net_2 = torch.nn.DataParallel(forward_net_2)\n",
    "\n",
    "# # 백워드 네트워크 인스턴스화 및 가중치 로드 후 DataParallel 적용\n",
    "# backward_net = BackwardNet().to(device)\n",
    "# backward_net.load_state_dict(torch.load('second_network_final_777_2input.pth', map_location=device))\n",
    "# backward_net = torch.nn.DataParallel(backward_net)\n",
    "\n",
    "# # 전방 네트워크 리스트 및 SerialNetwork 인스턴스 생성\n",
    "# forward_nets = [forward_net_0, forward_net_1, forward_net_2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# torch.load(model.module.first_network.state_dict(), './first_network_final.pth')\n",
    "# torch.load(model.module.second_network.state_dict(), './second_network_final.pth')\n",
    "\n",
    "#============================================\n",
    "# # 전방 및 후방 네트워크에 대한 옵티마이저 설정\n",
    "# optimizers = [torch.optim.Adam(list(forward_net.parameters()) + list(backward_net.parameters()), lr=learning_rate) for forward_net in forward_nets]\n",
    "\n",
    "# # 후방 네트워크에 대한 별도 옵티마이저 설정 (후방 네트워크 학습 단계용)\n",
    "# optimizer_backward = torch.optim.Adam(backward_net.parameters(), lr=learning_rate)\n",
    "#============================================\n",
    "\n",
    "# # Aggressive learning rate scheduler\n",
    "# scheduler = ReduceLROnPlateau(optimizers, mode='min', factor=0.7, patience=200, verbose=True)\n",
    "# # scheduler = ReduceLROnPlateau(optimizer_backward, mode='min', factor=0.7, patience=200, verbose=True)\n",
    "\n",
    "# # 각 전방 네트워크 옵티마이저에 대한 학습률 스케줄러 생성\n",
    "# schedulers = [ReduceLROnPlateau(optimizer, mode='min', factor=0.7, patience=200, verbose=True) for optimizer in optimizers]\n",
    "\n",
    "# # 후방 네트워크 옵티마이저에 대한 학습률 스케줄러 생성\n",
    "# scheduler_backward = ReduceLROnPlateau(optimizer_backward, mode='min', factor=0.7, patience=200, verbose=True)\n",
    "\n",
    "\n",
    "# 손실 함수와 최적화기를 정의합니다.\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T02:02:39.816595Z",
     "iopub.status.busy": "2024-04-23T02:02:39.816476Z",
     "iopub.status.idle": "2024-04-23T02:02:39.819450Z",
     "shell.execute_reply": "2024-04-23T02:02:39.819046Z"
    }
   },
   "outputs": [],
   "source": [
    "# 배치학습을 위한 데이터 로더 함수를 정의합니다.\n",
    "def create_dataloader(x_data, y_data, batch_size, shuffle):\n",
    "    dataset = TensorDataset(x_data, y_data)\n",
    "    loader = DataLoader(dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=shuffle)\n",
    "    return loader\n",
    "\n",
    "# 데이터 로더를 생성합니다.\n",
    "\n",
    "\n",
    "# # num_workers를 시스템의 CPU 코어 수에 따라 조정합니다.\n",
    "# import os\n",
    "# num_workers = os.cpu_count()\n",
    "# print(\"Number of workers:\", num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T02:02:39.821655Z",
     "iopub.status.busy": "2024-04-23T02:02:39.821539Z",
     "iopub.status.idle": "2024-04-23T04:10:14.481636Z",
     "shell.execute_reply": "2024-04-23T04:10:14.481279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasisLearnX\n",
      "\n",
      "Cycle 1/10\n",
      "2nd raining Forward Net 2 for Experiment 1 with A=7, B=7, C=7\n",
      "Training Forward Net 2 for Experiment 1 with A=7, B=7, C=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/100, Total Loss: 0.010241682762813986, Data Loss: 0.00855454625739793, PDE Loss: 0.0016871364779805966, LR: 0.002\n",
      "n0: 0.10416921228170395, n1: 0.10301641374826431, n2: 1.0 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 163\u001b[0m\n\u001b[1;32m    161\u001b[0m f_pred \u001b[38;5;241m=\u001b[39m forward_pass(model, batch_xy, device)\n\u001b[1;32m    162\u001b[0m data_loss \u001b[38;5;241m=\u001b[39m criterion(f_pred, batch_f)\n\u001b[0;32m--> 163\u001b[0m f_xx, f_yy \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_xy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m pde_loss \u001b[38;5;241m=\u001b[39m criterion(f_xx \u001b[38;5;241m+\u001b[39m f_yy, ((\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mB\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m+\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mC\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mf_pred\u001b[38;5;241m.\u001b[39msqueeze())\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Combine the lossesgnqk\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[20], line 49\u001b[0m, in \u001b[0;36mcompute_derivatives\u001b[0;34m(model, xy_data, n0, n1, n2, device)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# # 모델 예측을 n0, n1, n2 값과 함께 계산합니다.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# f_pred = model(xy_data, n0, n1, n2)  # 수정된 부분\u001b[39;00m\n\u001b[1;32m     48\u001b[0m ones \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(f_pred\u001b[38;5;241m.\u001b[39mshape, device\u001b[38;5;241m=\u001b[39mdevice, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 49\u001b[0m f_x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxy_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     50\u001b[0m f_y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(f_pred, xy_data, grad_outputs\u001b[38;5;241m=\u001b[39mones, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m][:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     51\u001b[0m f_xx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(f_x, xy_data, grad_outputs\u001b[38;5;241m=\u001b[39mones[:, \u001b[38;5;241m0\u001b[39m], create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m][:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:276\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 전방 네트워크와 후방 네트워크에 대한 스케쥴러를 설정\n",
    "# schedulers_forward = [ReduceLROnPlateau(optimizers[i], mode='min', factor=0.7, patience=1, verbose=True) for i in range(len(forward_nets))]\n",
    "# scheduler_backward = ReduceLROnPlateau(optimizer_backward, mode='min', factor=0.7, patience=1, verbose=True)\n",
    "\n",
    "# def l2_regularization(model, weight_decay):\n",
    "#     l2_loss = 0\n",
    "#     for param in model.parameters():\n",
    "#         l2_loss += torch.norm(param)**2\n",
    "#     return l2_loss * weight_decay\n",
    "\n",
    "# forward_nets = [net.to(device) for net in forward_nets]\n",
    "# backward_net = backward_net.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#==================================================\n",
    "\n",
    "# 학습 설정\n",
    "main_title = \"BasisLearnX\"\n",
    "num_epochs = 100\n",
    "num_epochs2 = 500\n",
    "learning_rate1 = 0.002\n",
    "learning_rate2 = 0.002\n",
    "lambda_l2 = 0\n",
    "\n",
    "batch_size = 64\n",
    "shuffle = True\n",
    "num_workers=16\n",
    "\n",
    "\n",
    "file_path = f\"./Newdist(M1M0.1)learn_Eucli_E{num_epochs},{num_epochs2}_{learning_rate1}lr_({main_title})\"\n",
    "\n",
    "# 디렉토리 생성\n",
    "if not os.path.exists(file_path):\n",
    "    os.makedirs(file_path)\n",
    "\n",
    "\n",
    "basis_name = f'./{file_path}/basis_net_Newdist(M1M0.1)learn_Eucli_E{num_epochs},{num_epochs2}_{learning_rate1}lr.pth'\n",
    "forward_name0 = f'./{file_path}/forward_net_0_Newdist(M1M0.1)learn_Eucli_E{num_epochs},{num_epochs2}_{learning_rate1}lr.pth'\n",
    "forward_name1 = f'./{file_path}/forward_net_1_Newdist(M1M0.1)learn_Eucli_E{num_epochs},{num_epochs2}_{learning_rate1}lr.pth'\n",
    "forward_name2 = f'./{file_path}/forward_net_2_Newdist(M1M0.1)learn_Eucli_E{num_epochs},{num_epochs2}_{learning_rate1}lr.pth'\n",
    "backward_name = f'./{file_path}/backward_net_Newdist(M1M0.1)learn_Eucli_E{num_epochs},{num_epochs2}_{learning_rate1}lr.pth'\n",
    "n_params_filename = f'./{file_path}/n_params_Newdist(M1M0.1)learn_Eucli_E{num_epochs},{num_epochs2}_{learning_rate1}lr.pth'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Weight average디렉토리 경로와 파일 경로 분리\n",
    "WA_forward_path = f\"./{file_path}/WA_forward\"\n",
    "\n",
    "# 디렉토리 생성\n",
    "if not os.path.exists(WA_forward_path):\n",
    "    os.makedirs(WA_forward_path)\n",
    "\n",
    "\n",
    "# Weight average디렉토리 경로와 파일 경로 분리\n",
    "WA_path = f\"./{file_path}/WA\"\n",
    "\n",
    "# 디렉토리 생성\n",
    "if not os.path.exists(WA_path):\n",
    "    os.makedirs(WA_path)\n",
    "\n",
    "\n",
    "# # 파일 저장 경로 결합\n",
    "# full_file_path = os.path.join(directory_path, file_path)\n",
    "\n",
    "# # 데이터프레임을 CSV 파일로 저장\n",
    "# df_new.to_csv(full_file_path, index=False)\n",
    "\n",
    "#==================================================\n",
    "\n",
    "print(main_title)\n",
    "\n",
    "for cycle in range(longest_length):  # 총 9개의 사이클\n",
    "    print(f\"\\nCycle {cycle + 1}/{10}\")\n",
    "    start_idx = cycle * 3  # 이 사이클에서 학습할 시작 인덱스\n",
    "    end_idx = start_idx + 3  # 이 사이클에서 학습할 마지막 인덱스\n",
    "\n",
    "    # 전방 네트워크 학습(n0, n1, n2 적용)\n",
    "    for idx in range(start_idx, end_idx):\n",
    "        # Sum_loss = 0\n",
    "        # total_loss1=0\n",
    "        A = data['A'][idx]\n",
    "        B = data['B'][idx]\n",
    "        C = data['C'][idx]\n",
    "        n0 = data['dist_from0'][idx]\n",
    "        n1 = data['dist_from1'][idx]\n",
    "        n2 = data['dist_from2'][idx]\n",
    "        label = data['Cluster'][idx]  # 할당된 라벨에 따라 네트워크 선택\n",
    "        x_data, y_data, f_data, f_test, xy_data = generate_data(A, B, C)\n",
    "        loader = create_dataloader(xy_data, f_data, batch_size, shuffle)\n",
    "\n",
    "\n",
    "        model = SerialNetwork(basis_net, forward_nets, backward_net, n0, n1, n2).to(device)\n",
    "\n",
    "\n",
    "        # 모든 네트워크 파라미터를 위한 단일 옵티마이저 생성\n",
    "        combined_parameters = list(backward_net.parameters())\n",
    "        for forward_net in forward_nets:\n",
    "            combined_parameters.extend(list(forward_net.parameters()))\n",
    "  \n",
    "        #================================================================      \n",
    "        # # n0, n1, n2 파라미터 추가\n",
    "        # combined_parameters.extend([model.n0, model.n1, model.n2])\n",
    "        n_parameters = []\n",
    "        \n",
    "        \n",
    "        # 라벨에 따라 n0, n1, n2 중 적절한 파라미터만 추가\n",
    "        if label != 0:\n",
    "            n_parameters.append(model.n0)\n",
    "        if label != 1:\n",
    "            n_parameters.append(model.n1)\n",
    "        if label != 2:\n",
    "            n_parameters.append(model.n2)\n",
    "        \n",
    "        \n",
    "        #================================================================\n",
    "        \n",
    "        # 파라미터 그룹 정의\n",
    "        param_groups = [\n",
    "            {'params': combined_parameters, 'lr': learning_rate1},  # 나머지 모델 파라미터용 학습률\n",
    "            {'params': n_parameters, 'lr': 0.002}  # model.n0, model.n1, model.n2에 대한 학습률\n",
    "        ]\n",
    "\n",
    "        # 이제 단일 옵티마이저에 모든 파라미터를 넣습니다.\n",
    "        optimizer = torch.optim.Adam(param_groups)\n",
    "        \n",
    "        print(f\"2nd raining Forward Net {label} for Experiment {idx + 1} with A={A}, B={B}, C={C}\")\n",
    "        # optimizer = optimizers[label]\n",
    "        # optimizer = torch.optim.Adam(list(forward_net.parameters()) + list(backward_net.parameters()), lr=learning_rate)\n",
    "        \n",
    "        # model = SerialNetwork(forward_nets, backward_net).to(device)\n",
    "        # model = nn.DataParallel(model)\n",
    "        \n",
    "        \n",
    "        # model = torch.nn.DataParallel(model)\n",
    "        print(f\"Training Forward Net {label} for Experiment {idx + 1} with A={A}, B={B}, C={C}\")\n",
    "        # Add lists to record separate losses\n",
    "        loss_history = []\n",
    "        data_loss_history = []\n",
    "        pde_loss_history = []\n",
    "        mse_values = []\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.7, patience=50, verbose=True)\n",
    "\n",
    "    \n",
    "                        \n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            batch_loss = 0.0\n",
    "            batch_data_loss = 0.0  # To record data loss\n",
    "            batch_pde_loss = 0.0   # To record pde loss\n",
    "            \n",
    "            # for batch_xy, batch_f in loader:\n",
    "            for batch_num, (batch_xy, batch_f) in enumerate(loader): \n",
    "                batch_xy, batch_f = batch_xy.to(device), batch_f.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Calculate the losses\n",
    "                f_pred = forward_pass(model, batch_xy, device)\n",
    "                data_loss = criterion(f_pred, batch_f)\n",
    "                f_xx, f_yy = compute_derivatives(model, batch_xy, n0, n1, n2, device)\n",
    "                pde_loss = criterion(f_xx + f_yy, ((1/B**2)+(1/C**2))*(-1)*f_pred.squeeze())\n",
    "\n",
    "                # Combine the lossesgnqk\n",
    "                loss = data_loss + pde_loss\n",
    "\n",
    "                # # Combine the lossesgnqk\n",
    "                # loss = data_loss + pde_loss\n",
    "                \n",
    "                # Backpropagate and optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Record losses\n",
    "                batch_loss += loss.item()\n",
    "                batch_data_loss += data_loss.item()\n",
    "                batch_pde_loss += pde_loss.item()\n",
    "\n",
    "            \n",
    "            avg_loss = batch_loss / len(loader)\n",
    "            avg_data_loss = batch_data_loss / len(loader)\n",
    "            avg_pde_loss = batch_pde_loss / len(loader)\n",
    "            \n",
    "            # Append the average losses for this epoch to the history\n",
    "            loss_history.append(avg_loss)\n",
    "            data_loss_history.append(avg_data_loss)\n",
    "            pde_loss_history.append(avg_pde_loss)\n",
    "            \n",
    "            # scheduler = schedulers[label]\n",
    "            scheduler.step(avg_loss)\n",
    "            \n",
    "            # Print the losses every 100 epochs\n",
    "            if (epoch % 10 == 0) or (epoch == num_epochs-1) :\n",
    "                current_lr = optimizer.param_groups[0]['lr']\n",
    "                print(f'Epoch {epoch}/{num_epochs}, Total Loss: {avg_loss}, Data Loss: {avg_data_loss}, PDE Loss: {avg_pde_loss}, LR: {current_lr}')\n",
    "                print(f'n0: {model.n0.item()}, n1: {model.n1.item()}, n2: {model.n2.item()} ')\n",
    "        # torch.save(forward_net.state_dict(), f'./Weight_average{label}_E1,500/forward_{label}net_{cycle}.pth')\n",
    "\n",
    "        for i, forward_net in enumerate(forward_nets):\n",
    "            torch.save(forward_net.state_dict(), f'./{WA_forward_path}/forward_net_{i}_{cycle}Cycle_{idx}th.pth')\n",
    "\n",
    "        \n",
    "        \n",
    "        # # 학습된 n으로 업데이트\n",
    "        # n0_final, n1_final, n2_final = model.n0.item(), model.n1.item(), model.n2.item()\n",
    "        \n",
    "        # # .loc을 사용하여 특정 인덱스의 값 업데이트\n",
    "        # data.loc[idx, 'dist_from0'] = n0_final\n",
    "        # data.loc[idx, 'dist_from1'] = n1_final\n",
    "        # data.loc[idx, 'dist_from2'] = n2_final\n",
    "        print(\"\\n\")\n",
    "\n",
    "        \n",
    "\n",
    "# =======================================================================================\n",
    "\n",
    "    # 후방 네트워크 학습\n",
    "    # 전방 네트워크의 파라미터를 고정\n",
    "    for net in forward_nets:\n",
    "        freeze_parameters(net, freeze=True)\n",
    "\n",
    "    print(\"Training Backward Net\")\n",
    "    loss_history = []\n",
    "\n",
    "\n",
    "    # # 모든 네트워크 파라미터를 위한 단일 옵티마이저 생성\n",
    "    # combined_parameters = list(backward_net.parameters()) + list(basis_net.parameters())\n",
    "    # for forward_net in forward_nets:\n",
    "    #     combined_parameters.extend(list(forward_net.parameters()))\n",
    "\n",
    "    # 모든 네트워크 파라미터를 위한 단일 옵티마이저 생성\n",
    "    combined_parameters = list(backward_net.parameters())\n",
    "    for forward_net in forward_nets:\n",
    "        combined_parameters.extend(list(forward_net.parameters()))\n",
    "\n",
    "    # 이제 단일 옵티마이저에 모든 파라미터를 넣습니다.\n",
    "    optimizer1 = torch.optim.Adam(combined_parameters, lr=learning_rate2)\n",
    "    \n",
    "    scheduler1 = ReduceLROnPlateau(optimizer1, mode='min', factor=0.7, patience=100, verbose=True)\n",
    "\n",
    "    for epoch in range(num_epochs2):\n",
    "        Sum_loss = 0\n",
    "        total_loss2=0\n",
    "        for idx in range(start_idx, end_idx):\n",
    "            A = data['A'][idx]\n",
    "            B = data['B'][idx]\n",
    "            C = data['C'][idx]\n",
    "            #111로 한번더...?\n",
    "            n0 = data['dist_from0'][idx]\n",
    "            n1 = data['dist_from1'][idx]\n",
    "            n2 = data['dist_from2'][idx]\n",
    "            \n",
    "            label = data['Cluster'][idx]  # 할당된 라벨에 따라 네트워크 선택\n",
    "            \n",
    "            model = SerialNetwork(basis_net, forward_nets, backward_net, n0, n1, n2).to(device)\n",
    "            \n",
    "            # model = SerialNetwork(forward_nets[label], backward_net).to(device)\n",
    "            \n",
    "            \n",
    "            # model = SerialNetwork(forward_nets, backward_net).to(device)\n",
    "            # model = nn.DataParallel(model)\n",
    "            \n",
    "            \n",
    "            # model = torch.nn.DataParallel(model)\n",
    "            x_data, y_data, f_data, f_test, xy_data = generate_data(A, B, C)\n",
    "            \n",
    "                    \n",
    "            # x_data, y_data, f_data, f_test, xy_data =  x_data.to(device), y_data.to(device), f_data.to(device), f_test.to(device), xy_data.to(device)\n",
    "            \n",
    "            f_data = f_data.to(device)\n",
    "            f_test = torch.tensor(f_test, dtype=torch.float32).view(-1, 1).to(device) # f_test를 PyTorch 텐서로 변환 후 디바이스로 옮김\n",
    "            xy_data = xy_data.to(device)\n",
    "            # # f_test를 PyTorch 텐서로 변환하고 디바이스로 옮김\n",
    "            # f_test = torch.tensor(f_test, dtype=torch.float32).view(-1, 1).to(device)\n",
    "            # xy_data = xy_data.to(device)\n",
    "            # f_data = f_data.to(device)\n",
    "            \n",
    "            # Calculate the losses\n",
    "            f_pred = forward_pass(model, xy_data, device)\n",
    "            data_loss = criterion(f_pred, f_test)\n",
    "            f_xx, f_yy = compute_derivatives(model, xy_data, n0, n1, n2, device)\n",
    "            pde_loss = criterion(f_xx + f_yy, ((1/B**2)+(1/C**2))*(-1)*f_pred.squeeze())\n",
    "                \n",
    "            # Combine the losses\n",
    "            total_loss2 = data_loss + pde_loss\n",
    "            Sum_loss += total_loss2\n",
    "        \n",
    "        model.train()    \n",
    "        optimizer1.zero_grad()\n",
    "        Sum_loss.backward()\n",
    "        optimizer1.step()\n",
    "        avg_loss = Sum_loss.item()\n",
    "        loss_history.append(avg_loss)\n",
    "        scheduler1.step(avg_loss)\n",
    "        \n",
    "        if (epoch % 10 == 0) or (epoch == num_epochs2-1) :\n",
    "            current_lr = optimizer1.param_groups[0]['lr']\n",
    "            print(f'Epoch {epoch}/{num_epochs}, Total Loss: {avg_loss}, LR: {current_lr}')\n",
    "            print(f'n0: {model.n0.item()}, n1: {model.n1.item()}, n2: {model.n2.item()}')   \n",
    "             \n",
    "    # 전방 네트워크의 파라미터 고정 해제\n",
    "    for net in forward_nets:\n",
    "        freeze_parameters(net, freeze=False)\n",
    "        \n",
    "    for i, forward_net in enumerate(forward_nets):\n",
    "        torch.save(forward_net.state_dict(), f'./{WA_path}/forward_net_{i}_cycle_{cycle}.pth')\n",
    "    \n",
    "    torch.save(backward_net.state_dict(), f'./{WA_path}/backward_net_cycle_{cycle}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T04:10:14.483609Z",
     "iopub.status.busy": "2024-04-23T04:10:14.483369Z",
     "iopub.status.idle": "2024-04-23T04:10:14.492521Z",
     "shell.execute_reply": "2024-04-23T04:10:14.491883Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# # 전방 네트워크 가중치 저장\n",
    "# for i, net in enumerate(forward_nets):\n",
    "#     torch.save(net.state_dict(), f'forward_net_{i}_afterDOE.pth')\n",
    "torch.save(basis_net.state_dict(), basis_name)\n",
    "torch.save(forward_nets[0].state_dict(), forward_name0)\n",
    "torch.save(forward_nets[1].state_dict(), forward_name1)\n",
    "torch.save(forward_nets[2].state_dict(), forward_name2)\n",
    "\n",
    "# 후방 네트워크 가중치 저장\n",
    "torch.save(backward_net.state_dict(), backward_name)\n",
    "\n",
    "\n",
    "# n0, n1, n2 파라미터를 딕셔너리로 저장\n",
    "n_params = {\n",
    "    'n0': model.n0.item(),  # model 대신 실제 모델 변수명 사용\n",
    "    'n1': model.n1.item(),\n",
    "    'n2': model.n2.item(),\n",
    "}\n",
    "\n",
    "\n",
    "# 파일로 저장\n",
    "torch.save(n_params, n_params_filename)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# torch.save(forward_nets[0].state_dict(), f'forward_net_0_afterDOE_2input_Newdist(max1)_E2,1000_0.002lr.pth')\n",
    "# torch.save(forward_nets[1].state_dict(), f'forward_net_1_afterDOE_2input_Newdist(max1)_E2,1000_0.002lr.pth')\n",
    "# torch.save(forward_nets[2].state_dict(), f'forward_net_2_afterDOE_2input_Newdist(max1)_E2,1000_0.002lr.pth')\n",
    "\n",
    "# # 후방 네트워크 가중치 저장\n",
    "# torch.save(backward_net.state_dict(), 'backward_net_afterDOE_2input_Newdist(max1)_E2,1000_0.002lr.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T04:10:14.494697Z",
     "iopub.status.busy": "2024-04-23T04:10:14.494234Z",
     "iopub.status.idle": "2024-04-23T04:10:14.500223Z",
     "shell.execute_reply": "2024-04-23T04:10:14.499677Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "basis_net2 = BasisNet().to(device)\n",
    "\n",
    "\n",
    "basis_net2.load_state_dict(torch.load('./basis_sum_pth/basis_network_basis_sum_777.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T04:10:14.502241Z",
     "iopub.status.busy": "2024-04-23T04:10:14.501866Z",
     "iopub.status.idle": "2024-04-23T04:10:14.528891Z",
     "shell.execute_reply": "2024-04-23T04:10:14.528423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basis1\n",
      "tensor([[ 0.0409, -0.2675],\n",
      "        [-0.0128, -0.1159],\n",
      "        [ 0.1628, -0.1552],\n",
      "        [-0.0342, -0.1779],\n",
      "        [ 0.1537,  0.1500],\n",
      "        [ 0.1299,  0.1010],\n",
      "        [ 0.1588, -0.1689],\n",
      "        [ 0.1025, -0.0292],\n",
      "        [-0.0029, -0.1205],\n",
      "        [-0.1587,  0.1501]], device='cuda:1')\n",
      "\n",
      "\n",
      "basis2\n",
      "tensor([[ 0.0409, -0.2675],\n",
      "        [-0.0128, -0.1159],\n",
      "        [ 0.1628, -0.1552],\n",
      "        [-0.0342, -0.1779],\n",
      "        [ 0.1537,  0.1500],\n",
      "        [ 0.1299,  0.1010],\n",
      "        [ 0.1588, -0.1689],\n",
      "        [ 0.1025, -0.0292],\n",
      "        [-0.0029, -0.1205],\n",
      "        [-0.1587,  0.1501]], device='cuda:1')\n",
      "\n",
      "\n",
      "diff\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]], device='cuda:1')\n",
      "\n",
      "\n",
      "basis1\n",
      "tensor([-0.7723,  2.3789,  2.7825, -1.2654,  1.7077, -1.3990,  1.2062, -1.3990,\n",
      "        -2.9084,  2.0049], device='cuda:1')\n",
      "\n",
      "\n",
      "basis2\n",
      "tensor([-0.7723,  2.3789,  2.7825, -1.2654,  1.7077, -1.3990,  1.2062, -1.3990,\n",
      "        -2.9084,  2.0049], device='cuda:1')\n",
      "\n",
      "\n",
      "diff\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:1')\n",
      "\n",
      "\n",
      "basis1\n",
      "tensor([[ 1.0208, -1.0057,  0.5675,  0.8763,  0.0424,  1.2228, -0.2888,  1.4270,\n",
      "          1.6705,  0.4404],\n",
      "        [-0.5044, -0.3380, -0.4662,  0.0950,  0.3606, -0.1524, -0.8484,  0.5068,\n",
      "         -0.2790, -0.7398],\n",
      "        [-0.3058, -1.0153,  1.4698, -0.0994,  0.4414, -0.9536,  0.6545, -1.5579,\n",
      "         -1.0510, -0.0060],\n",
      "        [-0.1149,  1.4475, -0.0986, -0.1643,  1.0932,  0.4221,  0.1710, -0.8467,\n",
      "          0.8494,  0.3763],\n",
      "        [-0.0716,  0.5973, -0.2894,  0.5449,  0.3644,  0.3028, -0.5537, -1.4007,\n",
      "          1.0980, -0.0600],\n",
      "        [-0.1392,  1.2042, -0.7150, -0.8907,  0.3393,  0.8888, -0.2371, -1.1524,\n",
      "          0.4814, -0.2114],\n",
      "        [ 0.4551,  1.8630, -0.2532, -0.5183,  0.5733,  0.4340,  0.0856, -1.5526,\n",
      "         -0.8617,  1.0717],\n",
      "        [ 0.2657,  0.5821,  0.4775, -0.1030, -0.1981,  0.8616,  0.3073,  0.3014,\n",
      "          0.5086,  0.5947],\n",
      "        [ 0.1025,  0.4628, -0.0655, -0.1214,  0.4419, -1.0762, -0.5734,  1.1579,\n",
      "          0.1572, -0.2523],\n",
      "        [-0.2105, -0.7013,  0.5887, -0.2265, -0.8318,  0.5813,  0.5678,  0.6883,\n",
      "         -0.5266,  0.7151]], device='cuda:1')\n",
      "\n",
      "\n",
      "basis2\n",
      "tensor([[ 1.0208, -1.0057,  0.5675,  0.8763,  0.0424,  1.2228, -0.2888,  1.4270,\n",
      "          1.6705,  0.4404],\n",
      "        [-0.5044, -0.3380, -0.4662,  0.0950,  0.3606, -0.1524, -0.8484,  0.5068,\n",
      "         -0.2790, -0.7398],\n",
      "        [-0.3058, -1.0153,  1.4698, -0.0994,  0.4414, -0.9536,  0.6545, -1.5579,\n",
      "         -1.0510, -0.0060],\n",
      "        [-0.1149,  1.4475, -0.0986, -0.1643,  1.0932,  0.4221,  0.1710, -0.8467,\n",
      "          0.8494,  0.3763],\n",
      "        [-0.0716,  0.5973, -0.2894,  0.5449,  0.3644,  0.3028, -0.5537, -1.4007,\n",
      "          1.0980, -0.0600],\n",
      "        [-0.1392,  1.2042, -0.7150, -0.8907,  0.3393,  0.8888, -0.2371, -1.1524,\n",
      "          0.4814, -0.2114],\n",
      "        [ 0.4551,  1.8630, -0.2532, -0.5183,  0.5733,  0.4340,  0.0856, -1.5526,\n",
      "         -0.8617,  1.0717],\n",
      "        [ 0.2657,  0.5821,  0.4775, -0.1030, -0.1981,  0.8616,  0.3073,  0.3014,\n",
      "          0.5086,  0.5947],\n",
      "        [ 0.1025,  0.4628, -0.0655, -0.1214,  0.4419, -1.0762, -0.5734,  1.1579,\n",
      "          0.1572, -0.2523],\n",
      "        [-0.2105, -0.7013,  0.5887, -0.2265, -0.8318,  0.5813,  0.5678,  0.6883,\n",
      "         -0.5266,  0.7151]], device='cuda:1')\n",
      "\n",
      "\n",
      "diff\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:1')\n",
      "\n",
      "\n",
      "basis1\n",
      "tensor([-0.1176, -0.3162,  0.3936, -0.5075, -0.7603, -0.7988, -0.2746, -0.6776,\n",
      "         0.3196,  0.4596], device='cuda:1')\n",
      "\n",
      "\n",
      "basis2\n",
      "tensor([-0.1176, -0.3162,  0.3936, -0.5075, -0.7603, -0.7988, -0.2746, -0.6776,\n",
      "         0.3196,  0.4596], device='cuda:1')\n",
      "\n",
      "\n",
      "diff\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:1')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (name1, param1), (name2, param2) in zip(basis_net.named_parameters(), basis_net2.named_parameters()):\n",
    "    weight_diff = param1.data - param2.data\n",
    "    print(\"basis1\")\n",
    "    print(param1.data)\n",
    "    print(\"\\n\")\n",
    "    print(\"basis2\")\n",
    "    print(param2.data)\n",
    "    print(\"\\n\")\n",
    "    print(\"diff\")\n",
    "    print(weight_diff)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T04:10:14.530351Z",
     "iopub.status.busy": "2024-04-23T04:10:14.530231Z",
     "iopub.status.idle": "2024-04-23T04:10:14.535080Z",
     "shell.execute_reply": "2024-04-23T04:10:14.534656Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "forward_nets0 = [ForwardNet().to(device) for _ in range(3)]\n",
    "\n",
    "\n",
    "forward_nets0[0].load_state_dict(torch.load('./basis_sum_pth/forward_network_0_basis_sum_777.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T04:10:14.536495Z",
     "iopub.status.busy": "2024-04-23T04:10:14.536380Z",
     "iopub.status.idle": "2024-04-23T04:10:14.549064Z",
     "shell.execute_reply": "2024-04-23T04:10:14.548626Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward0_1\n",
      "tensor([[-0.2405,  0.0427],\n",
      "        [ 0.0628, -0.1259],\n",
      "        [ 0.1119,  0.0131],\n",
      "        [-0.1072,  0.0615],\n",
      "        [-0.2191,  0.0679],\n",
      "        [-0.0405, -0.0165],\n",
      "        [ 0.1056, -0.0946],\n",
      "        [ 0.0434, -0.2570],\n",
      "        [ 0.0114,  0.1024],\n",
      "        [-0.1695, -0.2594]], device='cuda:1')\n",
      "\n",
      "\n",
      "forward0_2\n",
      "tensor([[ 0.1719, -0.0553],\n",
      "        [-0.2166, -0.1332],\n",
      "        [ 0.2314,  0.1686],\n",
      "        [ 0.0912,  0.2452],\n",
      "        [ 0.1926, -0.2042],\n",
      "        [-0.0840,  0.1033],\n",
      "        [-0.1877, -0.0892],\n",
      "        [-0.0533, -0.1691],\n",
      "        [ 0.2138,  0.2087],\n",
      "        [ 0.0098,  0.1530]], device='cuda:1')\n",
      "\n",
      "\n",
      "diff\n",
      "tensor([[-0.4124,  0.0980],\n",
      "        [ 0.2794,  0.0073],\n",
      "        [-0.1195, -0.1555],\n",
      "        [-0.1985, -0.1837],\n",
      "        [-0.4118,  0.2721],\n",
      "        [ 0.0435, -0.1199],\n",
      "        [ 0.2933, -0.0054],\n",
      "        [ 0.0967, -0.0880],\n",
      "        [-0.2024, -0.1063],\n",
      "        [-0.1793, -0.4124]], device='cuda:1')\n",
      "\n",
      "\n",
      "forward0_1\n",
      "tensor([-3.1004, -1.0550,  2.8708, -0.0550, -0.8923, -4.5338, -4.5922,  3.4581,\n",
      "         3.5120,  3.1023], device='cuda:1')\n",
      "\n",
      "\n",
      "forward0_2\n",
      "tensor([ 1.7300,  0.2092,  1.3216, -1.6478, -1.0615, -2.5309, -2.5836,  2.5261,\n",
      "         0.6514,  2.0247], device='cuda:1')\n",
      "\n",
      "\n",
      "diff\n",
      "tensor([-4.8304, -1.2642,  1.5492,  1.5928,  0.1691, -2.0030, -2.0086,  0.9320,\n",
      "         2.8605,  1.0776], device='cuda:1')\n",
      "\n",
      "\n",
      "forward0_1\n",
      "tensor([[ 2.4793, -0.8338, -0.1482,  2.2570,  0.0705, -0.9572,  0.8853, -1.6441,\n",
      "         -1.4349,  1.4125],\n",
      "        [ 0.2289, -1.4086,  0.7322, -0.7847,  0.2129, -1.2245,  1.7279,  1.6457,\n",
      "         -1.0363, -0.3922],\n",
      "        [ 2.3071,  1.1197,  0.9817,  0.3929,  0.2996, -1.3841,  1.0489,  0.8945,\n",
      "         -0.2767, -0.4971],\n",
      "        [-0.6410,  1.3028,  0.4598,  1.6837, -1.6528, -3.4613, -1.2583,  0.9302,\n",
      "          1.0531,  0.6310],\n",
      "        [ 1.8726,  1.0984,  0.9240, -1.2783,  1.1798,  0.1587, -0.2851,  1.0201,\n",
      "          1.4833, -1.0369],\n",
      "        [-1.4889,  1.5361,  0.6153,  0.8337,  0.9649,  0.7069, -1.0760,  0.9612,\n",
      "         -2.0484, -1.8562],\n",
      "        [-3.0154,  0.1431, -1.2200,  1.6807, -0.9838,  1.9125, -1.0077,  0.0247,\n",
      "         -1.5299, -1.3883],\n",
      "        [ 1.3192, -0.9967,  2.2930,  0.6019,  1.7363,  1.0750,  0.7120, -0.7029,\n",
      "         -1.2739,  0.6008],\n",
      "        [-0.4150,  0.3722, -2.3773,  1.6742, -2.0823,  0.9127,  0.8007, -2.5893,\n",
      "         -1.2006, -0.1728],\n",
      "        [-1.2953,  0.4375,  0.3203,  1.2639,  1.9045,  0.0819, -0.9917,  4.6737,\n",
      "          2.2627,  0.4302]], device='cuda:1')\n",
      "\n",
      "\n",
      "forward0_2\n",
      "tensor([[ 0.4930,  0.1458, -0.3084, -0.0061, -0.0857,  0.4385,  0.5502, -0.3057,\n",
      "         -0.8013, -0.3743],\n",
      "        [ 0.6497,  0.4506,  0.3496,  0.3672, -0.1174, -1.4576, -0.3312, -0.2564,\n",
      "         -0.6651,  0.6725],\n",
      "        [ 0.0759,  0.0971, -0.3074,  0.5385,  0.4588,  0.1904, -0.0460, -0.8690,\n",
      "         -0.4179, -0.2966],\n",
      "        [-0.0139,  0.0046,  0.1865, -0.0834, -0.0897,  0.5601,  0.4944,  0.1892,\n",
      "         -0.0824, -0.5380],\n",
      "        [-0.7427,  0.0872,  0.3157,  0.1659,  0.1291, -0.4136, -0.3105,  0.2477,\n",
      "          0.2795, -0.9850],\n",
      "        [-0.4368, -0.6250,  0.5066, -0.3825, -0.0961, -0.1407, -0.7897,  0.2613,\n",
      "         -0.1963, -1.5445],\n",
      "        [-0.6232,  0.5655, -0.3157, -0.0654, -0.2025,  1.4157,  0.5710, -0.6780,\n",
      "          0.2848, -0.3724],\n",
      "        [ 0.1195, -0.4271,  0.3616,  0.7816, -0.1478, -0.1494, -0.7569, -0.9499,\n",
      "         -0.1773, -0.0031],\n",
      "        [ 0.1779,  0.0772, -0.3725,  0.5263, -0.5281, -0.0361,  1.3004, -1.2863,\n",
      "         -0.0106, -0.8221],\n",
      "        [-0.4769, -0.0115,  0.3422,  0.0433, -0.5695,  0.1948, -0.4530,  1.0026,\n",
      "         -0.1991, -0.8003]], device='cuda:1')\n",
      "\n",
      "\n",
      "diff\n",
      "tensor([[ 1.9863, -0.9796,  0.1601,  2.2631,  0.1562, -1.3958,  0.3351, -1.3384,\n",
      "         -0.6335,  1.7868],\n",
      "        [-0.4209, -1.8593,  0.3826, -1.1520,  0.3303,  0.2332,  2.0591,  1.9021,\n",
      "         -0.3712, -1.0647],\n",
      "        [ 2.2312,  1.0226,  1.2891, -0.1456, -0.1592, -1.5745,  1.0949,  1.7635,\n",
      "          0.1413, -0.2006],\n",
      "        [-0.6272,  1.2982,  0.2733,  1.7671, -1.5631, -4.0215, -1.7528,  0.7410,\n",
      "          1.1356,  1.1690],\n",
      "        [ 2.6153,  1.0112,  0.6083, -1.4442,  1.0507,  0.5722,  0.0253,  0.7725,\n",
      "          1.2038, -0.0519],\n",
      "        [-1.0520,  2.1610,  0.1087,  1.2161,  1.0610,  0.8475, -0.2862,  0.6999,\n",
      "         -1.8521, -0.3118],\n",
      "        [-2.3922, -0.4225, -0.9043,  1.7461, -0.7813,  0.4968, -1.5787,  0.7027,\n",
      "         -1.8147, -1.0158],\n",
      "        [ 1.1998, -0.5696,  1.9315, -0.1797,  1.8841,  1.2244,  1.4690,  0.2470,\n",
      "         -1.0966,  0.6039],\n",
      "        [-0.5929,  0.2950, -2.0048,  1.1479, -1.5541,  0.9488, -0.4997, -1.3030,\n",
      "         -1.1900,  0.6493],\n",
      "        [-0.8184,  0.4491, -0.0219,  1.2206,  2.4740, -0.1129, -0.5387,  3.6711,\n",
      "          2.4619,  1.2305]], device='cuda:1')\n",
      "\n",
      "\n",
      "forward0_1\n",
      "tensor([-1.0806, -0.4926, -0.3920,  1.4716, -0.0149, -0.7820, -1.7077, -0.5360,\n",
      "        -1.8574,  2.4873], device='cuda:1')\n",
      "\n",
      "\n",
      "forward0_2\n",
      "tensor([-0.0057, -0.2715,  0.2454, -0.4961,  0.7667, -0.5553, -0.8986, -0.7387,\n",
      "        -0.7176,  0.7530], device='cuda:1')\n",
      "\n",
      "\n",
      "diff\n",
      "tensor([-1.0749, -0.2211, -0.6374,  1.9678, -0.7816, -0.2267, -0.8090,  0.2027,\n",
      "        -1.1398,  1.7342], device='cuda:1')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (name1, param1), (name2, param2) in zip(forward_nets[0].named_parameters(), forward_nets0[0].named_parameters()):\n",
    "    weight_diff = param1.data - param2.data\n",
    "    print(\"forward0_1\")\n",
    "    print(param1.data)\n",
    "    print(\"\\n\")\n",
    "    print(\"forward0_2\")\n",
    "    print(param2.data)\n",
    "    print(\"\\n\")\n",
    "    print(\"diff\")\n",
    "    print(weight_diff)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
